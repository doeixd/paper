# A Procedural and Naturalistic Model of Moral Objectivity

## Abstract

This paper extends Emergent Pragmatic Coherentism (EPC) from our previous work to metaethics, developing Pragmatic Procedural Realism, a naturalistic theory of moral objectivity grounded in systems theory and historical analysis. Unlike Kantian proceduralism, which relies on idealized rational procedures, our approach identifies objectivity with the actual historical process of pragmatic selection. We operationalize EPC's Systemic Brittleness Index through measurable proxies like the Coercion Ratio (C(t)) and Patch Velocity (P(t)), showing how normative claims are filtered by their real-world costs. This enables construction of a Negative Canon of empirically falsified moral principles, framing moral progress as systemic debugging. Moral objectivity emerges as a procedural fact about which normative architectures prove resilient. This objectivity rests not on historical accident but on the modal necessity of constraint-determined optimal solutions: the Apex Network exists as a structural fact about the viable normative landscape, discovered through pragmatic filtering rather than created by it. The result is a fallibilist realism that naturalizes moral reference while decisively responding to error theory (Mackie 1977) and quasi-realism (Blackburn 1993), reframing moral inquiry as an empirical, engineering discipline aimed at cultivating more viable social worlds.

## 1. Introduction: From Static Gaps to a Dynamic Filter

### 1.1. A Unified Theory of Justification: Emergent Pragmatic Coherentism (EPC)

Our previous work introduced Emergent Pragmatic Coherentism (EPC) as a general theory of justification. EPC treats inquiry as epistemic engineering: the ongoing project of building resilient public knowledge structures. These structures' viability can be assessed through their Systemic Brittleness Index (SBI), a measure of real-world costs from misalignment with pragmatic constraints. High costs appear as failed predictions, ad-hoc patches, and accumulating epistemic debt.

This paper extends EPC from epistemology to metaethics. We argue the is/ought gap is not a metaphysical barrier but results from static thinking that overlooks a unified cost-based justification mechanism. In a dynamic view, both factual and normative claims face the same pragmatic filter. The diagnostic tools for scientific theories can assess social and ethical systems. This unified approach dissolves the is/ought problem and grounds Pragmatic Procedural Realism—a naturalistic moral objectivity.

One might object that scientific and normative systems are fundamentally different kinds of entities, making this extension inappropriate. We argue the opposite. At the level of systems dynamics, both are informational architectures designed to solve problems of coordination—science coordinates our beliefs with the causal world, while ethics coordinates our actions with each other. Both generate measurable, real-world costs when their core principles are misaligned with their respective constraints. It is this shared functional challenge that justifies a unified diagnostic approach.

### 1.2. Thesis: Moral Progress as Systemic Debugging

This project rests on a simple idea: moral principles function like engineering designs for social worlds. Like any design, they can be elegant in theory but flawed in practice. Flawed bridge designs generate stress, cracks, and eventual collapse. Flawed normative designs (such as those built on slavery) generate social stress (dissent, rebellion), structural cracks (coercive costs, economic stagnation), and similar collapse. Our project develops diagnostic tools to detect these structural flaws in normative architectures before catastrophic failure.

Our central thesis is that moral progress is a real, observable process of systemic debugging, not teleological advance. Applying the SBI framework to history identifies brittle normative predicates (those generating catastrophic costs) and catalogs them in a Negative Canon of falsified moral principles. This reveals moral objectivity as an emergent procedural fact. Moral truths are reverse-engineered from systemic failures, like mapping reefs from shipwrecks.

The argument proceeds in four stages: (1) operationalizing SBI for normative analysis with measurable proxies; (2) applying this to model moral progress as predicate replacement; (3) situating Pragmatic Procedural Realism in metaethics as a naturalistic alternative; (4) defending against objections. The result unifies inquiry: pragmatic system-building discovers objective truth in science and ethics.

### 1.3. Scope and Limitations

This paper does not solve normativity's ultimate grounding or provide a non-circular defense of valuing survival. Instead, it takes a conditional, descriptive approach. The Constitutive Condition of Persistence serves as a procedural filter: normative systems must endure to be historically analyzable. Persistence is not a smuggled value but the entry requirement for justification. Our aim is not proving we ought to persist, but describing the rules of the game we play, shifting the focus from a search for metaphysical foundations to the task of building a testable, descriptive model of the evolutionary process through which values are filtered and earn their authority. This approach anticipates potential objections by clarifying that we do not claim to derive categorical imperatives from mere facts, but rather to identify the empirical patterns through which normative claims are tested and refined in practice.

## 2. The Diagnostic Engine: Operationalizing Normative Brittleness

### 2.1. Units of Selection: Standing Predicates

EPC provides a unified test for public knowledge systems. Claims are justified not just by internal coherence but by the system's demonstrated viability. Drawing from evolutionary theory, we distinguish the informational structure (core normative predicates and their relations) as the replicator: the abstract code transmitted over time. Social groups and institutions serve as the interactor: the physical vehicle for testing this code. A system "survives" by propagating its principles, even if the original group dissolves (as when Roman law was rediscovered in the Renaissance). This avoids naive group selectionism, focusing on long-term viability of the normative code.

This structure consists of Standing Predicates, reusable, action-guiding concepts that function as cultural "genes." A principle like "slavery is acceptable" is not just a statement but a predicate enabling actions, justifications, and social relations. We track these predicates' viability through historical testing.

Consider the normative predicate `...is a binding promise.` When a community treats this predicate as 'standing,' it doesn't just classify an utterance; it automatically licenses a cascade of normative judgments and social actions: the promiser incurs an obligation, the promisee gains a legitimate expectation, and third parties are licensed to apply social sanction (e.g., reputational damage) in case of non-fulfillment. The viability of this predicate is tested by its long-term success in reducing the costs of social friction and enabling complex cooperation.

### 2.2. Tiered Diagnostic Framework

To avoid circularity, we arrange costs hierarchically, from basic biological facts to complex systemic effects. While the SBI is a composite index, our analysis focuses on three core tiers:

*   Tier 1: Bio-Social Costs. Direct material consequences of friction with human persistence conditions, measured by objective proxies like excess mortality/morbidity rates, chronic malnutrition, and demographic decline. Systems generating these costs fail fundamentally.

*   Tier 2: Systemic Friction Costs. Resources expended managing dissent from Tier 1 costs, measured by the Coercion Ratio (C(t)), which tracks resources spent on suppression versus production. Rising C(t) indicates high maintenance costs for flawed designs.

*   Tier 3: Ideological Costs. Informational expenses justifying Tier 1 and 2 costs, measured by Patch Velocity (P(t)), the rate of ad-hoc ideological justifications (such as divine mandates for suffering). High P(t) signals accumulating ideological debt in failing systems.

These tiers form a causal cascade. Unaddressed Tier 1 costs (e.g., famine) generate dissent, forcing the system to incur Tier 2 costs (e.g., higher C(t) through suppression). To justify these failures, the system must then generate Tier 3 costs (e.g., accelerating P(t)). A high Tier 3 reading is thus a lagging indicator of deep, unresolved Tier 1 problems.

### 2.3. Falsifiability and Triangulation

This framework is empirically testable. Robust brittleness diagnosis requires convergent evidence from three baselines: (1) Comparative-Historical analysis against contemporaneous peers, (2) Diachronic comparison against the system's own trajectory, and (3) Biological Thresholds representing non-negotiable viability limits.

The core claim is that systemic costs predict long-term fragility. This would be falsified if historical analysis showed:

1. No Correlation: No significant link between high costs (e.g., violence) and systemic fragility
2. High-Cost Superiority: Coercive systems prove more innovative/resilient than cooperative ones
3. Negative Canon Failure: High-cost predicates (e.g., "slavery acceptable") enhance long-term viability

We acknowledge that measuring these costs is most straightforward in state-level societies with formal institutions. For informal normative systems, proxies must be more creative, relying on data from ethnographic studies, legal records of disputes, or bioarchaeological markers of stress within marginalized subgroups. The core principle remains: the costs are real and have empirical signatures, even when their measurement is indirect. The detailed methodology for conducting such a historical analysis, including protocols for operationalizing the brittleness metrics with inter-rater reliability checks, is laid out in the foundational paper for this framework (Glenn, Forthcoming).

With this diagnostic toolkit established, we can now apply it to historical cases to model the process of moral progress.

## 3. Moral Progress in Action: Diagnostic Case Studies

### 3.1. Non-Teleological Progress Model

EPC models moral progress as systemic debugging: identifying and removing high-cost predicates. This is not teleological advance toward utopia, but backward-looking correction of failures. Progress is empirically observable SBI reduction over time. A change qualifies as progress if the successor network has measurably lower SBI—fewer bio-social costs and systemic friction—than its predecessor.

### 3.2. Paradigm Case: Slavery's Systemic Failure

Abolition of chattel slavery exemplifies systemic debugging. Its status as objective progress rests not on modern sentiment but pragmatic diagnosis of "slavery is acceptable" as a catastrophic design flaw. Slave societies were high-brittleness fitness traps: locally stable but globally inefficient, sustained by immense coercive expenditure.

The costs were severe: pathologically high C(t) for surveillance and suppression; catastrophic bio-social costs from endemic violence and revolt risk; profound economic losses from suppressed human capital; and accelerating ideological patches (from "Curse of Ham" to race science), indicating high P(t). Abolitionist arguments diagnosed this inefficiency and brittleness. The replacement predicate "slavery is wrong" succeeded by promising dramatically lower SBI. The result was more viable social architecture. The successor system, while imperfect, proved significantly less brittle.

### 3.3. Complex Case: Patriarchy's Systemic Costs

EPC analyzes ongoing debates like patriarchy's decline. The predicate "women's roles are private and subordinate" proves profoundly inefficient: massive economic losses from excluding half the population; informational costs from silencing female perspectives; high coercive costs enforcing rigid roles.

Transition to egalitarianism involves short-term friction costs from social conflict. However, this is an investment that pays down patriarchal debt. Feminist critique wagers that fully utilizing all human resources yields greater long-term innovation and resilience (lower SBI). This transforms value clashes into empirical questions about social design efficiency. This wager is increasingly supported by evidence from development economics, which finds strong correlations between gender equality in education and economic participation and metrics of national prosperity and stability (cf. World Bank 2012; Duflo 2012).
## 4. Pragmatic Procedural Realism: The Metaethical Framework

### 4.1. Metaethical Position

Pragmatic Procedural Realism is the metaethical instantiation of Emergent Pragmatic Coherentism. While EPC provides the general theory of justification applicable across all domains (epistemology, science, mathematics), Pragmatic Procedural Realism specifies how that framework operates in the normative domain. The relationship is one of general theory to domain-specific application: EPC is the diagnostic methodology, Pragmatic Procedural Realism is its normative realization.

Pragmatic Procedural Realism is a naturalistic moral realism (cf. Boyd 1988; Railton 1986). Its objectivity claims are:

- Realist: Objective, mind-independent truths exist about normative viability. "Slavery is wrong" refers to structural facts about predicates' incoherence with the Apex Network, the emergent structure of viable norms.
- Procedural: Moral truths are emergent relational facts discovered historically. Truth-makers are objective facts about networks' pragmatic resilience (low SBI).
- Externalist: Justification rests on demonstrated historical track records, not internal coherence or cultural consensus.

This position maintains appropriate qualifications: while moral truths are objective in being determined by pragmatic constraints, our knowledge of them remains fallible and requires empirical triangulation, avoiding overconfidence in any particular historical assessment.

#### 4.1.1. The Pragmatic Procedure of Moral Inquiry

So, what is the 'procedure' in Pragmatic Procedural Realism? It is a multi-stage, iterative process of collective inquiry grounded in historical empirics:

1. Hypothesis Generation: Communities propose normative principles ('predicates') as potential solutions to social coordination problems.
2. Empirical Testing: These principles are implemented in social systems ('interactors'), where they are subjected to the non-negotiable filter of pragmatic consequences over historical time.
3. Data Collection and Diagnosis: We, as inquirers, analyze the historical track record of these systems, using the tiered diagnostic toolkit to measure their brittleness (Tier 1 costs, C(t), P(t)).
4. Mapping the Landscape: Through comparative analysis, we identify principles that reliably generate high costs and enter them into the Negative Canon (mapping the 'floor'). We also identify principles that repeatedly emerge in low-brittleness systems and add them to the Convergent Core.
5. Revision and Refinement: Armed with this evolving map, we are better equipped to revise our current normative systems, debugging high-cost principles and engineering more viable alternatives.

This procedure is empirical, fallible, and ongoing. It is the collective, scientific-historical method for discovering the objective contours of the viable normative landscape. This five-stage procedure grounds our realism: moral truths are objective because they are determined by this mind-independent filtering process, not by our subjective preferences or cultural conventions. What makes a principle true is its alignment with the emergent structure revealed through this collective, empirical method.

### 4.2. The Apex Network

Our objectivity rests on the Apex Network: the complete set of maximally coherent, pragmatically viable normative predicates. The Apex Network's objectivity stems not from historical contingency but from modal necessity. Reality imposes non-negotiable constraints: physical laws, biological facts about human cooperation, logical requirements, and coordination necessities. These constraints determine a landscape of possible normative configurations where some solutions are viable and others catastrophic. There exists an optimal configuration for navigating these constraints, just as there exists an optimal solution to a constrained optimization problem whether anyone has calculated it. The Apex Network is that optimal structure, existing whether we have discovered it or not, determined by constraints rather than by our beliefs about it.

Historical filtering is how we discover this structure, not how we create it. Failed systems are experiments revealing where the landscape drops off. Over time, with sufficient experiments across diverse conditions, we triangulate toward the peaks. This mirrors mathematical discovery: Ancient Babylonians and Indian mathematicians independently converged on π not through shared cultural transmission but because it is a necessary feature of Euclidean space, determined by geometric constraints. Similarly, independent cultures discovered reciprocity norms and harm prohibitions because these principles are structurally necessary for sustainable coordination. Discovery processes vary wildly; the discovered structure does not. This modal necessity, of course, holds relative to the deep and enduring pragmatic constraints that have defined the human condition. Should future technological or evolutionary developments fundamentally alter these constraints, the landscape of viability (and thus the structure of the Apex Network) would itself be subject to change. Our realism is therefore robust but not dogmatically fixed for all possible futures.

### 4.3. The Structure of the Viable Normative Landscape: The `Floor` and the `Ceiling`

This framework maps normativity's "floor" (non-negotiable viability conditions), not its "ceiling" of flourishing or aesthetics. Societies must secure the floor before pursuing higher goals.

- Negative Canon (Floor): Most secure objective knowledge, what is demonstrably unworkable. Provides boundaries preventing relativism, mapped from historical failures like a "reef chart."
- Convergent Core: Principles (such as reciprocity) independently discovered across cultures, suggesting stable, low-cost coordination solutions.
- Pluralist Frontier: Domain of multiple viable solutions (such as different organizational models). Accommodates cultural diversity and disagreement as empirical questions about boundaries.

### 4.4. Three-Level Normative Justification

This multi-level account applies the general three-level truth framework developed in EPC (see Glenn, Forthcoming, Section 4.3) to resolve the tension between relativism and objectivity. Normativity ascends through justificatory levels, from local coherence to objective viability.

**Level 1: Contextual Rightness (the 'Ought' of Coherence).** This is the realm of cultural relativity, where normativity follows a network's internal rules. In a 17th-century dueling society, the predicate `insults must be met with a challenge to a duel` was contextually right. Failing to issue a challenge was 'wrong' by the system's internal logic. This level provides procedural correctness without objective justification. The 'Ought of Coherence' commands: "If in this network, follow its rules." It binds locally but lacks external authority, explaining how abhorrent actions were once "right" while creating coherence traps that externalist checks must overcome.

**Level 2: Justified Rightness (the 'Ought' of Viability).** This level provides external, empirical justification based on demonstrated track records. While the dueling code was contextually right, historical diagnosis reveals catastrophic Tier 1 Bio-Social Costs (premature deaths of valuable community members) and high Tier 2 Costs (resources managing feuds and vendettas). The predicate is therefore justifiedly wrong, warranting its entry into the Negative Canon. The 'Ought of Viability' commands: "If we aim for resilient cooperation, adopt low-brittleness principles and avoid Negative Canon predicates."

**Level 3: Objective Rightness (the 'Ought' of Optimal Design).** This represents the regulative ideal and formal standard for Level 2 comparisons. The dueling predicate is objectively wrong because its high-cost nature conflicts with efficient, low-cost cooperation principles that form the Apex Network's modally necessary structure. The 'Ought of Optimal Design' represents the commands of a system that has solved for maximal viability. Principles like reciprocity that pass independent convergence tests are our strongest candidates. The dueling code demonstrably fails to achieve this solution.

### 4.5. The Entrenchment of Moral Principles: From Hypothesis to Core Norm

How does a normative principle like `innocent people should not be punished` achieve its foundational status? The entrenchment mechanism detailed in EPC (Glenn, Forthcoming) explains this journey of earning pragmatic indispensability:

1. Peripheral Hypothesis: The principle begins as a contested proposal, a potential solution to the high costs of rival principles like collective punishment.
2. Migration Inward: As it demonstrates immense value in lowering systemic brittleness (reducing C(t) by increasing legitimacy and stability), its revision becomes prohibitively costly. It becomes a Standing Predicate used to vet new laws and policies.
3. Core Principle (Systemic Caching): Its indispensability becomes so profound that it is embedded in the infrastructure of viable legal systems (constitutions, legal training, judicial review). This systemic caching is a rational response to bounded rationality; the system entrenches its most successful discoveries to avoid re-deriving them for every new case.

A core moral principle is not a self-evident axiom but a piece of highly optimized social technology that has survived rigorous pragmatic stress-testing. Its justification is its proven, indispensable functional role in viable social architectures. This entrenchment reflects pragmatic indispensability driven by bounded rationality (Simon 1972). The costs of revision become effectively infinite. Revising basic justice principles requires abandoning the conceptual tools needed to coordinate social expectations, resolve disputes, or maintain legitimate authority. After centuries of implementation, legal systems worldwide presuppose core fairness principles. Revision would generate catastrophic first-order costs, undermining the stability and legitimacy on which functional governance depends.

## 5. Objections, Defenses, and Principled Limitations

### 5.1. Objection: Might Makes Right

Pragmatic theories allegedly justify any enduring oppressive system. This confuses endurance with viability. Viability requires low SBI maintenance. Oppressive systems persisting through coercion are high-cost, high-brittleness traps. Longevity measures energy (high C(t)) needed for instability management, not strength.

### 5.2. Objection: Ideological Co-optation

Ideology might convince agents to endure failures, preventing revision. This mistakes brittleness symptoms for solutions. Ideological patches function as normative patching, analogous to ad-hoc scientific hypotheses that create epistemic debt. High P(t) (accelerating patch production) diagnoses rising SBI, not system health.

### 5.3. Objection: Testing Asymmetry

Empirical claims test quickly, moral claims slowly over generations. This asymmetry is predicted, not a flaw. EPC's unified filter acknowledges system complexity determines feedback timescale and texture.

### 5.4. Objection: Circularity and Grounding

Making viability the standard appears circular, seemingly smuggling in a normative commitment to persistence. We offer a two-part defense that separates the grounding of the justificatory arena from claims about internal normative force.

First, the Constitutive Defense. The Persistence Condition is not a value we endorse but a structural precondition for the existence of normative systems that can be analyzed. Any normative system that fails to persist simply drops out of the historical record, making it unavailable for comparative study. This is not because we judge non-persistence negatively, but because persistence is the entry condition for having a track record to evaluate. It functions as a methodological filter on available data, not as a substantive value commitment.

Second, the Instrumental Defense. Our framework offers a conditional ought: "If a community aims to persist while solving coordination problems, then it should adopt principles aligned with the Apex Network and avoid Negative Canon predicates." This hypothetical imperative does not claim persistence is categorically good, only that it is the goal relative to which our diagnostic tools provide guidance. For communities indifferent to persistence, our framework offers no normative force. But for communities that do aim to persist, our framework identifies which architectural features reliably support or undermine that goal.

### 5.5. Additional Objections and Replies

Objection: Cultural Relativism - Different cultures have viable but incompatible norms. Reply: Compatible with pluralism in periphery while maintaining floor constraints. Cultural diversity exists within viability boundaries.

Objection: Moral Progress Skepticism - Progress claims are Western bias. Reply: Framework predicts pluralist periphery but universal floor. Progress diagnosed empirically via SBI reduction, not cultural superiority.

Objection: Scientific Imperialism - Reducing ethics to science (cf. Putnam 2002). Reply: Not scientism but unified pragmatic filter. Moral claims remain normative but justified externally like scientific ones.

Objection: Evolutionary Debunking - Evolutionary pressures shaped moral intuitions for survival, not truth (cf. Street 2006). Reply: EPC resolves Street's dilemma by collapsing one of its horns. The dilemma assumes that truth and adaptiveness are independent aims, making their alignment a coincidence. Our framework denies this premise. For us, moral truth *is* a specific, demanding form of long-term systemic adaptiveness (i.e., viability). Evolution is not a distorting influence that the realist must explain away; it is the broader category of filtering processes within which the specific, cost-based discovery of moral truth takes place. Pragmatic viability is what moral truth supervenes on.

Objection: The Naturalistic Fallacy. The framework seems to define 'the good' as 'the viable,' improperly deriving a value from a fact. Reply: This misinterprets the project. We are not deriving 'ought' from 'is' in the classic sense. Rather, we are offering a naturalistic reconstruction of the function of our normative practice. The claim is that what our successful moral discourse has actually been tracking all along are these facts about systemic viability. 'Wrongness' is not being defined as high-brittleness; rather, high-brittleness is the underlying natural property that the term 'wrongness' has been imperfectly latching onto. This is a semantic externalist move: just as 'water' successfully referred to H₂O long before we understood molecular chemistry, 'wrong' has been successfully tracking high-brittleness principles long before we developed the diagnostic tools to measure it explicitly. This naturalizes the reference of our moral terms, explaining their functional authority without committing a fallacy.

Objection: How does this differ from Kitcher's 'Ethical Project'? Reply: Our project shares much with Kitcher's (2011) view of ethics as a social technology for solving problems of altruism. However, EPC offers two crucial advancements. First, it provides a more general diagnostic toolkit (the SBI) that applies equally to scientific and ethical 'technologies,' grounding the project in a unified theory of justification. Second, EPC's concept of the modally necessary Apex Network provides a more robustly realist foundation. Where Kitcher's progress is defined by functional enhancement relative to a historical starting point, our framework grounds progress in convergence toward an objective, mind-independent structure of viability. This offers a stronger defense against charges of historicism or relativism.

Objection: Hindsight Rationalization. The framework can only diagnose brittleness after failure, making it merely retrospective rather than providing prospective guidance. Reply: This misunderstands the calibration process. We use clear historical data (the Negative Canon) to calibrate our diagnostic instruments, identifying the empirical signatures that reliably precede collapse. These calibrated instruments then enable prospective diagnosis, not deterministic prediction, but epistemic risk assessment for contemporary systems. This parallels medical science: we learn disease patterns from past cases to diagnose present patients before symptoms become catastrophic. The framework thus operates in two stages: retrospective calibration using historical failures to identify brittleness indicators, then prospective application of these calibrated metrics to assess current systems and identify degenerating research programs before collapse.

### 5.6. Principled Limitations

**The Viable Evil Possibility.** If a deeply repugnant system achieved genuinely low brittleness (minimal coercive costs, stable demographics, sustained innovation, and adaptation), our framework would acknowledge it as viable, though not necessarily just by other moral standards. Consider a hypothetical perfectly internalized caste system where lower castes genuinely accept their position with minimal coercion, no demographic stress, stable innovation, and low enforcement costs, yet remains intuitively morally repugnant.

We accept this implication for intellectual honesty. The framework maps pragmatic viability, not all moral dimensions. If such a system existed, it would fall in the Pluralist Frontier, not the Negative Canon.

However, our empirical wager is that such systems are inherently brittle. Apparent stability in historical examples like Ottoman devşirme or Indian caste systems masked high coercive overheads, innovation lags, and fragility under shocks (cf. Acemoglu & Robinson 2012; Turchin 2003). True, cost-free internalization is likely a sociological impossibility. Oppression generates hidden costs that manifest under stress. Even systems like *Brave New World* that suppress cognitive capacities incur massive information suppression costs (Tier 2) that cripple long-term adaptation.

- Species-Specific: Apex Network for cooperative primates like humans. Empirical discipline, not relativism.
- Floor Not Ceiling: Maps viability necessities, not flourishing sufficiency.
- Tragic Knowledge: Most reliable moral insights from catastrophic failures. Progress real but costly.
- Fallibilism: Our assessments remain provisional; historical analysis can be contested, and new evidence may revise the Negative Canon.

## 6. Conclusion: The Pragmatic Craft of Building a More Viable World

Pragmatic Procedural Realism reframes moral philosophy from a search for ultimate metaphysical foundations to the ongoing, fallible craft of pragmatic navigation. It is a theory of the 'floor' of normativity, the necessary, evidence-based foundations upon which any successful cooperative system must be built. It does not dictate the final architecture of the 'ceiling,' the diverse forms of flourishing a viable society might choose to pursue. But by providing a naturalistic and falsifiable method for identifying the structural principles of systemic viability, it offers a solid, empirical foundation upon which those more aspirational projects can securely build, steering us by the light of humanity's most enduring successes and the hard-won lessons from the wreckage of its failures. It is a philosophy that learns from the architecture of failure to engineer more viable architectures of cooperation. This framework reframes moral inquiry as an essential form of collaborative engineering, requiring philosophers, social scientists, and policymakers to work together to diagnose and debug our most critical social systems. Its application to contemporary challenges, from the ethics of artificial intelligence to the design of institutions for global cooperation, represents a promising direction for future work with practical implications for policy and governance.

## Glossary

*   **Apex Network**: The complete set of maximally coherent, pragmatically viable normative predicates, existing as a necessary structure determined by pragmatic constraints rather than historical contingency
*   **Brittleness**: Accumulated systemic costs indicating structural fragility
*   **C(t) (Coercion Ratio)**: Proportion of a system's resources dedicated to internal coercion versus productive output
*   **Emergent Pragmatic Coherentism (EPC)**: General theory of justification grounding coherence in demonstrated viability across all inquiry domains
*   **Fitness Trap**: A locally stable but globally inefficient high-brittleness configuration maintained by high coercive costs
*   **Floor vs. Ceiling**: The 'floor' comprises non-negotiable viability principles; the 'ceiling' comprises underdetermined dimensions of human flourishing
*   **Negative Canon**: Catalogue of empirically falsified normative principles demonstrating high brittleness
*   **Normative Patching**: Creation of ad-hoc ideological justifications masking Tier 1 and Tier 2 costs
*   **P(t) (Patch Velocity)**: Rate at which a system generates ideological justifications to explain accumulating costs
*   **Standing Predicate**: Reusable, action-guiding normative concept functioning as a unit of cultural transmission
*   **Systemic Debt**: Accumulated, unaddressed costs of a brittle normative system, often paid suddenly during crisis

## References

Acemoglu, Daron, and James A. Robinson. 2012. *Why Nations Fail: The Origins of Power, Prosperity, and Poverty*. New York: Crown Business.

Axelrod, Robert. 1984. *The Evolution of Cooperation*. New York: Basic Books.

Bagnoli, Carla, ed. 2013. Constructivism in Ethics. Cambridge: Cambridge University Press.

Bennett, Andrew, and Jeffrey T. Checkel, eds. 2014. Process Tracing: From Metaphor to Analytic Tool. Cambridge University Press. 

Blackburn, Simon. 1993. *Essays in Quasi-Realism*. New York: Oxford University Press.

Boyd, Richard N. 1988. “How to Be a Moral Realist." In Essays on Moral Realism, edited by Geoffrey Sayre-McCord, 181–228. Ithaca, NY: Cornell University Press.

Buchanan, Allen, and Russell Powell. 2018. *The Evolution of Moral Progress: A Biocultural Theory*. New York: Oxford University Press.

Conquest, Robert. 1990. The Great Terror: A Reassessment. Oxford University Press.

Dewey, John. (1929) 1960. *The Quest for Certainty: A Study of the Relation of Knowledge and Action*. New York: Capricorn Books.

Foot, Philippa. 2001. *Natural Goodness*. Oxford: Clarendon Press.

Gil Martín, Francisco, and Jesús Encabo. 2008. “Truth and Moral Objectivity: Procedural Realism in Putnam's Pragmatism.” Poznan Studies in the Philosophy of the Sciences and the Humanities 95: 265–285.

Glenn, Patrick. Forthcoming. "The Architecture of Failure: How Systemic Brittleness Drives Convergent Coherence to Forge Objective Truth."

Heidler, Raphaela, et al. 2019. "Bayesian Analysis for Historians." Historical Methods 52(3): 143–162.

Habermas, Jürgen. 1990. Moral Consciousness and Communicative Action. Translated by Christian Lenhardt and Shierry Weber Nicholsen. Cambridge, MA: MIT Press.

Harding, Sandra G. 2004. *The Feminist Standpoint Theory Reader*. New York: Routledge.

Henrich, Joseph. 2015. *The Secret of Our Success: How Culture Is Driving Human Evolution, Domesticating Our Species, and Making Us Smarter*. Princeton, NJ: Princeton University Press.

Holling, C. S. 1973. “Resilience and Stability of Ecological Systems.” *Annual Review of Ecology and Systematics* 4: 1–23.

Joyce, Richard. 2001. The Myth of Morality. Cambridge: Cambridge University Press.

Kitcher, Philip. 2011. The Ethical Project. Cambridge, MA: Harvard University Press.

Korsgaard, Christine M. 1996. The Sources of Normativity. Cambridge: Cambridge University Press.

Mackie, J. L. 1977. *Ethics: Inventing Right and Wrong*. London: Penguin Books.

Patterson, Orlando. 1982. *Slavery and Social Death: A Comparative Study*. Cambridge, MA: Harvard University Press.

Popper, Karl. (1934) 1959. *The Logic of Scientific Discovery*. London: Hutchinson.

Putnam, Hilary. 2002. The Collapse of the Fact/Value Dichotomy and Other Essays. Cambridge, MA: Harvard University Press.

Quine, W. V. O. 1951. “Two Dogmas of Empiricism.” *The Philosophical Review* 60 (1): 20–43.

Railton, Peter. 1986. “Moral Realism.” *The Philosophical Review* 95 (2): 163–207.

Rawls, John. 1971. A Theory of Justice. Cambridge, MA: Harvard University Press.

Rorty, Richard. 1979. *Philosophy and the Mirror of Nature*. Princeton, NJ: Princeton University Press.

Scott, James C. 1998. Seeing Like a State: How Certain Schemes to Improve the Human Condition Have Failed. New Haven, CT: Yale University Press.

Street, Sharon. 2006. “A Darwinian Dilemma for Realist Theories of Value.” *Philosophical Studies* 127 (1): 109–66.

Streumer, Bart. 2025. "Quasi-Realism for Realists." Philosophers' Imprint 25 (10): 1–17.

Tainter, Joseph A. 1988. *The Collapse of Complex Societies*. Cambridge: Cambridge University Press.

Turchin, Peter. 2003. *Historical Dynamics: Why States Rise and Fall*. Princeton, NJ: Princeton University Press.
