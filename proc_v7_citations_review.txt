
================================================================================
Citation Extraction Run - 2025-10-07 12:59:25
Files scanned: proc_v7.md
Total citations: 4
================================================================================


################################################################################
FILE: proc_v7.md
################################################################################

Citation 1 [PARENTHETICAL]:
Line: 5
Citation: (Blackburn 1993)

Context:
## Abstract

This paper extends Emergent Pragmatic Coherentism (EPC) from our previous work to metaethics, developing Pragmatic Procedural Realism, a naturalistic theory of moral objectivity grounded in systems theory and historical analysis. Unlike Kantian proceduralism, which relies on idealized rational procedures, our approach identifies objectivity with the actual historical process of pragmatic selection. We operationalize EPC's Systemic Brittleness Index through measurable proxies like the Coercion Ratio (C(t)) and Patch Velocity (P(t)), showing how normative claims are filtered by their real-world costs. This enables construction of a Negative Canon of empirically falsified moral principles, framing moral progress as systemic debugging. Moral objectivity emerges as a procedural fact about which normative architectures prove resilient. This objectivity rests not on historical accident but on the modal necessity of constraint-determined optimal solutions: the Apex Network exists as a structural fact about the viable normative landscape, discovered through pragmatic filtering rather than created by it. The result is a fallibilist realism that naturalizes moral reference while decisively responding to error theory (Mackie 1977) and quasi-realism (Blackburn 1993), reframing moral inquiry as an empirical, engineering discipline aimed at cultivating more viable social worlds.

## 1. Introduction: From Static Gaps to a Dynamic Filter

Reference:
Blackburn, Simon. 1993. *Essays in Quasi-Realism*. New York: Oxford University Press.
------------------------------------------------------------

Citation 2 [PARENTHETICAL]:
Line: 61
Citation: (Glenn, Forthcoming)

Context:
2. High-Cost Superiority: Coercive systems prove more innovative/resilient than cooperative ones
3. Negative Canon Failure: High-cost predicates (e.g., "slavery acceptable") enhance long-term viability

We acknowledge that measuring these costs is most straightforward in state-level societies with formal institutions. For informal normative systems, proxies must be more creative, relying on data from ethnographic studies, legal records of disputes, or bioarchaeological markers of stress within marginalized subgroups. The core principle remains: the costs are real and have empirical signatures, even when their measurement is indirect. The detailed methodology for conducting such a historical analysis, including protocols for operationalizing the brittleness metrics with inter-rater reliability checks, is laid out in the foundational paper for this framework (Glenn, Forthcoming).

With this diagnostic toolkit established, we can now apply it to historical cases to model the process of moral progress.

Reference: NOT FOUND for 'Glenn Forthcoming'
------------------------------------------------------------

Citation 3 [PARENTHETICAL]:
Line: 134
Citation: (Glenn, Forthcoming)

Context:
### 4.5. The Entrenchment of Moral Principles: From Hypothesis to Core Norm

How does a normative principle like `innocent people should not be punished` achieve its foundational status? The entrenchment mechanism detailed in EPC (Glenn, Forthcoming) explains this journey of earning pragmatic indispensability:

1. Peripheral Hypothesis: The principle begins as a contested proposal, a potential solution to the high costs of rival principles like collective punishment.
2. Migration Inward: As it demonstrates immense value in lowering systemic brittleness (reducing C(t) by increasing legitimacy and stability), its revision becomes prohibitively costly. It becomes a Standing Predicate used to vet new laws and policies.

Reference: NOT FOUND for 'Glenn Forthcoming'
------------------------------------------------------------

Citation 4 [PARENTHETICAL]:
Line: 140
Citation: (Simon 1972)

Context:
2. Migration Inward: As it demonstrates immense value in lowering systemic brittleness (reducing C(t) by increasing legitimacy and stability), its revision becomes prohibitively costly. It becomes a Standing Predicate used to vet new laws and policies.
3. Core Principle (Systemic Caching): Its indispensability becomes so profound that it is embedded in the infrastructure of viable legal systems (constitutions, legal training, judicial review). This systemic caching is a rational response to bounded rationality; the system entrenches its most successful discoveries to avoid re-deriving them for every new case.

A core moral principle is not a self-evident axiom but a piece of highly optimized social technology that has survived rigorous pragmatic stress-testing. Its justification is its proven, indispensable functional role in viable social architectures. This entrenchment reflects pragmatic indispensability driven by bounded rationality (Simon 1972). The costs of revision become effectively infinite. Revising basic justice principles requires abandoning the conceptual tools needed to coordinate social expectations, resolve disputes, or maintain legitimate authority. After centuries of implementation, legal systems worldwide presuppose core fairness principles. Revision would generate catastrophic first-order costs, undermining the stability and legitimacy on which functional governance depends.

## 5. Objections, Defenses, and Principled Limitations

Reference:
Simon, Herbert A. 1972. "Theories of Bounded Rationality." In *Decision and Organization*, edited by C. B. McGuire and Roy Radner, 161â€“76. Amsterdam: North-Holland Publishing Company.
------------------------------------------------------------

