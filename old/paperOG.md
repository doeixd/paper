# Extending Quine's Web: A Pragmatic and Emergent Model of Moral Knowledge

### Abstract

This paper proposes **Emergent Pragmatic Coherentism (EPC)**, a descriptive model of moral epistemology designed to re-frame, rather than solve, the is/ought problem. Building on Quine’s holism, EPC models knowledge as an emergent hierarchy of shared “networks of predicates” scaling up from the individual “web of belief.” Within this architecture, truth is treated deflationarily: not as correspondence with ultimate reality, but as a functional label for robust coherence within a pragmatically-tested network. Crucially, EPC disciplines this network-relativity through an external, selective filter: evolutionary pragmatic selection, the relentless pressure exerted by reality itself. Networks incurring high systemic costs collapse over time, while resilient networks propagate. This process grounds a form of procedural objectivity: truth is internal to networks, but networks themselves can be objectively ranked by their long-term viability. The ultimate regulative standard is a real, emergent historical object—the Apex Network—understood not as a metaphysical ideal but as the cumulative record of predicates that have survived humanity’s long encounter with reality. EPC’s central claim is conditional: if we begin from minimal naturalism, where endurance is a non-negotiable constraint, then EPC provides the best available account of moral progress—not from metaphysical fiat, but from the empirical lessons encoded in our most resilient social and epistemic structures.

This initial network-relativity is disciplined by a procedural and objective process of evolutionary pragmatic selection. The model posits that networks are continuously filtered by the constraints of reality, and that unviable networks—those generating high degrees of systemic friction, or pragmatic pushback—are abandoned over time. Consequently, while 'truth' is a property internal to a network, the networks themselves can be objectively ranked by their long-term pragmatic viability. The ultimate standard for this ranking is a theoretical, emergent object this paper terms the Apex Network.

EPC's central claim is conditional: if we begin from a minimal naturalism where endurance is a de facto constraint, then EPC provides a robust model of procedural objectivity. The paper does not seek to solve the ultimate grounding problem but to describe the system that in fact adjudicates our normative claims. It offers a naturalistic model of moral progress, locating the source of normative authority not in a metaphysical foundation, but in the cumulative, hard-won lessons encoded in humanity's most resilient social and epistemic structures. EPC’s contribution is to naturalize moral epistemology by unifying descriptive and normative claims under one selection process, extending Quine’s holism into the moral domain.

---

## 1. Introduction: Modeling the Court of Pragmatic Selection

For centuries, philosophy has wrestled with the apparent gap between claims of fact (“is”) and claims of value (“ought”). EPC suggests that this gap is not a permanent chasm but an artifact of foundationalist epistemology, which artificially segregates descriptive and normative claims. Rather than building a speculative “bridge” across the gap, this paper describes the system we already use to adjudicate both: the evolutionary court of pragmatic selection. On this view, facts and values are tested by the same filter—the unforgiving feedback of reality—and the authority of an “ought” emerges not from metaphysical foundations but from survival-tested coherence.

This paper presents such a model: Emergent Pragmatic Coherentism (EPC). At its core, EPC is a systematic extrapolation of Quinean holism. It begins with the premise that individuals navigate reality using a “web of belief,” a coherent but fallible network of claims. Because all agents face the constraints of a shared reality, these individual webs inevitably overlap where they prove pragmatically successful, giving rise to an emergent hierarchy of shared networks.
EPC models this entire system as an evolutionary process. A claim is 'true' in a deflationary sense: it is coherent within a given network. However, the networks themselves are subject to a ruthless, external filter this paper terms evolutionary pragmatic selection. Networks that generate high degrees of systemic friction, or pragmatic pushback, are less viable and tend to be abandoned over time. The ultimate standard for this process is a theoretical, emergent object—the maximal set of historically viable predicates—termed the Apex Network. Our access to this standard is primarily negative, through the construction of an evidence-based Negative Canon of failed systems.

The argument will proceed by first detailing the core architecture of the EPC model: the bottom-up emergence of shared networks, the evolutionary engine of pragmatic selection, and the negative, historical methodology by which we approximate a standard of objectivity. The paper will then demonstrate the framework's explanatory power by applying its diagnostic tools throughout to a primary historical case study: the abolition of slavery. With the model fully articulated and illustrated, the argument will turn to defending it against the most pressing philosophical objections and, finally, situating it in the contemporary landscape by distinguishing it from its major rivals. 

### 1.1 The Status of the Project: A Conditional and Descriptive Turn

It is essential to be precise about scope. EPC does not claim to solve the ultimate problem of grounding normativity, nor to provide a non-circular answer to “why value survival?” Instead, it takes a conditional, descriptive turn. Its claim is modest but powerful: if we assume minimal naturalism—where endurance is the de facto constraint on any system—then EPC provides a robust account of procedural objectivity and moral progress. This conditionality is not a weakness but a methodological strength: by bracketing metaphysical ultimates, EPC avoids endless regress and instead models the actual process by which our normative claims are tested and revised. It does not provide a non-circular answer to the question, "Why should I value pragmatic viability?"

Instead, EPC is a conditional and descriptive model of moral epistemology. Its central claim is this: if one begins from a minimal naturalism where endurance is a de facto constraint on any system, then EPC provides a robust model of procedural objectivity and moral progress. The paper does not defend the initial 'if'—a task for a different metaethical project—but rather demonstrates the explanatory power of the 'then'.

Its ambition is to provide the first systematic description of the rules of the game we are already playing. It shifts the focus from a futile search for metaphysical foundations to the construction of a testable model of the evolutionary process by which values are filtered, retained, and come to have authority. It describes the court of pragmatic selection; it does not attempt to justify that court's ultimate jurisdiction.

### 1.2 Truth, Viability, and the Pragmatic 'Ought'

Within this descriptive framework, EPC employs a deflationary account of truth. 'Truth' is not a claim of correspondence with ultimate reality, but a functional label for a predicate’s robust coherence within a specified, pragmatically-tested network. A critic might then ask: why should this internal property of 'truth' have any normative force?

The answer lies in the evolutionary origin of the network itself. A shared network is not a logic puzzle; it is a tool for survival forged in the crucible of history. The descriptive fact that a predicate is 'true' (i.e., coherent with one of our most successful, time-tested networks) is therefore a powerful empirical signal. It indicates that the predicate is an integral component of a highly viable strategy for navigating reality.

This reconnects the 'is' and the 'ought' in a procedural way. The 'is' of a predicate's truth-value serves as a reliable guide to the pragmatic 'ought', precisely because that network's coherence was itself forged by the unforgiving 'is' of reality's feedback. To trust what is 'true' in our best networks is therefore not an appeal to correspondence with a hidden reality, but a pragmatic wager: the hard-won lessons of history are more reliable guides than our untested intuitions. This reframes the is/ought problem procedurally: the “is” of a predicate’s truth-value signals the pragmatic “ought,” because coherence itself has already been stress-tested against reality’s feedback. EPC therefore grounds normativity not in metaphysics but in the cumulative survival data of humanity’s most resilient networks.

## 2. The Architecture of Emergence: From Individual Webs to Shared Networks

The foundation of Emergent Pragmatic Coherentism is a systematic extrapolation of W.V.O. Quine’s holism. Just as Quine’s critique of the analytic/synthetic distinction collapsed the wall between truths of logic and truths of fact, EPC uses his holistic framework to re-frame the distinction between facts and values. Quine famously pictured an individual's knowledge as a “web of belief”—a contextual, coherent network that serves as the arena in which truth-claims are made and adjudicated.¹ While a brilliant metaphor, it remains fundamentally psychological. The task for a social epistemology is to model the structural nature of our shared knowledge.

EPC argues that this transition from the private to the shared is not a puzzle to be solved, but an inevitable, bottom-up process of emergence. The model rests on two basic premises:

1. Every individual agent navigates the world using their own Quinean web of beliefs.
2. Every individual agent is subject to the pragmatic constraints of a shared reality.

From these premises, a third fact follows with structural necessity: wherever agents successfully interact with reality, their individual webs are forced to overlap. Crucially, this intersection is not a conscious negotiation or top-down agreement, but an instantaneous, bottom-up emergence. As soon as two agents align around a successful practice (building a canoe, trading food, coordinating defense), their individual webs have already been pragmatically updated and partially fused. Shared networks are therefore contextual and fluid: they arise automatically at the points where individual survival strategies converge under reality’s feedback. When two people build a functional canoe, their individual webs regarding concepts like 'buoyancy' and 'cooperation' have been forced into a shared, coherent alignment by the unforgiving feedback of the physical world.

The coherent set of predicates shared by the canoe-builders is a miniature emergent network. This process scales dynamically across all levels of social organization. A scientific community, a legal system, or an entire culture are simply vastly more complex versions of the same phenomenon. These emergent, shared networks are not centrally designed or consciously ratified. They are the inevitable, contextual byproducts of countless individual webs being continuously filtered and revised against a shared reality. Because individuals are always adjusting their own webs in real time under pragmatic pressure, overlap emerges instantly wherever coherence is rewarded. This bottom-up mechanism explains why durable norms often appear without formal coordination—they are the structural consequence of convergence under common constraints. Their existence is a matter of structural necessity, not consensus.

To analyze this emergent reality, EPC makes a crucial shift from the psychological language of a "web of belief" to the more formal concept of a “network of predicates.” A predicate is the structural component of a claim (e.g., “…is wrong,” “…boils at 100°C”). This move is crucial for three reasons. First, it shifts the analysis from the private and mental to the shared and structural. Second, it makes the formal commensurability of all claims explicit, preparing the ground for a unified test of viability.

Third, and most crucially, it operationalizes the paper's deflationary and coherentist account of truth. On this view, 'truth' is not a claim of correspondence with a noumenal reality, but a functional label. It is a relational property that signifies a predicate's robust coherence within a specified network—a network that has itself been forged by the bottom-up, emergent process. A predicate is therefore 'true' relative to a network, and its truth-value can change the moment that network is pragmatically revised in response to friction. This dynamic updating is not optional but constitutive: coherence shifts whenever agents encounter pushback, making truth a continuously recalibrated property of networks. Far from simple relativism, this context-sensitive dynamism is the conceptual ground for EPC’s account of procedural objectivity: objectivity emerges not from static correspondence, but from the convergent survival of networks forged in the bottom-up crucible of shared reality.

## 3. The Engine of Selection: Pragmatic Pushback and System Viability

What prevents the emergent networks described in Section 2 from being arbitrary, self-justifying constructs? The answer is the constant, bottom-up filter of evolutionary pragmatic selection. This is not a slow or occasional tribunal, but a continuous and immediate process: as soon as a predicate misfires against reality, individuals experience friction, update their webs, and shift alignment. The aggregate of these countless local adjustments is the instant contextual evolution of the shared network. Selection is therefore not external policing but an internal, ever-present discipline exerted by reality’s feedback. This section will detail the causal model of this mechanism, showing how a set of minimal premises entails both the bottom-up emergence of shared networks and the selective, non-foundationalist filter that continuously refines them.

The model rests on two minimal, empirically observable premises: (1) that agents exist within a world with hard constraints, and (2) that they are animated by a suite of persistent, evolved drives to navigate these constraints. Within this suite, one drive has a unique philosophical status: the ‘drive to endure.’ This is not a thick, value-laden concept of "flourishing," but the most minimal, biologically-grounded precondition for any system's continued existence: the persistence of its structure and core information over time.

The causal primacy of this drive can be seen by examining networks organized around apparently different goals (e.g., a religious community focused on otherworldly salvation or a "death cult" focused on glorious sacrifice). The EPC model does not deny the existence of these alternative drives. Instead, it diagnoses them as predicates whose widespread adoption incurs catastrophic First-Order costs. A network that devalues worldly persistence in favor of otherworldly rewards will, in the long run, be outcompeted and eliminated by networks that are better at managing their members' material and social well-being. The drive to endure retains its primary, foundational status not because it is the only drive agents possess, but because it is the ultimate selective filter through which all other drives are tested.

This minimal definition is what gives the drive its unique, non-moral status. All other potential drives (e.g., for purity, glory, or divine submission) are substantive claims about how to live; they are predicates whose long-term pragmatic consequences are to be evaluated. The drive to endure, by contrast, functions as the constitutive condition of inquiry itself. It is the pre-rational, biological "is" that makes the testing of any predicate-network a necessary and meaningful activity. While its precise boundaries are a valid site of philosophical contention, the project of navigating reality via a network of beliefs necessarily presupposes a commitment to persistence. To question this drive's primacy is a form of pragmatic self-contradiction, as the act of questioning is performed by a system already engaged in the project of enduring.

These premises explain not only why shared networks form (as a convergent solution to shared problems), but also how they are filtered. The selective pressure originates at the individual level as pragmatic pushback. When an agent's actions, guided by a predicate, clash with the constraints of reality, they generate friction—a personal experience of dysfunction. When a predicate is misaligned with shared conditions of reality, individuals will independently and repeatedly experience friction. These experiences aggregate instantly into systemic signals: widespread suffering, dissent, inefficiency, or brittleness. The emergent network “knows” this in real time, not because anyone has consciously tallied costs, but because its constituent agents are already updating their webs in response.

It is this large-scale aggregation of individual friction that constitutes systemic pragmatic pushback: the holistic, emergent consequence of a network's widespread adoption. This is not a vague feeling, but a phenomenon with objective, empirical signatures, such as:

- **Persistence and Breadth:** Systemic friction that recurs across generations and cultural contexts.
- **Systemic Cost:** The immense and ongoing investment of energy (e.g., in coercion and ideological maintenance) required to manage the friction a predicate generates.

This persistent, costly friction is the selective pressure that drives network evolution. It is a bottom-up, emergent phenomenon: individuals, experiencing friction, independently revise their personal networks. The mass aggregation of these local recalibrations causes flawed predicates to decay and more viable alternatives to propagate, thus evolving the shared network. The crucial point is that the data signaling a predicate's incoherence is generated most intensely at the points of greatest friction. Therefore, suffering and dissent are not mere moral problems; they are primary epistemological signals of a network's pragmatic failure. To prevent a circular diagnosis, however, we must turn to the causal mechanism of that failure.

### **3.1 The Causal Mechanism: A Hierarchy of Pragmatic Costs**

To ground the analysis of systemic friction in a non-circular, non-ideological metric, the EPC model specifies a causal hierarchy of pragmatic costs.

*   **First-Order Costs:** These are the direct, material signatures of a network's conflict with the constitutive drive to endure. They can be identified through objective metrics: elevated mortality rates, systemic violence, resource depletion, and the immense, ongoing energy expenditure required for mass coercion. These are not abstract "harms" but the measurable, physical consequences of a system generating friction against the biological reality of its agents.

*   **Second-Order Costs:** These are more abstract, ideologically-framed costs contingent on a particular sub-network's survival, such as threats to a cultural identity or the disruption of an existing economic model.

The central principle is that **First-Order costs have causal and diagnostic priority.** This is not a normative claim about which forms of suffering matter more; it is a descriptive, systems-dynamic claim about what makes a network unstable. High mortality rates and massive energy expenditures on coercion are objective, material drags on a system's resilience, *regardless of how the dominant group interprets them*. A network that must constantly pay immense First-Order costs to shield itself from potential Second-Order costs is demonstrating a critical design flaw. Its long endurance is not evidence of its viability, but a measure of the energy it must burn to manage its own self-inflicted instability.

This dynamic creates a fatal feedback loop termed **Information Cost**. By systematically suppressing the dissent of those experiencing the most intense First-Order costs, a network blinds itself to the most critical data signaling its own failures. This self-induced epistemic brittleness makes the network profoundly vulnerable to novel challenges and provides a pragmatic justification for treating the testimony of the marginalized as crucial diagnostic data. Their dissent is not just morally relevant but epistemically decisive: it is the localized signal of systemic friction, the bottom-up evidence that predicates are failing. Because emergence is contextual and instant, ignoring these signals accelerates collapse by blinding the network to the very updates it needs to survive.

### **3.2 A Note on Asymmetry and a Brief Case Study**

This framework predicts the vast asymmetry between the testing of empirical and moral predicates. An empirical predicate like “…boils at 100°C” is a hypothesis about a simple system with short, decisive feedback loops. A moral predicate like “…is unjust” is a hypothesis about structuring a complex adaptive social system, where feedback is diffuse, holistic, and unfolds over generations. This difference in velocity explains why moral knowledge is so much harder-won.

Consider the predicate “slavery is acceptable.” The pragmatic pushback was a slow-motion cascade of systemic failure, driven by the immense First-Order costs (violence, mortality, coercion) inflicted upon the enslaved. The primary epistemological signal came from the constant social friction these costs generated. This signal forced a diagnostic process, revealing secondary frictions: the logical incoherence of holding contradictory predicates (e.g., “all men are created equal”), the institutional brittleness of an oppressive economy, and the high Information Cost of suppressing dissent. The revision of the predicate was justified because it was the most coherent explanation for the system's primary frictions, and because the new predicate ('slavery is wrong') represented a more viable, lower-friction hypothesis for social organization.

### 3.3 The Scope and Operationalization of the Model

It must be stated clearly, in agreement with the sharpest critiques, that EPC does not offer a simple algorithm for producing a quantitative "viability score." The empirical project of assessing the total First-Order costs of a complex historical network is immense. The purpose of this framework is not to provide a final calculation but a diagnostic toolkit and a philosophical research program. It disciplines the analysis by identifying what we should be measuring, even if the measurement is difficult and comparative rather than absolute.

To move beyond a thought experiment, EPC points toward specific, objective criteria that can be investigated by historians, archaeologists, and economists. A research program for EPC would compare networks by tracking empirical signatures of systemic friction, including:

- **Demographic Indicators:** Comparing excess mortality rates, morbidity, population instability (e.g., collapse or mass flight), and bioarchaeological data (e.g., skeletal markers of malnutrition and violence) between societies organized around different core predicates.
- **Energetic & Economic Indicators:** Measuring the ratio of societal resources allocated to coercive apparatus (internal security, slave patrols, ideological enforcement) versus productive infrastructure (agriculture, trade, education). A network that must spend a vast and increasing share of its energy merely to suppress internal dissent is demonstrably inefficient.
- **Institutional Indicators:** Tracking the frequency of internal conflict, the stability of legal systems, and the costs of information suppression. A network requiring high "Information Costs"—by censoring dissent and punishing heretics—blinds itself to crucial feedback, a quantifiable vulnerability.

Crucially, these metrics are not cherry-picked to confirm a pre-existing moral intuition. They are the objective signatures any system struggling against the endurance filter will necessarily exhibit. For example, a comparative analysis of apartheid South Africa would reveal pathologies across all three categories: elevated mortality in townships, massive security expenditures that crippled the broader economy, and constant internal resistance requiring ever more costly suppression. The model's claim is falsifiable: if a society predicated on, for instance, "slavery is acceptable" could be shown to consistently exhibit greater long-term stability, lower coercive costs, and higher demographic resilience than more cooperative societies under comparable conditions, the EPC hypothesis would be severely damaged. The goal is not a perfect calculation, but a robust, evidence-based inference about a network's design viability.

## 4. The Architecture of Objectivity: A Methodological Account

The EPC model avoids simple relativism by demonstrating how a robust, fallibilist objectivity can emerge from a system of pragmatic selection. This section will detail that architecture. It is an account of objectivity grounded not in access to a final truth, but in a rigorous, public, and fallible methodology for inquiry, built upon the bottom-up, emergent hierarchy of contextually coherent networks that is the inevitable result of agents confronting a shared reality.

### 4.1 The Status of the Apex Network: An Objective, Emergent Fact

It is crucial to be precise about the ontological and epistemological status of this Apex Network. It is not a Platonic ideal to be discovered or a teleological endpoint of history. The EPC model posits it as an objective, emergent, historical fact—not a metaphysical essence. Given the model’s premises, countless networks are constantly being filtered by reality. It follows structurally—not teleologically—that at any given point there exists a maximal, coherent set of predicates that has, to date, best survived this process. The “Apex Network” is simply shorthand for this shifting, cumulative record of survival. It is not a destination or ideal form, but the running ledger of what has endured reality’s tests so far.

The challenge is purely epistemological. Our access to this real object is incomplete, mediated, and fallible. A more precise analogy is evolutionary fitness landscapes in biology. No biologist has direct access to the "optimal organism," yet the concept of fitness is objective and scientifically meaningful because we can measure its empirical signatures: reproductive success, survival rates, adaptation to environmental pressures. Similarly, the Apex Network's reality is demonstrated through measurable signatures: the systematic collapse of networks with high First-Order costs, the cross-cultural convergence on certain cooperative norms, and the predictable instability of systems that suppress dissent. Unlike the global economy (which we observe through market data), we access the Apex Network through historical data—the documented failures and successes of actual normative experiments conducted at civilizational scale. Similarly, the Apex Network is a real, causally significant object that we can only ever approximate by building fallible models based on its historical signatures—the wreckage of failed systems. This epistemic limitation does not render the object non-existent; on the contrary, its existence as an objective, albeit shifting, baseline is what grounds the possibility of making objective claims about pragmatic viability.

The Apex Network's epistemic accessibility increases through triangulation methodology. We cross-reference: (1) Archaeological evidence of civilizational collapse patterns, (2) Demographic data on mortality/morbidity rates across governance systems, (3) Economic historians' measurements of resource allocation efficiency, (4) Anthropological records of social coordination mechanisms. When predicates consistently correlate with objective failure signatures across these independent data streams, we have robust evidence of their distance from the Apex Network. This is not perfect knowledge but converging approximation—like using multiple instruments to locate a star.

### 4.2 The Methodology of Objective Inquiry: Charting the Wreckage

Our connection to this regulative ideal is purely methodological. The procedure is fundamentally negative and historical.

First is the Principle of Negative Universalism. Our most reliable knowledge is of failure. The project is not to positively define a utopia, but to build an evidence-based Negative Canon: a robust, cross-cultural catalogue of predicates (e.g., “slavery is acceptable”) that have been empirically demonstrated to generate catastrophic First-Order costs. Crucially, this record is built from the lived experience of those who bear those costs. Oppressed and marginalized individuals are not external to the system but constitutive parts of the shared network. Their dissent, suffering, and resistance provide the most sensitive diagnostic signals of systemic friction. Far from being erased, their webs of belief continuously contribute to the aggregate updates that revise the shared network.

Second is the Test of Independent Convergence under Varying Conditions, the primary tool for distinguishing a structural necessity from a contingent cultural artifact. This test moves beyond simply observing that successful societies share a trait; it actively seeks to falsify the hypothesis that the trait is a mere historical accident. The procedure involves identifying core predicates or functional norms and testing their recurrence across networks that have endured under maximally different environmental, technological, and historical conditions.

For example, the emergence of reciprocity norms in hunter-gatherer societies in arid deserts, agrarian societies in fertile river valleys, and maritime trading societies provides powerful evidence. The vastly different external conditions (geography, subsistence strategy, population density) make it highly improbable that the convergence on reciprocity is an accident. Instead, it suggests that reciprocity is a necessary, convergent solution to a universal set of coordination problems inherent in any enduring human social system. This test becomes more robust still when it aligns with formal models, such as game theory's demonstration that strategies like tit-for-tat are objectively superior for stabilizing cooperation in repeated interactions.

This methodology actively guards against "just-so" stories by demanding that we account for variance. If a predicate only appears in, for example, large-scale agrarian empires, we have reason to believe it is a contingent adaptation to that specific context, not a candidate for the Convergent Core. By systematically cross-referencing history, anthropology, and formal modeling, we build a case for a predicate's pragmatic necessity that is robust, evidence-based, and, crucially, falsifiable. The authority of such a predicate comes not from its presence in a single "winning" culture, but from its repeated discovery as a necessary solution to a universal coordination problem.

A critic might rightly argue that such convergence may merely reflect a contingent, shared human psychology. EPC fully accepts this, as it is irrelevant to the pragmatic project. The theory offers a model for building the most viable maps for the territory we actually inhabit, and that territory includes the unchangeable constraints of our own evolved psychology. EPC's naturalism lies in treating these evolved "givens" as the non-negotiable starting point.

The convergence test becomes more robust when we focus on functional solutions to universal coordination problems. That multiple isolated cultures develop reciprocity norms isn't mere psychological coincidence—it's repeated discovery of a mathematical necessity for stable cooperation. Game theory shows certain strategies are objectively superior for repeated interactions. Cultural convergence on these solutions is evidence of their logical necessity, not human bias.

The normative force of our inquiry thus comes not from a perfect, verifiable image of the destination, but from a trans-generational nautical chart pieced together from the records of countless failed voyages. We do not have a picture of the safe harbor, but the chart is littered with the records of shipwrecks. This is the essence of moral progress in EPC: the difficult, empirical process of adding to this shared chart of known failures.

To distinguish genuine pragmatic constraints from mere psychological bias, EPC employs a crucial filtering mechanism: the **Test of Functional Necessity**. This examines whether convergent norms solve specific coordination problems that any enduring social system must address, regardless of psychological makeup. For example, some form of reciprocity norm emerges across cultures not merely because humans happen to value fairness, but because groups lacking such norms face systematic collective action failures that threaten their persistence. The universality of incest taboos reflects not shared psychological quirks but the biological reality that inbreeding depression threatens group viability. These norms persist because they solve real, objective problems that any enduring system must address. Crucially, this test can distinguish between contingent human preferences (which vary widely) and structural requirements (which converge because reality constrains viable solutions).

### 4.3 The Structure of Objective Knowledge: The Core and Periphery

This architecture does not predict a single, uniquely correct answer for every moral question. Instead, it predicts a structured landscape: a “Convergent Core” of universally viable solutions surrounded by a “Pluralist Periphery” of multiple workable options. The Convergent Core is reached not only by dominant groups but through the continuous input of marginalized perspectives. Because oppressed individuals experience systemic friction most acutely, their networks often supply the decisive evidence that certain predicates (“slavery is acceptable,” “women are subordinate”) belong in the Negative Canon. Thus, convergence emerges from the bottom up, shaped by the whole population of interacting networks—not only the powerful. This structure is a direct consequence of the theory: convergence is expected where universal problems have a narrow range of viable solutions, while pluralism is expected where multiple, equally stable solutions exist.

It is crucial to note that the precise boundary between these zones is an ongoing empirical question, not an a priori declaration. The framework's strength is not in providing pre-ordained answers, but in offering a fallible, evidence-based procedure for discovering where objective constraints are tight and where they are loose. This distinction allows EPC to incorporate the insights of thinkers like Sam Harris while avoiding the pitfalls of a simplistic consequentialism. The concept of the Pluralist Periphery explains why there may be multiple, equally stable peaks on the moral landscape, allowing EPC to account for legitimate cultural disagreements without collapsing into relativism. What prevents relativism is precisely the negative filtering role of systemic failure signals—signals disproportionately supplied by those marginalized within a network. Their webs constrain which cultural variations are truly stable and which are simply subsidized failures waiting to collapse. In this way, dissent and oppression are not noise but epistemically privileged inputs into the shared, evolving chart of viable moral options.

## **5. Defending the Model: Four Critical Objections**

This section addresses some of the most pressing objections to the EPC model. Demonstrating the theory’s resilience against these challenges strengthens the case for its adoption as a viable framework for a naturalistic moral epistemology.

### **5.1 Objection: The Stability of Evil**

**Objection:** A technologically advanced, oppressive society endures for millennia. Hasn't its network "won" the pragmatic test, thereby making its oppressive predicates objectively true by EPC's standards?

**Reply:** This objection rests on two crucial errors: it mistakes mere endurance for pragmatic viability, and it misidentifies the unit of selection. First, the critic mistakes a dominant sub-network for the entire emergent social system. The "stable evil" society is not one coherent network; it is a system defined by the costly conflict between the oppressive network of the dominant group and the resistant networks of the subjugated. The predicates of the subjugated are an ineliminable part of the total emergent structure, and their persistent rejection of the dominant norms is the primary source of the system's friction.

Second, the objection underestimates pragmatic cost by conflating temporary stability with long-term viability. Historical analysis reveals that seemingly "stable" oppressive systems follow predictable decay patterns: (1) Escalating coercive costs as resistance adapts; (2) Information degradation as suppression blocks crucial feedback; (3) Institutional brittleness as adaptive capacity atrophies; (4) Elite defection as maintenance costs exceed benefits. The Roman Empire's slave system, medieval serfdom, and apartheid all exhibited these phases. Even when such systems endure for centuries, they demonstrate exactly what EPC predicts: networks requiring massive, ongoing energy expenditure to suppress their own internal contradictions are fundamentally unstable. Their "success" lies not in genuine viability but in temporarily accessing sufficient resources (through conquest, extraction, or technological advantage) to subsidize their core dysfunction. When those external subsidies disappear—as they inevitably do—the systems collapse rapidly, revealing their underlying fragility. In this sense, oppressive empires are not counterexamples to EPC, but paradigmatic confirmations: their longevity is not evidence of strength but of massive external subsidies spent to manage internal contradictions. Their collapse is not a surprise—it is the predictable endpoint of predicates that burn through resources to suppress dissent faster than they can generate resilience. In this sense, oppressive empires are not counterexamples to EPC, but paradigmatic confirmations: their very longevity demonstrates the staggering energy cost of maintaining predicates misaligned with reality. The "stable evil" society is "successful" only in its ability to extract the energy required to manage its own self-inflicted instability. This constant energy drain makes the system brittle and less adaptable to novel challenges. Its endurance does not make its predicates true; it merely makes it a long-running failed experiment whose wreckage we chart to build a better map.

### **5.2 Objection: The Power of Ideology**

**Objection:** Ideology can co-opt the revision process. A network can create "patch" predicates (e.g., “your suffering is a noble trial”) that convince agents to endure failure rather than revise the core of the network.

**Reply:** This objection correctly identifies a key tactic in the attrition between predicates. Yet ideological patches are never pragmatically free. They introduce cascading costs: not only second-order incoherence, but also measurable First-Order drains in the form of surveillance, propaganda, and coercion apparatuses. These patches create brittle systems that depend on constant inputs of energy to maintain illusions. EPC predicts that such networks can mask dysfunction in the short run, but at the price of compounding their long-term fragility. The very need for costly ideological insulation is itself an epistemic red flag: it signals predicates already misaligned with reality. While ideology can mask the *symptoms* of pragmatic pushback, it cannot eliminate the underlying dysfunction.

This highlights the theory's crucial short-term diagnostic force. While the ultimate filter is long-term, EPC provides an urgent, present-tense criterion: **we have a powerful pragmatic reason to be deeply skeptical of any network that requires costly ideological patches to function.** The presence of these defense mechanisms is a primary epistemological signal that the network's core predicates are misaligned with reality. It gives us a reason to listen to dissenters *now*, as they are the canaries in the coal mine of long-term systemic failure.

### **5.3 Objection: The Asymmetry of Testing**

**Objection:** The test for an empirical claim (“water boils at 100°C”) is immediate, while the test for a moral claim (“slavery is unacceptable”) is slow and contested. This asymmetry is so great that it renders the claim of a unified test meaningless.

**Reply:** This asymmetry is not a weakness of EPC but a direct prediction of it. The model posits a unified principle of justification—pragmatic viability—while fully acknowledging plural timescales and textures of testing. Simple physical systems yield rapid feedback; complex adaptive social systems yield slow, distributed signals across generations. What unifies them is not speed but filter: both are disciplined by reality’s unforgiving feedback. The lag in moral testing is exactly what the model expects, and explains why moral knowledge is harder won but no less objective. The nature of the pragmatic pushback is proportional to the complexity of the system being mapped. An empirical predicate about a simple physical system has short, decisive feedback loops. A moral predicate about structuring a complex adaptive social system has long, diffuse, and contested feedback loops that unfold over generations. This difference in velocity and texture explains why moral knowledge is so much harder-won, without undermining the unified framework.

### **5.4 Objection: The Grounding Problem in Three Forms**

The most fundamental challenge to EPC can be posed in three interconnected ways: **(a)** that the theory is circular, resting on a smuggled normative premise (the "drive to endure"); **(b)** that it still requires us to *care* about what survives, a normative commitment it cannot justify; and **(c)** that its deflationary truth severs the link between what is 'true' and what we 'ought' to do. These are all facets of the same grounding problem.

**Reply:** The EPC model answers all three facets of this objection with its explicit **descriptive and conditional turn**, as outlined in Section 1.1.

First, the model is not circular: it does not attempt to justify endurance normatively. Endurance is not a smuggled value but a transcendental condition of inquiry. A system that does not persist cannot evaluate, revise, or remember. Thus the “drive to endure” is not a moral claim within the game, but the constitutive rule of the game itself. We need not choose survival any more than we choose gravity; it is the brute filter through which all networks are already passing. EPC’s modest but powerful claim is simply this: if one is engaged in inquiry at all, one is already presupposing endurance. The system's anchor is not a value we choose, but a brute fact of selection we observe. We do not need to *value* survival for it to be the non-negotiable constraint, any more than we need to *value* gravity for it to determine which structures stand and which fall.

Second, this answers the question of why we should *care*. EPC's claim is conditional: *if* an agent or system has a de facto commitment to enduring, *then* EPC describes the process by which more viable strategies are discovered and encoded. The theory does not command this commitment; it simply describes the consequences for systems that have it versus those that do not.

Finally, this reconnects 'truth' and the pragmatic 'ought' through a purely instrumental and conditional logic. The theory does not make the normative claim that "what survives is what is good." It makes the descriptive claim that our most enduring networks are vast repositories of data on what has survived. The key insight is that the "drive to endure" is not a normative commitment we choose, but the constitutive constraint that makes normative inquiry possible at all. Just as formal logic presupposes the law of non-contradiction without deriving it from more basic premises, EPC identifies endurance as the transcendental condition that makes the evaluation of any normative system meaningful. A system that systematically undermines its own persistence cannot coherently evaluate anything, including alternative values like justice or beauty. Therefore, the normative force is conditional but non-arbitrary: if an agent engages in normative inquiry at all, then they are already presupposing the framework within which 'true' predicates (coherent with time-tested networks) provide the most rational pragmatic guidance. The "ought" is not a moral command, but a piece of evidence-based, strategic advice for a system that presupposes its own desire to endure.

#### 5.4.1 The Transcendental Status of Endurance

The authority of the endurance filter is thus physical, not moral. It is a constitutive background condition, analogous not to a chosen value like "justice," but to a physical constraint like gravity. An architect does not need to normatively value gravity to be bound by its rules; any design that ignores gravity is not a viable alternative, but simply a failure. Gravity is the non-negotiable filter through which all blueprints pass.

Similarly, EPC does not argue that one ought to value a system’s endurance. It makes the descriptive claim that persistence-over-time is the de facto selective filter for any information-bearing system, be it a genome, a species, or a network of predicates. A network that fails this filter does not lose a moral argument; it ceases to exist. The object of selection is the informational structure of the network itself. While this has consequences for the individuals within it, the primary filter acts on the viability of the shared code.

Therefore, to question endurance’s primacy is not to propose an alternative value, but to misunderstand the frame of inquiry. It is a pragmatic self-contradiction, as the act of questioning is performed by a system (an agent, a language, a culture) already engaged in the project of enduring through time. EPC’s claim is not circular because it doesn't justify endurance; it simply points out that it is the arena in which all justification takes place.


### 5.5 Objection: The Status of the Apex Network

**Objection:** The Apex Network is epistemologically problematic. As a standard that is fundamentally inaccessible, it is functionally equivalent to an unknowable Platonic form.

**Reply:** This objection conflates epistemology (our access) with ontology (what exists). EPC posits the Apex Network not as a metaphysical ideal but as a structural byproduct of reality’s filtering. Its existence is no more mysterious than the fact that, among countless organisms, some persist while others go extinct. Our access is partial and fallible, but this is the standard epistemic condition for studying any large-scale emergent system—ecosystems, economies, even the climate. That we cannot see the whole does not erase the object; it disciplines us to triangulate using convergent evidence from history, anthropology, and systems dynamics. Its existence is an inevitable structural consequence of the model's premises. The challenge is purely epistemological: our access to this real object is incomplete and fallible. However, this is the standard condition for inquiry into any large-scale emergent system, from an ecosystem to "the global economy." We cannot perceive these systems directly, but we can build and test fallible models of them.

The existence of the Apex Network is what grounds the possibility of making objective, truth-apt claims: a statement is objectively true if it is coherent with the Apex Network and objectively false if it is not. Our epistemic humility comes from acknowledging that we can never be 100% certain that our current map of this network is perfect. Our confidence in any truth claim is therefore proportional to the strength of our evidence—primarily, the long-term, cross-cultural data gathered via our "nautical chart" of failed systems. Our claim to objectivity rests not on a perfect vision of the safe harbor, but on the undeniable reality of the historical wreckage.


## **6. Situating the Model: A Unified Alternative**

Emergent Pragmatic Coherentism synthesizes insights from several traditions to occupy a unique position in the philosophical landscape. This section will situate the EPC model by contrasting it with major rival accounts in metaethics and epistemology, demonstrating its distinct advantages.

### **6.1 A Form of Procedural, Pragmatic Realism**

First, EPC is a form of realism without metaphysical mystery. It is realist in that it claims there are objective truths about which normative systems are superior—but unlike Non-Natural Realism, it grounds these truths in observable patterns of viability, not in positing sui generis moral properties. Unlike constructivist approaches, EPC does not rest on the coherence of our attitudes alone, but on their exposure to reality’s external filter. Its objectivity is therefore procedural: grounded in the evolutionary dynamics of pragmatic selection, not in metaphysical fiat or conceptual analysis. The truth-makers for moral claims are not mysterious, non-natural properties (as in Non-Natural Realism) nor are they reducible to an analysis of our moral concepts (as in Michael Smith's analytic realism). Rather, the truth-makers are the objective, empirical facts about which networks prove most viable against the real-world constraints of pragmatic selection. The validity of a moral predicate is thus an emergent, relational property, much as the ‘fitness’ of an organism is a real, objective property of its relationship with an environment. To put it plainly: 'truth' is a property internal to a network’s coherence, while **viability** is an objective property of that network’s external relationship with reality.

This specific type of procedural realism places EPC firmly within the tradition of **pragmatic naturalism**. It distinguishes itself, however, by providing a more rigorous philosophical architecture with three distinct contributions: (1) a formal emergent structure (the **nested hierarchy of networks**); (2) a causal, rather than purely normative, filter (the **hierarchy of pragmatic costs**); and (3) a naturalistic basis for fallibilist objectivity (the **Apex Network**). The necessity for such a rigorous architecture is vividly illustrated by the philosophical dead ends encountered by more intuitive, "folk" versions of pragmatic naturalism, which often struggle to escape relativism without a formal model of procedural objectivity.

### **6.2 A Completion of the Quinean Project**

Second, the EPC framework should be understood as the systematic completion of the **Quinean project**, itself a direct heir to **American Pragmatism**. Quine’s demolition of the analytic/synthetic distinction unified all descriptive claims within a single pragmatic web. EPC extends this holism one decisive step further: it shows that normative claims are subject to the same filtering process. Where Quine mapped the static architecture of an individual’s web of belief, EPC identifies the dynamic, bottom-up mechanism that evolves these webs into shared networks and continuously revises them under pragmatic pushback. In doing so, it completes the Quinean project by dissolving the last firewall—between fact and value—without resorting to metaphysical shortcuts. It inherits Quine’s core commitments—fallibilism, pragmatism, and the rejection of a priori firewalls—but where Quine described the static architecture of an individual’s web, EPC identifies the missing piece: the **dynamic, evolutionary engine** of pragmatic selection. It fulfills John Dewey’s project of dissolving dualisms and provides a naturalistic answer to C.S. Peirce’s “end of inquiry”: the Apex Network is not an ideal limit, but the messy, emergent result of what has *actually survived* our collective experiment. This realism distinguishes EPC from the anti-representationalism of neopragmatists like Richard Rorty. Where Rorty replaces objectivity with solidarity, EPC argues that lasting solidarity is an **emergent property** of a network that has achieved objective pragmatic success.

This synthesis of holism and evolution also distinguishes EPC from other non-foundationalist epistemologies. Unlike **Foundherentism** (Haack 1993), EPC posits a more ruthless, eliminative filter: pragmatic viability, not mere mutual support. And while it shares a language with **Network Epistemology**, its focus is on the **diachronic, evolutionary dynamics** that forge and destroy networks, not on the static analysis of belief-linkages.

### **6.3 A Realist Alternative to Constructivism and Expressivism**

Finally, while EPC shares constructivism’s insight that moral systems are human-built, it departs decisively by locating validity not in coherence alone but in long-term viability under reality’s pressures. Unlike constructivism, it does not stop at “we built it, therefore it binds us”; instead, it subjects constructions to elimination by pragmatic selection. Similarly, unlike expressivism, EPC does not reduce normative claims to projections of sentiment; it explains why some sentiments propagate and stabilize while others collapse. EPC therefore offers a realist account of moral objectivity that is both stance-independent and naturalistic: truths about norms are emergent properties of which networks survive, not of how we feel about them.

It avoids the pitfalls of some forms of **Evolutionary Ethics** that attempt to derive normative content directly from our evolved psychological dispositions. EPC makes no such direct derivation; the test of a predicate is not its origin, but its long-term performance. This also distinguishes it from **Norm-Expressivism** (Gibbard 1990). While Gibbard provides a brilliant naturalistic account of the psychological function of normative language, EPC offers a theory of how these normative systems are themselves subject to an objective, external, mind-independent selective pressure. It can explain not just why we have norms, but why some normative systems fail.

This externalism is also what distinguishes EPC from a more conventional **Constructivism**. A purely constructivist theory, whether Kantian or Humean, ultimately grounds normativity in the coherence of our own attitudes. This is most clearly articulated in the constitutivism of thinkers like Christine Korsgaard, who grounds normativity in the self-reflective structure of rational agency. For EPC, this internal coherence is insufficient. The ultimate arbiter of a network's validity is not its internal logical structure but its **external relationship with the selective pressures of reality.**

This provides EPC's definitive answer to Sharon Street's "ideally coherent Caligula." A constructivist might struggle to condemn Caligula if his monstrous attitudes are perfectly coherent. For EPC, Caligula's internal coherence is irrelevant. The network that produced and sustained such a predicate was an **objective, pragmatic, evolutionary failure**, judged not by our disapproval, but by the immense, real-world systemic friction it generated. This stance-independence is what makes the theory a form of realism and allows it to suggest that the ingenious project of **quasi-realism** (Blackburn 1993) is a brilliant solution to a problem that a more sophisticated, realist-compatible epistemology like EPC dissolves from the outset.

### 6.4 The Dynamics of Moral Innovation

EPC privileges neither tradition nor novelty but demonstrated functionality. Established norms have no intrinsic authority; they persist only if they continue to pass reality’s filter. Moral innovations face the same test: many fail, but those that resolve entrenched systemic friction spread and stabilize. Abolitionism, for example, succeeded not because it was sentimentally compelling but because it alleviated immense First-Order costs that slavery generated. EPC therefore captures both conservatism and revolution within a single logic: every predicate, old or new, must prove its viability against the same bottom-up, pragmatic selection process. Abolitionism initially appeared 'untested' but succeeded because slavery generated massive First-Order costs that abolition resolved. The framework's bias isn't toward tradition but toward demonstrated functionality. Revolutionary moral insights that reduce systemic friction will, by definition, propagate and become part of the Apex Network.


## **7. Conclusion: Inquiry as a Pragmatic Project**

Emergent Pragmatic Coherentism ultimately argues that **morality is a project, not a given.** It offers a descriptive model of all inquiry—scientific, political, and ethical—as part of the same fundamental human endeavor: the multi-generational effort to construct the most viable maps for navigating our shared existence. On this view, an "is" is a predicate about how the world appears to function, and an "ought" is a time-tested predicate about how best to act within it. Both are adjudicated in the same ultimate court of long-term pragmatic selection.

This framework is not a solution to the ultimate philosophical problem of grounding normativity. Instead, by taking a descriptive turn, it provides a powerful, naturalistic model for a form of **procedural objectivity**. It allows us to be both **humble and hopeful.** We are humble in knowing that our current maps are imperfect and that our access to the lessons of history is fallible. Yet we can be hopeful, because moral progress is a real, observable phenomenon. We can state with confidence that abolishing slavery was not a mere change of opinion; it was a profound act of **debugging our societal code**. It was the identification and removal of a predicate from our **Negative Canon** of demonstrably failed systems.

Progress occurs when we treat suffering, dissent, and instability not as mere political problems to be managed, but as **primary epistemological data**—the "check engine" light for society. This gives us a powerful, pragmatic reason to listen to the marginalized, as they possess the most crucial information about where our collective map is wrong.

The authority of an “ought” is therefore not found in a metaphysical foundation or the structure of rational agency. It is located in the immense, objective, and procedural weight of the lessons we have collectively learned from what has, and has not, survived our species’ long and often brutal encounter with reality. An "ought," on this view, is simply a predicate that is 'true' within our most pragmatically resilient network—a hard-won empirical signal that it is a viable strategy for the shared, enduring project of human cooperation.

The conditionality isn't a weakness but a methodological strength. By explicitly bracketing ultimate metaphysical questions, EPC provides what philosophy most needs: a research program rather than dogma. Whether one is a Kantian, utilitarian, or virtue ethicist, all must confront the empirical question: do the systems advocated by their theory actually work? EPC does not deliver final answers, but it does provide the conceptual and methodological tools for approaching that question with greater objectivity. It reframes moral philosophy from the search for ultimate foundations to the ongoing, fallible craft of building the best maps we can from the wreckage of failed systems.

---

### **References**

Blackburn, Simon. *Essays in Quasi-Realism*. Oxford University Press, 1993.

Dewey, John. *The Quest for Certainty: A Study of the Relation of Knowledge and Action*. Minton, Balch & Company, 1929.

Haack, Susan. *Evidence and Inquiry: A Pragmatist Reconstruction of Epistemology*. 2nd ed. Prometheus Books, 2009.

Harris, Sam. *The Moral Landscape: How Science Can Determine Human Values*. Free Press, 2010.

James, William. *Pragmatism: A New Name for Some Old Ways of Thinking*. Longmans, Green, and Co., 1907.

Joyce, Richard. *The Evolution of Morality*. MIT Press, 2006.

Kitcher, Philip. *The Ethical Project*. Harvard University Press, 2011.

Korsgaard, Christine. *The Sources of Normativity*. Cambridge University Press, 1996.

O’Connor, Alex (CosmicSkeptic). “Why Ethics Are Subjective - Destiny” *YouTube*, May 29, 2021. Video, 1:17:34. https://www.youtube.com/watch?v=Izg97iGcTk4.

O'Connor, Cailin. *The Origins of Unfairness: Social Categories and Institutional Inertia*. Oxford University Press, 2019.

Peirce, Charles Sanders. “How to Make Our Ideas Clear.” *Popular Science Monthly* 12 (January 1878): 286–302.

Putnam, Hilary. *The Collapse of the Fact/Value Dichotomy and Other Essays*. Harvard University Press, 2002.

Quine, W.V.O. “Two Dogmas of Empiricism.” *The Philosophical Review* 60, no. 1 (1951): 20–43.

Quine, W.V.O. *Word and Object*. MIT Press, 1960.

Rorty, Richard. *Contingency, Irony, and Solidarity*. Cambridge University Press, 1989.

Sellars, Wilfrid. *Empiricism and the Philosophy of Mind*. Harvard University Press, 1997.

Street, Sharon. “A Darwinian Dilemma for Realist Theories of Value.” *Philosophical Studies* 127, no. 1 (2006): 109–66.