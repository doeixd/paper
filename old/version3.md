# **Extending Quine's Web: A Procedural and Naturalistic Model of Moral Objectivity**

## **Abstract**

The is/ought problem, this paper argues, is not a metaphysical chasm to be bridged but an artifact of foundationalist epistemology. To reframe it, this paper develops **Emergent Pragmatic Coherentism (EPC)**, a descriptive model of moral knowledge. Building on Quine’s holism, EPC models all knowledge as an emergent hierarchy of shared “networks of predicates.” This social-epistemic architecture scales from the individual’s “web of belief” to encompass entire traditions of inquiry. Within this architecture, truth is treated deflationarily as a functional label for robust coherence within a pragmatically-tested network. This network-relative conception of truth is simultaneously disciplined by an external selective filter—evolutionary pragmatic selection—where the ultimate metric is not mere persistence but **pragmatic viability**: a system's homeostatic efficiency in propagating its structure with minimal coercive cost. Networks incurring high systemic costs collapse over time, while efficient, resilient networks propagate. This process grounds a form of procedural objectivity: while truth is a property internal to a network, networks themselves can be objectively ranked by their long-term viability. The ultimate regulative standard is the Apex Network—a theoretical model of a real, emergent historical object representing the cumulative record of predicates that have proven most viable. EPC’s central claim is conditional: if we begin from minimal naturalism, where endurance is a non-negotiable constraint, then EPC provides a robust account of moral progress. It locates normative authority not in metaphysical fiat or non-cognitive attitudes, but in the empirical lessons encoded in humanity’s most resilient social and epistemic structures.

## **1. Introduction: Reframing the Is/Ought Problem as a System's Challenge**

For centuries, philosophy has treated the gap between claims of fact (“is”) and claims of value (“ought”) as a fundamental chasm in our conceptual landscape. This paper argues that the infamous is/ought problem is not a foundational feature of reality but a symptom of foundationalist epistemology, which artificially segregates descriptive and normative claims. The solution proposed here is not to build another speculative bridge across the gap, but to adopt an epistemology where no such gap arises in the first place—a unified system that adjudicates all claims in the same **evolutionary court of pragmatic selection**.

While EPC proposes a unified model of justification applicable to all domains of inquiry, this paper will test its viability against its most challenging application: the fact/value distinction. In this, it applies the methodological spirit of W.V.O. Quine’s attack on the analytic/synthetic distinction. By treating claims like “water boils at 100°C” and “murder is wrong” as formally commensurable ‘predicates’ within a single holistic framework, we can see that they are tested by the same unforgiving filter: the feedback of reality. The authority of an “ought” emerges not from a mysterious normative realm, but from the hard-won, survival-tested coherence of our best maps of the world.

To realize this Quinean ambition, this paper defends a framework formally titled **Emergent Pragmatic Coherentism (EPC)**. At its core, EPC is a systematic extrapolation of Quinean holism. It begins with the premise that individuals navigate reality using a fallible “web of belief” (Quine 1951). Because all agents face shared constraints, their individual webs are forced to overlap where pragmatically successful, giving rise to an emergent hierarchy of shared networks. A claim is 'true' in a deflationary sense if it is coherent within a given network. This initial relativity, however, is not the final word. It is disciplined by an external filter of evolutionary pragmatic selection, which grounds a form of procedural objectivity. Networks generating high degrees of systemic friction prove less viable and are abandoned over time, allowing for an objective ranking of networks based on their long-term pragmatic success. The ultimate regulative standard for this process is the Apex Network—a theoretical model of the real, emergent object that is the sum of humanity's historically successful predicates.

### **1.1 The Status of the Project: A Conditional and Descriptive Turn**

It is essential to be precise about the scope of this project. EPC does not claim to solve the ultimate problem of grounding normativity, nor does it provide a non-circular answer to the question, “Why value survival?” Instead, it takes a descriptive and conditional turn. Its central claim is this: **if one begins from a minimal naturalism where endurance is a de facto constraint on any system, *then* EPC provides a robust model of procedural objectivity and moral progress.**

This paper does not defend the initial ‘if’—a task for a different metaethical project—but rather demonstrates the explanatory power of the ‘then’. Its ambition is not to prove that we *ought* to play this game, but to provide the first systematic description of the rules of the game we are already playing. It shifts the focus from a futile search for metaphysical foundations to the construction of a testable model of the evolutionary process by which values are filtered, retained, and come to have authority. It describes the court of pragmatic selection; it does not attempt to justify that court’s ultimate jurisdiction.

### **1.2 Truth, Viability, and the Pragmatic 'Ought'**

Within this descriptive framework, why should a 'true' predicate—one that is merely coherent with a successful network—have any normative force? The answer lies in the network's evolutionary origin. A shared network is not a logic puzzle; it is a tool for navigating reality forged in the crucible of history. The descriptive fact that a predicate is 'true' within one of our most time-tested networks is therefore a powerful empirical signal: it indicates that the predicate is an integral component of a highly viable strategy.

This reconnects the 'is' and the 'ought' procedurally. The “is” of a predicate’s truth-value serves as a reliable guide to the pragmatic “ought,” precisely because that network’s coherence was itself forged by the unforgiving “is” of reality’s feedback. To trust what is 'true' in our best networks is therefore not an appeal to metaphysical correspondence, but a **pragmatic wager**: the hard-won lessons of history are more reliable guides than our untested intuitions.

The argument constructs the EPC architecture in three stages: it first details the emergence of shared networks from individual webs (Section 2), then defines the evolutionary engine of pragmatic viability that selects among them (Section 3), and finally outlines the negative, empirical methodology for approximating the resulting objectivity (Section 4). With the model fully articulated, it will be defended against critical objections (Section 5) and situated within the contemporary philosophical landscape (Section 6).

## **2. The Architecture of Emergence: From Individual Webs to Shared Networks**

Emergent Pragmatic Coherentism begins not with a novel invention but with a systematic extrapolation of Quinean holism, extending it from an individual, psychological model to a social epistemology. The architecture rests on two basic premises:

1.  Every individual agent navigates the world using their own Quinean web of beliefs.
2.  Every individual agent is subject to the pragmatic constraints of a shared reality.

From these premises, a third fact follows with structural necessity: wherever agents successfully interact with reality, their individual webs are forced to overlap. This intersection is not a conscious negotiation or a top-down agreement, but an automatic, bottom-up emergence. When two people build a canoe, each recalibrates their own web in light of material constraints (buoyancy, wood strength) and the demands of cooperation. Their individual adjustments converge, producing a shared, functional network of beliefs. Crucially, this network cannot drift arbitrarily; only those recalibrations that succeed under the external constraints of reality persist. This eliminative pressure grounds the network’s objectivity, a process that scales dynamically across all levels of social organization, from scientific communities to legal systems.

This scaling from simple cooperation to complex social systems requires a more formal analytic tool. To that end, EPC makes a crucial shift from the psychological language of a "web of belief" to the more formal concept of a **“network of predicates.”** A predicate is the logical structure of a claim that says something about a subject—for instance, the propositional content of “…is wrong,” “…boils at 100°C,” or “…is a viable social strategy.” This is more than a semantic tweak; this move is vital for three reasons.

First, it shifts the analysis **from the private and mental to the shared and structural.** We are no longer describing an individual’s internal cognitive state, but the public architecture of our collective knowledge, which exists in our language and practices.

Second, it makes the **formal commensurability of all claims explicit.** By treating “…is wrong” and “…boils at 100°C” as the same type of formal object—a predicate being applied to a subject—we dissolve the artificial barrier between fact and value at the most basic level of analysis, preparing the ground for a unified test of viability.

Third, and most crucially, it **operationalizes the paper's deflationary, coherentist account of truth.** On this view, 'truth' is not a claim of correspondence with a noumenal reality, but a functional label. It is a relational property that signifies a predicate's robust coherence within a specified network—a network that has itself been forged by the emergent process of pragmatic selection. A predicate is therefore 'true' *relative to* a network, and its truth-value can change the moment that network is pragmatically revised in response to friction. This context-sensitive dynamism, far from being a concession to simple relativism, is the conceptual ground for EPC’s account of procedural objectivity, which emerges from the convergent survival of networks forged in the bottom-up crucible of shared reality.

## **3. The Engine of Selection: Pragmatic Viability**

What prevents the emergent networks described in Section 2 from being arbitrary, self-justifying constructs is the relentless filter of evolutionary pragmatic selection. This selection process acts upon the network's **informational structure**, which is tested through its physical instantiation in a society's institutions, laws, and norms. A network ultimately fails when the **First-Order Costs** of maintaining its core institutions—through coercion and ideological repair—exceed the society’s capacity to pay them, leading to systemic collapse or radical transformation.

This model is anchored not by a chosen value but by a minimal, constitutive precondition: the **‘drive to endure,’** defined as the persistence of a system's structure and core information over time. This drive's authority is physical, not moral; it is a background condition analogous to gravity. An architect need not normatively *value* gravity to be bound by its rules; any design that ignores it is not a viable alternative but simply a failure. Similarly, endurance is the non-negotiable filter through which all informational blueprints must pass. For an informational system to propagate to a new generation, it requires a substrate of adherents who survive. A network whose highest stated value is glorious death in battle must still rely on a set of unstated pragmatic predicates concerning health, social cohesion, and resource management to maintain the stability required to transmit its code. Endurance is thus the ultimate selective filter for the systems themselves.

Crucially, the selective criterion this filter uses is not mere persistence but **pragmatic viability**. This is a measure of a system's *homeostatic efficiency*: its ability to maintain stability and propagate its informational structure over time with low internal friction and minimal energy expenditure on coercion. A system that persists for millennia by burning immense energy to suppress dissent is *enduring* but not *viable*. It is a high-cost, inefficient system whose apparent stability masks a profound normative brittleness.

By contrast, a viable network maintains stability through lower-cost mechanisms like voluntary coordination. The preference for low coercion is not a smuggled moral value but a conclusion from systems dynamics. High-coercion systems are **energetically inefficient**, burning a vast portion of their resources on internal control rather than productive adaptation. They are also **informationally fragile**, as coercion requires suppressing dissent—the primary data stream signaling systemic flaws. A network that must pay immense energetic and informational costs to maintain its structure is, by definition, less resilient to external shocks than a more efficient one. This distinction grounds the model’s defense against simplistic “might makes right” in a descriptive claim about systemic efficiency, not a normative one about the evils of coercion.

### **3.1 A Hierarchy of Pragmatic Costs**

To ground the analysis of viability in a non-circular metric, EPC specifies a causal hierarchy of costs.

-   **First-Order Costs:** These are the direct, material signatures of a network's conflict with the drive to endure. They can be identified through objective metrics: elevated mortality rates, systemic violence, resource depletion, and the immense energy expenditure required for mass coercion. These are not abstract "harms" but the measurable, physical consequences of a system generating friction against the biological reality of its agents.
-   **Second-Order Costs:** These are more abstract, ideologically-framed costs contingent on a particular sub-network's survival, such as threats to a cultural identity or an economic model.

The central principle is that **First-Order costs have causal and diagnostic priority.** This is not a normative claim about which forms of suffering matter more; it is a descriptive, systems-dynamic claim about what makes a network unstable. A network that must constantly pay immense First-Order costs to shield itself from potential Second-Order costs is demonstrating a critical design flaw. This dynamic creates a fatal feedback loop termed **Information Cost**: by systematically suppressing the dissent of those experiencing the most intense First-Order costs, a network blinds itself to the most critical data signaling its own failures. This self-induced epistemic fragility makes the network profoundly vulnerable. It thus provides a purely pragmatic, systems-dynamic justification for the central claim of standpoint epistemology: the testimony of the marginalized is treated as epistemically privileged data not from a moral imperative, but because those at the points of greatest systemic friction have the most direct access to the data signaling a network’s impending failure (Dular 2024).

### **3.2 Case Study and Causal Attribution**

To illustrate the EPC method, consider the predicate “slavery is acceptable.” This is not offered as a simplistic causal proof but as an example of a testable hypothesis EPC would generate. The hypothesis is that networks predicated on chattel slavery will, due to their inherent structure, reliably produce specific, measurable signatures of normative brittleness. An EPC-guided research program would seek to verify this by quantifying: (1) the immense **First-Order Costs** (excess mortality, systemic violence) borne by the enslaved (Patterson 1982); (2) the massive **Systemic Costs** of the coercive apparatus required to manage the inevitable pragmatic pushback, diverting resources from productive adaptation (North 1961); and (3) the crippling **Information Cost** incurred by suppressing the data that signaled these dysfunctions. The argument is not that slavery was the *sole* cause of any specific collapse, but that it predictably imposes these systemic burdens, rendering any network that relies on it inherently less viable than alternatives. Abolition represents the historical triumph of a predicate that offered a more homeostatically efficient model for social organization.

However, a critic might argue that isolating the causal effect of a single predicate from the "historical noise" of famines, plagues, or invasions is impossible. A cooperative society might be destroyed by a volcano, while a brutal empire persists. How can EPC reliably attribute failure to a network's design rather than to historical bad luck?

The solution lies not in denying contingency but in analyzing it through a comparative methodology focused on what EPC terms **normative brittleness**: a network's inherent vulnerability to external shocks, caused by high internal friction. EPC predicts that networks with high internal friction (high First-Order and coercive costs) are inherently more brittle and less adaptable to external shocks. A high-cost network expends its energy on internal control, leaving fewer surplus resources to adapt to novel threats. The EPC research program would therefore proceed by identifying patterns across multiple historical case studies to build a robust, evidence-based inference, as is done in fields like epidemiology or cliodynamics (Tainter 1988; Turchin 2003).

This method seeks to identify **Historical Paired Cases**: instances where societies with different normative structures faced a similar external shock. EPC predicts a statistically significant pattern: the more pragmatically viable (i.e., lower-friction) network will be more likely to adapt successfully, while the less viable network will be more likely to collapse. The external shock acts as a "stress test" that reveals the underlying fragility caused by the network's informational structure. The goal is not to prove that a predicate was the *sole* cause of collapse, but to establish a robust correlation: that networks organized around it consistently and predictably exhibit higher normative brittleness than comparable networks organized around alternatives. The model does not offer a deterministic account of history; it offers a **probabilistic theory of systemic risk**. A network with high normative brittleness is not fated to collapse on a specific timeline, just as a poorly built ship is not fated to sink on its next voyage. However, its design makes it statistically less likely to survive the inevitable storms of historical contingency.

### **3.3 Operationalizing Viability: A Methodological Sketch**

A valid objection is that concepts like "energetic cost" and "informational fragility" risk remaining vague abstractions. To be a testable model, EPC must point toward measurable proxies. This section provides a non-exhaustive sketch of how a research program could operationalize these metrics for comparative analysis. The goal is not a simple "viability score" but a dashboard of indicators to assess normative brittleness.

1.  **Measuring Energetic Cost:** This can be approximated by tracking the allocation of a society's key resources. Proxies include:
    -   **Fiscal Ratio:** The proportion of state budget or GDP dedicated to internal security, surveillance, and penal systems versus productive infrastructure like education, healthcare, and technology.
    -   **Labor Allocation:** The percentage of the population engaged in non-productive coercive roles (e.g., secret police, ideological enforcers) rather than productive labor.
    -   **Resource Depletion Rates:** Comparing rates of environmental degradation or resource exhaustion against the society's capacity for innovation and renewal.
2.  **Measuring Informational Fragility:** This can be assessed by quantifying the costs of suppressing feedback. Proxies include:
    -   **Legal-Institutional Indicators:** The existence and enforcement severity of laws criminalizing dissent, blasphemy, or "subversive" speech. A high number of political prisoners is a direct indicator.
    -   **Social Trust Metrics:** Using survey data and historical records to track levels of interpersonal and institutional trust. High-coercion networks predictably exhibit low social trust, which acts as a major drag on economic and social coordination.
    -   **Innovation Lag:** Tracking the lag between the emergence of critical new knowledge (scientific, social, or technological) outside the society and its adoption within it. The suppression of genetics in the Soviet Union under Lysenkoism, for example, represents a quantifiable informational cost with catastrophic agricultural consequences.

While no single metric is decisive, a consistent pattern across these indicators would provide strong, evidence-based grounds for diagnosing a network's low pragmatic viability.

## **4. The Architecture of Objectivity: Mapping a Real Landscape**

Emergent Pragmatic Coherentism avoids relativism not by positing access to a transcendent truth, but by grounding objectivity in a rigorous, fallible, and public methodology. This section details that architecture. To begin, we must resolve an apparent tension: if truth is coherence within a network, how can we make objective claims that transcend any single network?

The resolution lies in a two-level account of truth. A predicate like “slavery is acceptable” may possess *contextual truth* within the dominant sub-network of a functioning slave society. However, when we make objective moral claims, we are implicitly appealing to a higher standard. From the wider, evidence-based perspective of the historical record, that predicate is *objectively false*. Its falsehood is grounded not in a metaphysical fiat, but in the robust, empirical conclusion that networks predicated on it are pragmatically unviable, consistently collapsing under the weight of their own catastrophic First-Order costs.

### **4.1 The Apex Network: A Model of a Real Object**

The ultimate standard for this objective ranking is the Apex Network. To defend this concept against the charge that it is merely an unknowable Platonic Form, we must be precise about its status. The Apex Network is best understood as **a theoretical model of a real, mind-independent, and emergent historical object.**

First, we must establish why such an object must necessarily exist as a structural fact, given the model's premises. Because countless individual webs are constantly being filtered by the pragmatic constraints of a shared reality, their forced convergence creates a maximal, coherent, and shared set of pragmatically successful predicates. This emergent, time-tested informational structure—forged in the crucible of humanity’s collective, filtered experience—is the *real object* being modeled. Its ontological status is that of a real, complex system, like an ecosystem or the global economy: it exists and exerts causal pressure whether or not we map it perfectly.

Our access to this real object is never direct. Instead, we construct the *Apex Network* as a fallible, scientific **model** of it. This distinction is what saves the concept from being an unfalsifiable abstraction. The model is not an article of faith but a scientific instrument judged by its **predictive and explanatory power**. Specifically, our current model of the Apex Network generates testable predictions about which novel social arrangements are likely to be brittle. For example, a model informed by the consistent failure of totalitarian systems (our Negative Canon) would predict that a new political arrangement reliant on total information control will exhibit high systemic costs and be vulnerable to collapse. If historical or future events contradict this—if such a system proves highly efficient and resilient—then our model of the Apex Network is **falsified** and must be revised. A predicate is **epistemically justified** for us if it is coherent with our current, best-tested model. A predicate is **objectively true** if it is coherent with the real, emergent object. Moral progress is the process of improving our model by rigorously testing it against the historical record.

### **4.2 A Negative and Comparative Methodology**

Our connection to this standard is purely methodological, grounded in an epistemology that is fundamentally negative and empirical. An accurate analogy is not a satellite image of a safe harbor, but a **trans-generational nautical chart pieced together from the records of countless failed voyages.** We learn the principles of viable design primarily by studying the wreckage. This methodology proceeds via two main principles:

1.  **The Principle of Negative Universalism:** Our most reliable knowledge is of failure (Popper 1959). The project is to build an evidence-based **Negative Canon**: a robust, cross-cultural catalogue of predicates empirically demonstrated to generate catastrophic First-Order costs and produce normative brittleness. Predicates like “slavery is acceptable” or “genocide is a valid political tool” belong in this canon.
2.  **The Test of Independent Convergence:** To identify candidates for the positive **Convergent Core** while guarding against survivorship bias, this test distinguishes structural necessity from cultural accident. It identifies core functional norms (e.g., reciprocity) that have emerged independently across networks under maximally different historical and environmental conditions. This convergence suggests not mere psychological coincidence but the repeated discovery of game-theoretically stable solutions to universal coordination problems, a finding reinforced by formal models of cooperation (Axelrod 1984).

This methodology predicts a structured landscape of moral knowledge: a **Convergent Core** of universally viable predicates surrounded by a **Pluralist Periphery** of multiple, culturally-specific yet workable solutions. The boundary is an empirical question, not an a priori declaration. The Convergent Core includes predicates that solve universal coordination problems with a narrow range of viable solutions. The Pluralist Periphery accounts for legitimate cultural disagreements—such as between different but stable models of political economy—where multiple, equally viable solutions exist. It allows the theory to account for deep, persistent disagreements without collapsing into relativism, because the entire periphery is still bounded by the hard constraints revealed by the Negative Canon.

## **5. Defending the Model: Four Critical Objections**

This section addresses four of the most pressing objections to Emergent Pragmatic Coherentism. The model’s resilience against these challenges strengthens the case for its adoption as a robust naturalistic framework.

### **5.1 Objection: The Stability of Evil**

*Objection:* An oppressive society, perhaps technologically advanced, endures for millennia. Hasn't its network "won" the pragmatic test, thereby making its oppressive predicates objectively true by EPC's standards?

*Reply:* This objection rests on two errors: it mistakes mere endurance for the richer concept of **pragmatic viability**, and it misidentifies the unit of selection.

First, the "stable evil" society is not one coherent network; it is a system defined by the costly conflict between the oppressive network of the dominant group and the resistant networks of the subjugated. The predicates of the oppressed are an ineliminable part of the total emergent structure, and their persistent dissent is the primary source of the system's friction.

Second, the objection conflates temporary stability with long-term viability. As defined in Section 3, viability is a measure of homeostatic efficiency. An oppressive state that persists through immense coercion is not viable; it is a high-cost, inefficient system. Its longevity is not a sign of strength but a measure of the immense energy it must burn to manage its own self-inflicted instability. Such systems are often functionally parasitic, their endurance subsidized by external extraction (e.g., conquest or resource windfalls) that masks their internal normative decay. Historical analysis reveals that such systems follow predictable decay patterns: escalating coercive costs, information degradation, and institutional brittleness. Their endurance does not make their predicates true; it merely makes them long-running failed experiments whose wreckage we chart to build a better map.

### **5.2 Objection: The Power of Ideology**

*Objection:* Ideology can co-opt the revision process. A network can create "patch" predicates (e.g., “your suffering is a noble trial”) that convince agents to endure failure rather than revise the network's core.

*Reply:* Ideological patches are never pragmatically free. They introduce cascading costs, not only in second-order incoherence but also in the measurable First-Order drains of surveillance, propaganda, and enforcement. While ideology can mask the *symptoms* of pragmatic pushback, it cannot eliminate the underlying dysfunction. Crucially, the very need for costly ideological insulation is itself an epistemic red flag. It provides an urgent, present-tense diagnostic criterion: **we have a powerful pragmatic reason to be deeply skeptical of any network that requires immense energy expenditure to suppress dissent and explain away suffering.** The presence of these defense mechanisms is a primary epistemological signal that the network’s core predicates are misaligned with reality, giving us a reason to heed dissenters *now* as they are the canaries in the coal mine of long-term systemic failure.

### **5.3 Objection: The Grounding Problem**

*Objection:* The theory is circular. It rests on a smuggled normative premise—the value of endurance—and cannot justify why we ought to care about what survives its pragmatic filter.

*Reply:* This objection is well-founded and targets the core of the project. The resolution lies in being ruthlessly consistent with the paper’s **descriptive and conditional turn** (1.1). EPC does not derive a moral “ought” from a descriptive “is.” Rather, it makes a purely descriptive, causal claim about systems dynamics and then formulates an instrumental, hypothetical recommendation.

The descriptive claim is: “Networks organized around predicate X consistently exhibit high First-Order Costs, information blockage, and normative brittleness, leading to a higher probability of collapse under stress.” This is an empirical, falsifiable hypothesis about the world.

The recommendation that follows is not a moral imperative but a **strategic one**: “*If* a system’s goal is to persist, *then* it has a powerful pragmatic reason to avoid predicate X.” The “ought” here is no more mysterious than the “ought” in the statement, “If you want to live, you ought not drink poison.” The gravitational analogy is useful only if understood this way: an architect who ignores gravity does not violate a moral duty, but they do guarantee their project’s failure. EPC’s claim is that history provides an accumulating record of such design failures. The model’s authority is not prescriptive; it is diagnostic. It does not tell us we *must* value survival, but it does claim to identify the structural principles that lead to collapse for any system that *does* operate under that de facto constraint.

### **5.4 Objection: The Inaccessibility of the Apex Network**

*Objection:* The Apex Network is epistemologically problematic. As a standard that is fundamentally inaccessible, it is functionally equivalent to an unknowable Platonic Form or Kantian noumenon. An unknowable standard is no standard at all.

*Reply:* This objection conflates epistemology (our access) with ontology (what exists). As argued in Section 4.1, the Apex Network is a **theoretical model of a real, emergent historical object** whose existence is a structural consequence of the model's premises. The challenge is purely epistemological. Our access is partial and fallible, but this is the standard condition for inquiry into any large-scale emergent system, from an ecosystem to the global economy.

The existence of this real object is what grounds the possibility of making objective, truth-apt claims: a statement is objectively true if it is coherent with this maximally viable set of predicates. Our epistemic humility comes from acknowledging that our map is always provisional. Our confidence, however, comes from the fact that we are mapping a real territory. Our claim to objectivity rests not on a perfect vision of the safe harbor, but on the **undeniable reality of the historical wreckage** charted in our Negative Canon.

## **6. Situating the Model: A Unified Alternative**

Emergent Pragmatic Coherentism is not an isolated proposal but a synthesis that occupies a unique and powerful position in the philosophical landscape. By reframing metaethics around a unified theory of justification, it offers a novel, naturalistic alternative to several dominant traditions.

First, EPC is a form of **procedural, pragmatic realism**. It is realist in positing objective truths about which normative systems are superior. Unlike Non-Natural Realism, however, it grounds these truths not in mysterious, *sui generis* moral properties, but in observable, empirical patterns of viability. The truth-makers for moral claims are the objective facts about which networks prove most efficient and resilient against the real-world constraints of pragmatic selection. The key distinction is that ‘truth’ is a property internal to a network’s coherence, while **viability** is an objective property of that network’s external relationship with reality. In this, EPC suggests that the ingenious project of quasi-realism (Blackburn 1993) is a brilliant solution to a problem that EPC dissolves. Where quasi-realism seeks to vindicate the realist-sounding *grammar* of our moral claims without realist commitments, EPC argues that this grammar is sound because it is, in fact, tracking an objective, procedural reality of pragmatic viability.

Second, the framework should be understood as the **systematic completion of the Quinean and Deweyan projects**. Quine’s demolition of the analytic/synthetic distinction unified all descriptive claims within a single pragmatic web. EPC extends this holism one decisive step further, dissolving the fact/value distinction by showing that normative claims are subject to the same filtering process. Where Quine described the *static architecture* of an individual’s web, EPC identifies the missing piece: the *dynamic, evolutionary engine* of pragmatic selection. It fulfills Dewey's (1929) project of treating inquiry as a continuous process of resolving problems and argues that lasting solidarity, which Rorty (1989) champions over objectivity, is in fact an emergent property of a network that has achieved objective pragmatic success.

Finally, this stance-independent realism distinguishes EPC from more conventional **constructivism**. A purely constructivist theory ultimately grounds normativity in the coherence of our own attitudes. For EPC, Caligula's internal coherence is irrelevant because the locus of judgment is external. Where a constructivist must assess the internal consistency of Caligula's attitudes, EPC assesses the external viability of the socio-political network that licensed them. Street's anti-realist dilemma forces a choice between accepting the coherence of such monsters or asserting a realist truth that evolution has not equipped us to track. EPC offers a third way: the network that produced and sustained Caligula was an **objective, pragmatic, evolutionary failure**, judged not by our disapproval, but by the real-world systemic friction and First-Order Costs it generated—political instability, assassination, social fragmentation—which demonstrably undermined the Roman Principate (Barrett 1990).

This external, systems-level focus also distinguishes EPC from other naturalist rivals like **Neo-Aristotelianism** (Foot 2001). The Neo-Aristotelian project grounds normativity in a thick, teleological concept of species-specific flourishing; the unit of evaluation is the organism. EPC, by contrast, shifts the unit of selection from the organism to the **informational structure of the network itself**. Its metric is not a contentious concept of "flourishing," but the thinner, procedural standard of multi-generational viability. By focusing on the external viability of the network's informational code rather than the internal states of the organism, EPC offers a more robust, non-teleological naturalism capable of grounding both the Convergent Core and the Pluralist Periphery.

## **7. Conclusion: Inquiry as a Pragmatic Project**

Emergent Pragmatic Coherentism is, at its core, a unified theory of inquiry. It argues that morality is not a special domain with its own logic but is, like science and politics, a project subject to the same evolutionary pressures. It reframes all human endeavor as a single, multi-generational project: the construction of ever more viable maps for navigating a shared reality. On this view, an "is" is a predicate about how the world appears to function, and an "ought" is a time-tested predicate about how best to act within it. Both are adjudicated in the same ultimate court of long-term pragmatic selection.

It is crucial, however, to be precise about the scope of this project. The instrumental and conditional framing of EPC is a deliberate methodological choice that defines its limits. EPC is a theory of **internal normative diagnostics**, not external conflict resolution. It provides a framework for a system to evaluate and debug its *own* organizing principles against the long-term metric of viability. It does not, for example, offer a non-question-begging way to adjudicate a life-or-death conflict between two distinct, survival-oriented systems (e.g., two empires at war), as each operates under the same brute constraint of endurance. By bracketing this intractable problem, EPC focuses on a more modest but powerful task: providing a naturalistic, evidence-based method for identifying and moving away from self-defeating social structures.

This framework offers a naturalistic model for procedural objectivity that allows us to be both humble and hopeful. We are humble in knowing that our current maps are imperfect and that our access to the lessons of history is fallible. Yet we can be hopeful, because moral progress is a real, observable phenomenon. We can state with confidence that abolishing slavery was not a mere change of opinion; it was a profound act of **debugging our societal code**—the identification and removal of a demonstrably failed organizing principle from our **Negative Canon**.

Progress occurs when we treat suffering, dissent, and instability not as mere political problems to be managed, but as **primary epistemological data**. They are the "check engine" light for society. This gives us a powerful, pragmatic reason to listen to the marginalized, as they possess the most crucial information about where our collective map is wrong. The authority of an “ought,” therefore, is not found in a metaphysical foundation or the structure of rational agency, but in the immense, procedural weight of historical evidence. An “ought” is a time-tested predicate coherent with our most pragmatically resilient networks—a hard-won empirical signal that it represents a viable strategy for the shared project of human endurance. EPC thus reframes moral philosophy: from a search for ultimate justification to the ongoing, fallible craft of social engineering—the art of steering by the light of humanity’s most enduring successes and charting the wreckage of its failures.

### **Glossary**

-   **Apex Network:** A theoretical model of a real, emergent historical object. This object is the maximal, coherent set of predicates that has, to date, best demonstrated pragmatic viability across human history. Our access to it is fallible and mediated through the model.
-   **Drive to Endure:** The minimal, constitutive precondition for a system's persistence over time. Functioning as an amoral, transcendental filter analogous to gravity, its conflict with a given network generates the First-Order Costs that are the primary data for assessing pragmatic viability.
-   **First-Order Costs:** The direct, material consequences of a network's conflict with the drive to endure (e.g., elevated mortality, systemic violence, high coercive energy expenditure). They are the primary, objective indicators of low pragmatic viability.
-   **Negative Canon:** An evidence-based catalogue of predicates empirically demonstrated to generate catastrophic First-Order Costs and normative brittleness across multiple historical contexts (e.g., “slavery is acceptable”).
-   **Network of Predicates:** The public, structural unit of shared knowledge, emerging bottom-up from the forced overlap of individual webs of belief.
-   **Normative Brittleness:** A network's inherent vulnerability to external shocks, caused by high internal friction (i.e., high First-Order Costs and coercive costs). It is the inverse of resilience.
-   **Pragmatic Viability:** A system's homeostatic efficiency; its ability to maintain stability and propagate its informational structure with low internal friction and minimal energy expenditure on coercion. It is the primary metric for evolutionary pragmatic selection, distinct from mere endurance.
-   **Procedural Objectivity:** Objectivity grounded in the evolutionary dynamics of pragmatic selection. While truth is a property internal to a network, networks themselves are objectively ranked by their external, real-world viability.

### **References**

Axelrod, Robert. 1984. *The Evolution of Cooperation*. New York: Basic Books.

Barrett, Anthony A. 1990. *Caligula: The Corruption of Power*. New Haven, CT: Yale University Press.

Blackburn, Simon. 1993. *Essays in Quasi-Realism*. Oxford: Oxford University Press.

Dewey, John. 1929. *The Quest for Certainty: A Study of the Relation of Knowledge and Action*. New York: Minton, Balch & Company.

Dular, Nicole. 2024. “Standpoint Moral Epistemology: The Epistemic Advantage Thesis.” *Philosophical Studies* 181 (8): 1813–35.

Foot, Philippa. 2001. *Natural Goodness*. Oxford: Oxford University Press.

North, Douglass C. 1961. *The Economic Growth of the United States, 1790-1860*. Englewood Cliffs, NJ: Prentice-Hall.

Patterson, Orlando. 1982. *Slavery and Social Death: A Comparative Study*. Cambridge, MA: Harvard University Press.

Popper, Karl R. 1959. *The Logic of Scientific Discovery*. London: Hutchinson & Co.

Quine, W. V. O. 1951. “Two Dogmas of Empiricism.” *The Philosophical Review* 60 (1): 20–43.

Rorty, Richard. 1989. *Contingency, Irony, and Solidarity*. Cambridge: Cambridge University Press.

Street, Sharon. 2006. “A Darwinian Dilemma for Realist Theories of Value.” *Philosophical Studies* 127 (1): 109–66.

Tainter, Joseph A. 1988. *The Collapse of Complex Societies*. Cambridge: Cambridge University Press.

Turchin, Peter. 2003. *Historical Dynamics: Why States Rise and Fall*. Princeton, NJ: Princeton University Press.