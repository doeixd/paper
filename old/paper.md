# Re-Framing the Is/Ought Distinction: A Defense of Emergent Pragmatic Coherentism

### Abstract

This paper proposes **Emergent Pragmatic Coherentism (EPC)**, a descriptive model of moral epistemology that aims to re-frame the is/ought problem. Building on Quine’s holism, it models knowledge as an emergent hierarchy of shared “networks of predicates” that scales up from the individual “web of belief.” Within this architecture, EPC employs a deflationary account of truth: 'truth' is not a claim of correspondence with ultimate reality, but a functional label for a predicate’s robust coherence within a specified, pragmatically-tested network.

This initial network-relativity is, however, disciplined by a procedural and objective evolutionary process. The model posits that networks are continuously tested against the constraints of a shared reality through evolutionary pragmatic selection. Unviable networks—those generating high degrees of systemic friction, or “pragmatic pushback”—are filtered out over time as agents abandon them for more functional alternatives. Consequently, while 'truth' is a property internal to a network, the networks themselves can be objectively ranked by their long-term pragmatic viability.

The entire model is anchored by a single, minimal axiom: the constitutive, biological drive to endure, a pre-rational ‘is’ that serves as the de facto non-circular foundation for the selective process. By bracketing the ultimate philosophical question of grounding, EPC offers a fully naturalistic model of procedural objectivity and moral progress, locating the source of normative authority not in a metaphysical foundation, but in the cumulative, hard-won lessons of our species’ pragmatic encounter with reality.

---

## 1. Introduction: From Symptom to System

For centuries, a central project in philosophy has been to understand the relationship between claims of fact (“is”) and claims of value (“ought”). This paper suggests that the infamous is/ought gap may be an artifact of a particular epistemological tradition. It is perhaps the most famous symptom of a deep-seated tension within foundationalist epistemologies, which tend to segregate facts and values into distinct metaphysical or justificatory domains. The aim is not to build a bridge across the is/ought gap, but to describe a framework in which their apparent separation is greatly reduced—where both are adjudicated by the same pragmatic process.

This paper defends such a framework: **Emergent Pragmatic Coherentism (EPC)**. At its core, EPC is a systematic extrapolation of Quinean holism. It begins with the familiar premise that we each navigate the world with an individual "web of belief." However, because we inherit our beliefs, share a language, and face the constraints of a common reality, these individual webs are not isolated. They inevitably overlap and share common structures, giving rise to an **emergent hierarchy of shared coherent networks**. EPC aims to formalize this intuitive observation, providing a name for a process we can already observe.

This emergent structure is the foundation for a general theory of justification. EPC applies a single set of criteria—internal coherence and pragmatic resilience—to all truth-apt claims. The resilience of any network is determined by a relentless, evolutionary process: its constant, practical interface with a reality that pushes back against inadequate maps. While the primary goal of this paper is to offer a unified model of inquiry, the dissolution of the is/ought problem is a direct and necessary consequence. This project is not without precedent; it consciously follows the playbook W.V.O. Quine used to collapse the analytic/synthetic distinction. By treating claims like “water boils at 100°C” and “murder is wrong” as formally and grammatically commensurable—as the same type of entity called a 'predicate'—EPC's first move is to treat them as formally commensurable 'predicates.' This does not in itself solve the problem, but it removes the artificial barrier that prevents them from being judged in the same court. The paper's central move is then to argue that all predicates, factual and normative, are adjudicated in the same ultimate court: the unforgiving, bottom-up process of evolutionary pragmatic selection. EPC does not claim to have solved the philosophical grounding problem of why we ought to prefer viable networks. Instead, it offers a descriptive model of the de facto system that has always served this function.

The argument will proceed as follows. First, I will detail EPC's core concepts: the crucial move from Quine’s individual "web" to the shared **"network of predicates,"** which makes the emergent structure explicit; the engine of **evolutionary pragmatic selection** that drives network revision; and the **emergent hierarchy of networks** itself, which provides the framework for a fallibilist and naturalized objectivity. Second, I will directly confront and rebut some of the most pressing objections to the theory, including the problem of stable evil and the nature of its grounding assumptions. Finally, I will situate EPC in the contemporary landscape, demonstrating its advantages over rival accounts.

### 1.1 Truth as a Pragmatic Indicator

It is crucial to clarify EPC’s unique stance on truth and normativity from the outset. This theory is primarily descriptive in its account of how truth-claims function, yet it is powerfully normative in its practical implications.

EPC argues that all claims, including moral ones, are genuinely truth-apt because it adopts a deflationary, coherentist account of truth. 'Truth' is not a mysterious property of correspondence with a noumenal reality, but a functional, relational property internal to a system. A predicate is 'true' relative to a specified network, meaning it coheres with the other predicates that constitute that pragmatically-tested map of reality. A claim can therefore be objectively true within a given context.

This is where the connection between the theory's deflationary 'truth' and its normative implications becomes clear. A critic might ask: if 'truth' is merely a label for coherence within a network, why should that internal property guide our actions outside the network? Why should we care about what is 'true' in this sense?

The answer lies in the evolutionary origin of the network itself. A network is not an arbitrary collection of statements; it is a pragmatically forged tool for navigating reality. It is the survivor of a relentless, eliminative process that filters out dysfunctional maps. Therefore, the descriptive fact that a predicate is 'true' (i.e., coherent with one of our most historically successful, shared networks) is not merely an interesting logical property. It is a powerful empirical signal. It indicates that this specific predicate is an integral component of a map that has demonstrated immense long-term pragmatic viability.

EPC, therefore, reconnects the 'is' and the 'ought' in a purely procedural and naturalistic way. The 'is' of a predicate's descriptive truth-value (its coherence within a time-tested network) serves as a reliable guide to the 'ought' of pragmatic action, precisely because that network's coherence was itself forged and disciplined by the unforgiving 'is' of reality's relentless feedback. To trust what is 'true' in our best networks is simply to make the pragmatic bet that the hard-won lessons of history are a better guide to future action than our own untested intuitions.

This framework does not eliminate moral choice; it reframes it. The choice is not between obeying or defying a mysterious moral law, but between adopting more or less viable pragmatic strategies. An agent remains free to ignore the pragmatic indicators embedded in the shared network, but this choice has predictable consequences. EPC is therefore fully compatible with determinism, as the practical reality of choosing between different predicates—and being held accountable for those choices—persists regardless of the ultimate nature of free will. Our moral agency lies in our capacity to diagnose the flaws in our current maps and participate in the project of building better ones.

It is therefore essential to distinguish EPC's project from that of traditional metaethics. The theory does not seek to ground normativity or derive an 'ought' from an 'is' in the classical sense. Rather, it offers a descriptive, causal account of how normative systems evolve. In this sense, it contains a constructivist element: our networks are indeed human constructions, forged and revised over time. However, this is where EPC makes its crucial departure from standard constructivism. It argues that this process of construction is not a free-floating project of social agreement, but a project that is relentlessly disciplined by a real, external, and unforgiving selective pressure. The 'oughts' we construct are continuously tested against the 'is' of reality's pragmatic constraints. EPC is therefore a theory of realistically-constrained construction, where the authority of a norm lies not in its philosophical grounding or the coherence of our attitudes, but in the accumulated, empirical evidence of its having survived this brutal, eliminative filter.

 ### 1.2 The Status of the Grounding Claim: A Descriptive Turn

 It is essential from the outset to be precise about what this paper does and does not claim to accomplish. EPC **does not claim to have solved the ultimate philosophical problem of grounding normativity**—that is, it does not provide a non-circular answer to the question, "Why *should* I value pragmatic viability or endurance?" To do so would be to attempt to square the meta-ethical circle.

 Instead, EPC takes a **descriptive and procedural turn**. Its ambition is to offer a **naturalistic model of moral epistemology**: a theory of how normative systems function and evolve. The paper's central thesis is not normative, but descriptive and systemic: that a process of evolutionary pragmatic selection, anchored by the *de facto* constraint of endurance, **is the system that *in fact* adjudicates the viability of all our truth claims, including moral ones.**

 The theory's project is not to prove that we *ought* to play this game, but to provide the first systematic description of the rules of the game we are *already playing*. It shifts the focus from a futile search for metaphysical foundations for our values to the construction of a robust, testable model of the evolutionary process by which values are actually filtered, retained, and come to have authority. EPC, therefore, offers a sophisticated framework for understanding moral reasoning and an account of **procedural objectivity**, all without making a circular normative claim about its own foundations. It describes the court; it does not attempt to justify the court's ultimate jurisdiction.

## 2. The Foundation: From Individual Webs to Emergent Networks

The foundation of *Emergent Pragmatic Coherentism (EPC)* is not a novel invention but a systematic extrapolation of a mechanism already implicit in W.V.O. Quine’s holism. Just as Quine’s critique of the analytic/synthetic distinction collapsed the wall between truths of logic and truths of fact, EPC uses his holistic framework to collapse the wall between truths of fact and truths of value. Quine famously pictured knowledge as an individual’s “web of belief”—a contextual, coherent network that serves as the **arena in which truth-claims are made and adjudicated.**¹ This is a brilliant metaphor, but it remains fundamentally psychological, describing an agent’s private mental state. The task for a social epistemology is to explain the structural nature of our *shared* knowledge.

EPC argues this transition from the private to the public is not a puzzle to be solved, but an inevitable, bottom-up process of emergence. Consider the basic premises:

1.  Every individual navigates the world using their own Quinean web of beliefs.
2.  Every individual is subject to the pragmatic constraints of a shared reality.

From these two premises, a third fact follows with structural necessity: **wherever individuals successfully interact with reality, their individual webs of belief are forced to overlap.** This intersection is not a conscious negotiation; it is an automatic, emergent consequence of pragmatic pressure. When two people build a functional canoe, their individual webs regarding concepts like 'buoyancy,' 'wood,' and 'cooperation' have been forced into a shared, coherent alignment by the unforgiving feedback of the physical world.

The coherent set of beliefs shared by the canoe-builders is a miniature emergent network. This process scales instantly and dynamically. A scientific community, a legal system, or an entire culture are simply vastly more complex versions of the same phenomenon. These **emergent, shared networks** are therefore not centrally designed, democratically voted upon, or consciously constructed. They are the inevitable, structural result of innumerable individual webs being continuously filtered against a common reality, converging only where they prove pragmatically successful. Their existence is not a matter of consensus but of structural necessity, pointing toward a theoretical limit: the Apex Network, the maximal intersection of all pragmatically viable beliefs across all of human experience.

To analyze this emergent reality, EPC proposes a crucial shift in terminology: from the psychological language of a "web of belief" to the more formal, linguistic concept of a **“network of predicates”** (Here, 'predicate' is used in its broad, semantic sense—the propositional content of an attribution—rather than a strictly formal, logical one). In this context, a predicate refers to the structural component of a claim that asserts a property of a subject—for instance, the propositional content of “…is wrong,” “…is a planet,” or “…boils at 100°C.” This is more than a semantic tweak; this move from subjective belief to predicate is crucial for three reasons.

First, it moves the analysis from the private and mental to the **shared and structural**. We are no longer describing an individual’s internal cognitive state, but the objective, shared architecture of our collective knowledge. A predicate exists "out there" in our language and practices, available for collective inquiry. When an agent asserts "promises should be kept," they are typically not just reporting on their private network but appealing to a predicate they infer to be a stable component of a **shared, emergent network**.

Second, it makes the **grammatical and logical commensurability** of all claims explicit, executing the first step in resolving the is/ought problem. By treating “…is wrong” and “…boils at 100°C” as the same *type* of formal object—a predicate being applied to a subject—we dissolve the artificial barrier between fact and value at the most basic level of analysis. Both are simply truth-apt statements whose validity is determined by their function within a pragmatically tested network. This structural move denies the premise that quasi-realists must work so hard to overcome; it grants moral claims genuine, albeit network-relative, truth-aptness from the start.

Third, and most crucially, this move operationalizes a deflationary theory of truth consistent with contextual coherentism. 'Truth' on this view is not a mysterious property of correspondence with a noumenal reality, but a functional label. It is a relational property that signifies a predicate's robust coherence within a specified network—a network that has itself been forged by the bottom-up, emergent process of pragmatic selection. A predicate is therefore 'true' relative to a network, and its truth-value can change if that network, as a node in the larger emergent hierarchy, is revised in response to pragmatic pushback. This initial establishment of network-relativity, far from being a concession to simple relativism, is the essential conceptual ground upon which a more sophisticated and procedural objectivity will be built.

### **3. The Engine: Evolutionary Pragmatic Selection**

What prevents emergent networks from being arbitrary, self-justifying constructs? The engine that drives their evolution and anchors them to reality is the process of **evolutionary pragmatic selection**. This section will detail this mechanism, showing how a set of minimal premises entails both the bottom-up emergence of shared networks and the selective, non-foundationalist filter that continuously refines them.

The engine of EPC rests on two minimal, empirically observable premises: (1) that as agents, we find ourselves in a world with hard constraints that push back against our actions, and (2) that we are animated by a suite of persistent, evolved drives to navigate these constraints. It is critical to be precise about the philosophical status of the foundational drive within this suite, which EPC terms the 'drive to endure.' This is not a thick, value-laden concept of "flourishing," but the most minimal, biologically-grounded precondition for any system's continued existence: the persistence of a system's structure and core information over time.

This minimal definition is what gives the drive its unique, non-moral status. All other potential drives (e.g., for purity, for glory, for submission to a divine will) are substantive claims about how to live; they are predicates to be evaluated by the system based on their long-term pragmatic consequences. The drive to endure functions less as a moral directive and more as the constitutive condition of inquiry itself: without persistence over time, no system could test or revise its predicates. It is the pre-rational, biological "is" that makes the formation and testing of any predicate-network a necessary and meaningful activity in the first place.

While the precise boundaries of this drive will always be a site of philosophical contention, any coherent system of inquiry must presuppose some version of it. A network is, by definition, a tool for navigating reality, and the project of "navigating" presupposes a commitment to persistence. To question the primacy of this drive is therefore a form of pragmatic self-contradiction, for the act of questioning is performed by a system already engaged in the project of enduring.

From these premises, the existence of shared networks follows as a matter of structural logic. Each individual agent must develop and revise their personal network of predicates to navigate reality. Because every agent shares the same fundamental drives and faces the same external constraints, their independent, trial-and-error processes are bound to converge where they prove successful. A predicate that works for one agent is likely to work for others facing similar problems. This convergence is not centrally planned; it **bubbles up** from the parallel processing of countless individuals, resulting in the bottom-up emergence of shared, coherent networks of predicates.

These initial conditions, therefore, do double duty. They explain the existence of networks, and they create the powerful, continuous filter that revises them. The process of selection, however, acts upon individuals, and it is at this level that **pragmatic pushback originates**. When an agent adopts a predicate from a shared network that provides a poor map for reality, their actions generate friction—a personal experience of dysfunction. While what constitutes pushback can vary between individuals, the constraints of a shared reality and our common evolved drives ensure that these experiences are not random. When a predicate is sufficiently misaligned with these shared conditions, countless individuals will independently and repeatedly experience similar forms of friction.

It is this large-scale aggregation of individual friction that constitutes what EPC terms **pragmatic pushback**: the holistic, emergent consequence of a network's widespread adoption. While its specific manifestations are countless, its character as an objective, system-level signal is identified by its empirical signatures. Pushback is distinguished from mere local disagreement or temporary political resistance by two key hallmarks:

*   **Persistence and Breadth:** Genuine pushback is not a fleeting event. It is a form of systemic friction that tends to persist across generations and recur across different cultural contexts whenever a similar unviable predicate is implemented.
*   **Systemic Cost:** A predicate’s pragmatic failure can be measured by the immense and ongoing investment of energy required to manage the friction it generates. A system that must constantly expend resources on coercion and ideological maintenance is demonstrating the high pragmatic cost of its core predicates.

It is this persistent, costly friction—originating in individual experience but aggregating into a systemic force—that serves as the selective pressure driving the **coherent, shared updating of our higher-level networks**. While the effects of pushback are distributed, its signals are not. The data signaling a predicate's incoherence is generated most intensely at the points of greatest friction—that is, by the individuals who suffer the most from its application. Therefore, suffering, dissent, and instability are not merely unfortunate byproducts; they are the primary epistemological signals that a network is failing its pragmatic test.

It is crucial to be precise about how this process of revision unfolds. It is not a top-down, legislative act but a **bottom-up, emergent phenomenon**. An individual agent, experiencing persistent friction generated by a shared predicate, independently revises their personal network—perhaps abandoning the flawed predicate or adopting a more functional alternative. This is a local, private act of cognitive recalibration, but it is not an isolated one. Across the system, countless other agents are engaged in the same parallel process of trial-and-error, driven by similar frictions. The emergent result is that the flawed predicate's prevalence within the public language begins to decay, while more viable alternatives gain purchase. The shared network—which is nothing more than the aggregated, coherent intersection of these countless individual networks—begins to evolve. This is the engine of change: the mass aggregation of independent, local solutions to a shared, systemic problem.

But what prevents this diagnostic process from becoming circular, whereby we simply label as "pushback" that which offends our prior moral commitments? The answer lies in the causal mechanism of systemic failure itself. The process is not a formal debate to be won, but an evolutionary filter with an objective, non-arbitrary hierarchy of costs.

### **3.1 The Causal Mechanism: A Hierarchy of Pragmatic Costs**

To adjudicate between competing claims of "pushback" (e.g., the instability of a slave system versus the economic disruption of abolition) and to ground the analysis in a non-circular metric, we must specify the causal hierarchy of pragmatic costs.

*   **First-Order Pragmatic Costs:** These are the direct, empirical signatures of a network's conflict with the **constitutive drive to endure**. They are pre-ideological and can be identified through objective metrics: elevated mortality and morbidity rates, the systemic violence required for control, resource depletion, and the immense, ongoing energy expenditure required for mass coercion. These are not abstract "harms"; they are the measurable, physical consequences of a system generating friction against the biological reality of its agents.

*   **Second-Order Pragmatic Costs:** These are more abstract, systemic, and often ideologically framed costs contingent on a particular sub-network's survival. They include threats to a specific cultural identity, disruption of an existing economic model, or the reorganization of social hierarchies.

The central principle of EPC is that **First-Order costs have causal and diagnostic priority.** This is not a normative claim about which forms of suffering are more morally important. It is a **descriptive, systems-dynamic claim about what makes a network unstable.** High mortality rates and massive energy expenditures on coercion are not merely "bad"; they are objective, material drags on a system's resilience and adaptability, *regardless of how the dominant group interprets or justifies them*.

To put it in purely physical terms: a social system is a machine for converting energy into order. A network that must constantly expend vast amounts of energy suppressing internal friction (managing slave revolts, producing propaganda, policing dissent) is like a profoundly inefficient engine. It may run for a long time if it has access to a massive fuel source (e.g., an exploitable population), but its design is inherently fragile. It is less adaptable to external shocks and will be outcompeted by more efficient, lower-friction designs in the long run.

Therefore, when a network inflicts continuous First-Order costs (violence, death) upon one population to shield another from potential Second-Order costs (economic change, cultural anxiety), it is not making a rational trade-off. It is demonstrating a critical design flaw. Its long endurance is not evidence of its viability, but a measure of the immense energy it must burn to manage its own self-inflicted instability—a pragmatic "success" that perfectly masks its deep structural fragility.

This dynamic creates a fatal feedback loop we can term **Information Cost**. By systematically suppressing the dissent of those experiencing the most intense First-Order costs, the network blinds itself to the very data it needs to adapt and survive. This self-induced epistemic brittleness makes the network profoundly vulnerable to novel challenges. This provides a purely pragmatic, rather than moral, justification for treating the testimony of the marginalized as the most crucial source of data for diagnosing a network’s flaws.

This framework also explains the vast asymmetry between the test for an empirical claim and the test for a moral one. This observed asymmetry is not a weakness of the theory, but a direct prediction of it. EPC posits a unified *principle* of justification, not a unified *methodology* or *timescale* of testing. The nature of the pragmatic pushback is proportional to the complexity of the reality being mapped.

- **Simple Systems, Sharp Pushback:** An empirical predicate like “…boils at 100°C” is a hypothesis about a simple, isolable physical system. The feedback loops are short and direct. Pragmatic failure is swift and decisive.
- **Complex Systems, Diffuse Pushback:** A moral predicate like “…is unjust” is a hypothesis about structuring a complex adaptive system—an entire society—for long-term viability. The feedback loops are long, holistic, and contested, unfolding over generations.

This difference in velocity and texture explains why moral knowledge is so much harder-won than scientific knowledge, without undermining the unified framework. Consider again a network containing the predicate “slavery is acceptable.” The pragmatic pushback was a slow-motion cascade of systemic failure, driven by the immense First-Order costs inflicted upon the enslaved. The epistemological signal, however, was sharp and clear: it came from the constant social friction and instability generated by those experiencing these costs. This signal forced a diagnostic process, revealing secondary frictions: the logical incoherence of holding contradictory predicates like “all men are created equal,” the institutional brittleness of an economy dependent on oppression, and the psychological costs borne by all. The revision of the predicate was justified because it was the most coherent explanation for the system's primary frictions, and because the new predicate ('slavery is wrong') represented the most compelling hypothesis for creating a more viable and lower-friction social order going forward.

This provides the foundation for a naturalistic account of moral error and progress. It requires no appeal to transcendent moral truths because the pressure to revise—and the data required to guide that revision—is generated from within the system’s own costly and ultimately fatal encounter with the world.

It must be stated clearly that EPC does not offer a simple algorithm for measuring "pragmatic viability." The empirical project of assessing the total First-Order costs of a complex historical network is immense and fraught with difficulty. The purpose of the framework is not to provide a quantitative "viability score" for a given society. Rather, its purpose is **diagnostic and philosophical**. It provides a causal model for understanding *why* systems fail and a non-arbitrary, materialist framework for grounding claims about moral error. By focusing the analysis on objective, physical metrics like mortality and energy expenditure, it disciplines the debate and resists the charge that "friction" is merely a matter of ideological interpretation. The framework identifies *what we should be looking for*, even if the looking is hard.

## **4. The Architecture: An Emergent Hierarchy and Naturalized Objectivity**

EPC avoids simple relativism by demonstrating how a robust, fallible objectivity emerges from the interaction of countless individual networks. (It is important to note that when EPC refers to 'better' or 'superior' networks, this refers to objective measures of pragmatic functionality and long-term viability, not to moral goodness in a metaphysical sense.) Because agents inherit, share, and test their networks against a common reality, a nested hierarchy of shared networks is an inevitable emergent feature of our collective existence:

1.  **Individual Networks:** The private set of predicates held by a single agent.
2.  **Sub-Networks:** The coherent intersection of predicates shared within a group, such as a culture, scientific community, or historical epoch. Most of our day-to-day truth claims operate relative to these shared networks.
3.  **The Apex Trans-historical Network:** The maximal coherent set of predicates that has, to date, proven most viable across the widest range of human experience.

It is absolutely crucial to be precise about the epistemological status of this Apex Network. It is not a Platonic ideal to be discovered or a Hegelian absolute unfolding in history. Its primary function is **philosophical, not empirical**. It serves as a **regulative ideal**—the theoretical limit of the eliminative process of pragmatic selection. The Apex Network is the *name* we give to the hypothetical, maximally viable network that would remain if this brutal filtering process were run to completion. We do not need to access it directly to use it as a conceptual tool; its role is to ground a naturalistic and fallibilist account of objectivity, allowing us to speak meaningfully about better and worse networks without appealing to transcendent truths.

This provisional and inaccessible status is a core feature of the theory, not a flaw. However, to prevent this regulative ideal from becoming a mere placeholder for contemporary values, our approximation of it must be grounded in a concrete, two-part methodology resistant to projection and survivorship bias.

First is the **Principle of Negative Universalism**. Our knowledge of the Apex Network is primarily negative. The project is not to positively define a utopia, but to build an evidence-based **Negative Canon**: a robust, cross-cultural catalogue of predicates that have been empirically demonstrated to be core components of failed networks. We can state with high confidence that predicates like “slavery is acceptable” or “genocide is a valid political tool” are objectively false relative to the Apex Network, because the historical record provides overwhelming evidence that the networks they anchor generate catastrophic First-Order pragmatic costs and are ultimately unsustainable.

Second is the **Test of Independent Convergence**. To identify candidates for the positive "Convergent Core" while guarding against survivorship bias, we must look for predicates that have emerged independently in multiple, historically distinct, and long-enduring sub-networks. The authority of a predicate like “reciprocity is a binding norm” comes not from its presence in a single "winning" culture, but from its repeated, independent discovery as a uniquely successful solution to a universal human coordination problem. The records of historical "winners" are also treated as crucial data, but often as cautionary tales; the immense First-Order and Information costs required to maintain their dominance are empirical evidence of their networks' pragmatic weaknesses. Together, these principles ground our approximation in an epistemology that is fundamentally negative and empirical—a model built not from a priori insight, but from charting the wreckage of a vast, multi-millennial, and brutal process of elimination.

A critic might rightly argue that such "independent convergence" may not reveal objective moral truth, but merely reflect a contingent, shared human psychology shaped by our evolutionary history. EPC fully accepts this possibility, because it is irrelevant to the pragmatic project. The theory does not claim to provide access to a noumenal realm of values. Rather, it offers a theory of **how to build the most viable maps for the territory we actually inhabit.** That territory includes not only external reality but also the unchangeable constraints of our own evolved psychology. Whether the fundamental rules of the game are dictated by the structure of the cosmos or the structure of the minds that perceive it, they remain the only rules we have. EPC's naturalism lies in treating these evolved "givens" as the non-negotiable starting point for all inquiry.

This negative, empirical approach is what gives our model of the Apex Network its normative force. Its authority is not that of a satellite map offering a perfect, verifiable image of the destination. A more accurate analogy is that of a **trans-generational nautical chart, pieced together from the records of countless failed voyages.** We do not have a picture of the safe harbor, but the chart is littered with the records of shipwrecks, meticulously documenting the location of reefs, shoals, and catastrophic currents. Our knowledge is not of what is definitively *right*, but of what has been demonstrably, and often brutally, proven *wrong*. To ask, "Why should I care about this retrospective model?" is therefore like a new captain asking, "Why should I care about this chart of known hazards?" The answer is not a command, but a piece of practical, evidence-based advice: this is the most reliable guide we have for avoiding catastrophic failure while navigating the non-negotiable constraints of our shared reality. The Apex Network is best understood as a regulative ideal: the hypothetical maximally viable network that would survive pragmatic filtering if the process were extended indefinitely. Its role is not metaphysical but epistemic, grounding our talk of better and worse networks.

This architecture provides a naturalistic framework for understanding both progress and error. It allows us to state, without anachronism, that a predicate like “slavery is acceptable” was coherent *within a specific historical sub-network*, while also maintaining that this predicate is objectively false *relative to our best retrospective model of the more pragmatically-tested Apex Network*. Moral progress, then, is the difficult, empirical process reflected in the evolution of sub-networks, which occurs as the individuals within them revise their personal beliefs in response to pragmatic pushback, thereby becoming more aligned with the hard-won lessons of history.

Crucially, this architecture provides a direct answer to the challenge of value pluralism. The model does not predict that the Apex Network will contain a single, uniquely correct answer for every question. Instead, its logic points to a specific structure for objective knowledge: a **“Convergent Core”** surrounded by a **“Pluralist Periphery.”** This structure is not an ad-hoc assertion but a direct prediction of the theory. Convergence is expected in domains that address universal coordination problems with a narrow range of viable solutions (e.g., responses to the prisoner's dilemma, norms for in-group violence). Pluralism is expected in domains where multiple, distinct, but equally stable solutions to a coordination problem exist (e.g., specific kinship structures or aesthetic norms).

This distinction—between a universal, convergent core and a variable, pluralist periphery—allows EPC to incorporate the insights of thinkers like Sam Harris while avoiding the pitfalls of a simplistic consequentialism. The various pragmatically successful but culturally distinct sub-networks can be seen as analogous to the multiple "peaks" on Harris's *Moral Landscape*. Each peak represents a coherent network that has found a stable solution for minimizing pragmatic friction for its members. EPC affirms Harris's core naturalist insight that some ways of life are demonstrably worse than others (i.e., they are in the "valleys" of high pragmatic cost). However, EPC's architecture provides a crucial layer of sophistication. By grounding viability in the historical, emergent process of pragmatic selection rather than a direct calculation of "well-being," it avoids the intractable problem of defining and measuring utility. Furthermore, the concept of the Pluralist Periphery gives a formal, structural reason for why there might be **multiple, equally high peaks on the moral landscape.** It predicts that on many complex social questions, there is no single "correct" answer, but rather a range of different but equally viable solutions. This allows the theory to account for deep, persistent, and legitimate cultural disagreements without collapsing into simple relativism.

## **5. Defending the Core: Four Critical Objections**

This section addresses some of the most pressing objections to EPC. Demonstrating the theory’s resilience against these challenges strengthens the case for its adoption as a viable framework.

### **5.1 The Objection from Stable Evil**

**Objection:** The most challenging objection posits a technologically advanced, oppressive society that endures for millennia. Hasn't its network "won" the pragmatic test, thereby making its oppressive predicates objectively "true" by the standards of EPC?
**Reply:** This objection rests on two crucial errors: it mistakes mere endurance for pragmatic viability, and it misidentifies the unit of selection.
First, the critic mistakes a single, dominant sub-network for the entire emergent social system. The "stable evil" society is not one coherent network; it is a system defined by the violent conflict between at least two networks: the oppressive network of the dominant group and the resistant networks of the subjugated. The predicates of the subjugated ("we are being unjustly harmed," "our subjugation is illegitimate") are not erased by oppression; they are an ineliminable and active part of the total emergent structure. Their persistent rejection of the dominant predicates is the primary source of the system's friction.

Second, the objection underestimates the nature of pragmatic cost. Such a system must bear an immense, ongoing First-Order pragmatic cost. To mistake its persistence for viability is like confusing a gas-guzzling, high-maintenance engine for an efficient one simply because it has enough fuel to keep running. The "stable evil" society is pragmatically "successful" only in the narrow sense that it successfully extracts the enormous energy required to continuously suppress the competing networks within it. This constant energy drain makes the system fundamentally brittle and less adaptable to novel challenges than a low-friction, high-cohesion alternative.

Therefore, its endurance does not make its predicates true at the highest level of justification. It is merely a very long and brutal failed experiment in social engineering, a testament to the immense cost of its own internal contradictions. We chart its wreckage—including the persistent, counter-hegemonic networks of the oppressed—to build a better map.

### **5.2 The Objection from Ideology**

**Objection:** The theory claims that pragmatic pushback leads to network revision. But ideology can co-opt this process. A network can create "patch" predicates (e.g., “your suffering is a noble trial”) that convince agents to endure failure rather than revise the core of the network.

**Reply:** This objection correctly identifies a key tactic in the war of attrition between predicates. Ideological claims are often second-order predicates designed to manage the pragmatic failures generated by a network's primary predicates. However, these patches are not pragmatically free; they introduce their own **pragmatic costs**.

An ideological patch must cohere with the rest of a network, and it often creates second-order incoherence by clashing with more fundamental, biologically-driven predicates like “unnecessary harm is to be avoided.” To maintain its hold, such a patch requires a constant input of energy—rituals, propaganda, suppression of dissent—which adds to the network’s total pragmatic cost. This often requires a degree of epistemic closure that makes the entire network more fragile and less adaptable. Most importantly, while ideology can mask or delay the *symptoms* of pragmatic pushback, it can never eliminate the underlying dysfunction. The superior network, in the long run, is not the one most skilled at creating patches to manage its self-inflicted wounds, but the one whose core predicates generate the least pragmatic friction to begin with. Ideology is a costly, and ultimately temporary, defense mechanism against the relentless pressure of reality.

This objection, however, highlights the theory's crucial short-term normative force. While the ultimate evolutionary filter is long-term, EPC provides an urgent, present-tense diagnostic criterion: **we have a powerful pragmatic reason to be deeply skeptical of any network that requires costly ideological patches to function.** A system that must expend immense energy suppressing dissent, punishing heretics, and explaining away suffering is providing real-time evidence of its own high-friction design. The theory's immediate imperative is therefore not to wait for collapse, but to treat the *presence* of these ideological defense mechanisms as a primary epistemological signal that the network's core predicates are misaligned with reality. It gives us a reason to listen to the dissenters *now*, as they are the canaries in the coal mine of long-term systemic failure.

### **5.3 The Objection from Asymmetrical Testing**

**Objection:** The theory claims a single criterion—pragmatic selection—applies to all predicates. Yet the test for an empirical claim like “water boils at 100°C” is immediate and decisive, while the test for a moral claim like “inequality is acceptable” is slow and contested. This asymmetry is so great that it renders the claim of a unified test meaningless.

**Reply:** This observed asymmetry is not a weakness of the theory, but a direct prediction of it. EPC posits a unified *principle* of justification, not a unified *methodology* or *timescale* of testing. The nature of the pragmatic pushback is proportional to the complexity of the reality being mapped.

- **Simple Systems, Sharp Pushback:** An empirical predicate like “…boils at 100°C” is a hypothesis about a simple, isolable physical system. The feedback loops are short and direct.
- **Complex Systems, Diffuse Pushback:** A moral predicate like “…is unjust” is a hypothesis about structuring a complex adaptive system—a society—for long-term viability. The feedback loops are long, holistic, and contested, unfolding over generations.
This difference in velocity and texture explains why moral knowledge is so much harder-won than scientific knowledge, without undermining the unified framework.

### **5.4 The Objection from Circularity (The Grounding Problem)**

**Objection:** The most fundamental objection is that EPC is either a free-floating coherentist fantasy or, worse, a circular argument. It claims to derive "oughts" from a pragmatic test based on "endurance," but this drive to endure seems to be a foundational "ought" that has been smuggled in without justification. The system appears to be grounded on the very kind of value it purports to explain.

**Reply:** This objection correctly identifies the source of normativity in EPC but makes a category error regarding its philosophical status. EPC is not grounded on the normative premise that "survival is good"; it is grounded on the descriptive, amoral observation that non-enduring systems cease to exist. The 'drive to endure' is not a moral premise we choose, but the constitutive, empirical precondition for having a system of justification at all.

The entire framework is a logical extrapolation of this starting point. The charge of smuggling in an "ought" fails because the selective filter is causal, not logical or moral. To be clear, an individual agent can rationally choose a course of action that contradicts endurance. However, the predicates guiding such actions cannot become stable features of a shared, enduring network. A network containing the predicate "our group should not defend itself" is not eliminated because it would lose a public argument; it is eliminated because the group that adopts it is outcompeted or ceases to exist.

Therefore, the system's anchor is not a value, but a brute fact of selection. We do not need to value survival for it to be the non-negotiable constraint that shapes the entire system, any more than we need to value gravity for it to determine which structures stand and which fall. Endurance is not the "good" we aim for; it is simply the condition of remaining in the game.

### **5.5 The Objection from Deflationary Truth (Reconnecting Truth and Viability)**

**Objection:** The theory's deflationary account of truth severs the connection between what is 'true' and what is 'good'. If 'truth' is merely a label for coherence *within* a network, why should the external property of that network's *viability* have any normative force for an agent?

**Reply:** This objection correctly distinguishes between internal coherence ('truth') and external viability, but it misses that the former is an **evolutionary indicator** of the latter. The normative force of a 'true' predicate arises from the **pragmatic origin of the network itself.**

A shared network is not an arbitrary logic puzzle; it is a tool for survival forged in the crucible of historical trial and error. Therefore, the descriptive fact that a predicate is 'true' (i.e., coherent with one of our most successful, time-tested networks) is not a mere logical curiosity. It is a powerful **empirical signal** that the predicate is an integral component of a highly viable strategy for navigating reality.

To trust what is 'true' in our best networks is not a moral commandment; it is to make a **pragmatic bet**. It is to bet that the cumulative, hard-won lessons of history—encoded in the coherent structure of our most resilient networks—are a more reliable guide to future success than any individual's private, untested intuitions.


### **5.6 The Objection from the Normativity of Endurance (The Grounding Problem Revisited)**

**Objection:** The claim that the "drive to endure" is merely a "constitutive precondition" is a philosophical sleight of hand. The theory still requires us to *care* about what survives this process, a normative commitment it cannot justify internally.

**Reply:** This objection is answered by the paper's explicit **descriptive turn**, as outlined in Section 1.2. EPC does not, and cannot, provide a non-circular answer to the question "Why *should* I value endurance?" To do so would be to attempt to square the meta-ethical circle. Instead, it makes a more modest but powerful claim: the selective filter of endurance is the **de facto, causal reality** that has *in fact* shaped every normative system that currently exists.

The system's anchor is not a value we choose, but a brute fact of selection we observe. We do not need to *value* survival for it to be the non-negotiable constraint that shapes our normative systems, any more than we need to *value* gravity for it to determine which structures stand and which fall. A network predicated on its own demise is not philosophically wrong; it is causally eliminated. EPC's project is not to justify this ultimate constraint, but to describe the emergent epistemic system that operates within it.

### **5.7 The Objection from the Inaccessibility of the Apex Network**

**Objection:** The "Apex Network" is epistemologically problematic. It serves as the ultimate standard of objectivity, yet it is defined as being fundamentally inaccessible. An unknowable standard is no standard at all.

**Reply:** This objection conflates **epistemology** (what we can know) with **ontology** (what is real). The Apex Network is not a "regulative ideal" in the sense of being a mere philosophical fiction. It is posited as an **objective, emergent, historical fact.** Given the premises of the theory—that countless networks are constantly being filtered by reality—it is an *inevitable structural consequence* that there will be a maximal, coherent set of predicates that has, to date, best survived this process. The Apex Network is simply the *name* we give to this real, emergent object. Its existence is a direct consequence of the system's dynamics.

The challenge is purely **epistemological**. Our access to this real object is incomplete, mediated, and fallible, just as a historian's access to the full reality of the Roman Empire is incomplete. This does not render the object non-existent or the project of approximating it meaningless. On the contrary, it grounds the possibility of making objective, truth-apt claims. A statement is **objectively true** if it is coherent with the Apex Network, and **objectively false** if it is incoherent with it.

Our epistemic humility comes from the fact that we can never be 100% certain that our current, best-approximated network perfectly mirrors the Apex Network. Our confidence in a truth claim is therefore proportional to the strength of our evidence—primarily, the long-term, cross-cultural data gathered via our negative methodology (the **Negative Canon**). We can be highly confident that "slavery is acceptable" is objectively false because our historical "nautical chart" shows with overwhelming evidence that this predicate is part of a wrecked system. Our claim to objectivity rests on the reality of that historical wreckage, not on a perfect vision of the safe harbor.


## **6. Situating the Proposal: A Unified Alternative**

**Emergent Pragmatic Coherentism (EPC)** synthesizes insights from several traditions to occupy a unique position in the philosophical landscape. By reframing the debate around a unified theory of justification, it offers a novel approach to long-standing problems in metaethics.

First, EPC is a form of **realism without mystery**. It is a moral realist theory because it holds that there are objective truths about which moral networks are superior to others. This objectivity, however, is **procedural, not substantive**. The truth-makers for moral claims are not mysterious, non-natural properties but the objective, empirical facts about which networks prove most viable against the real-world constraints of pragmatic selection. The validity of a moral predicate is thus an emergent, relational property, much as the ‘fitness’ of an organism is a real, objective property of its relationship with an environment. To put it plainly: truth is a property internal to a network’s coherence, while viability is an objective property of that network’s external relationship with reality.

This specific type of procedural realism places EPC firmly within the tradition of **pragmatic naturalism**. EPC is built upon this foundation, sharing its commitment to an empirically-grounded worldview that treats morality as an evolving, natural phenomenon. However, it distinguishes itself from a more generalized pragmatic naturalism by providing a more rigorous and systematic philosophical architecture. While many pragmatic naturalisms gesture toward concepts like "social learning" or "inquiry," EPC proposes a more structured model with three distinct contributions: (1) it posits a formal emergent structure—a **nested hierarchy of networks**—to give a specific architecture to the vague concept of "shared knowledge"; (2) it provides a **causal, rather than purely normative, filter**—the hierarchy of pragmatic costs—to explain *why* certain networks fail over time due to brittleness and high energy costs; and (3) it offers a naturalistic basis for fallibilist objectivity through the theoretical construct of the **Apex Network**.

The necessity for such a rigorous architecture is vividly illustrated when the core intuitions of pragmatic naturalism are articulated without a systematic framework. For example, in public discourse, one can observe thinkers like Steven Bonnell (Destiny) articulating a "proto-theory" with similar starting points: that morality is grounded in shared preferences, and that radical value conflicts are ultimately resolved by pragmatic conflict where the more viable system wins (O’Connor 2021). This is cited not as philosophical evidence, but as a real-world illustration of a powerful but incomplete intuition. Lacking a formal architecture, this view predictably runs into classic philosophical dead ends, forcing the concession that moral progress is merely a subjective preference and that the preference against genocide is ultimately the same kind of preference as one's taste in food.

This is precisely the explanatory gap that EPC's descriptive model is built to fill. By replacing subjective "preferences" with the universal "drive to endure," and by analyzing outcomes through the objective, causal hierarchy of pragmatic costs, EPC provides a robust, non-subjective explanation for why these two types of predicates are systemically different. It takes the raw intuition of pragmatic selection and provides the philosophical machinery to model a system of procedural objectivity that can withstand the classic challenges of relativism.

This EPC framework should be understood as the systematic completion of the **Quinean project**, itself a direct heir to **American Pragmatism**. Quine’s demolition of the analytic/synthetic distinction was the first step, unifying all descriptive claims within a single, pragmatic web of belief. EPC takes the second and final step, unifying descriptive and normative claims within the same framework. It inherits Quine’s core commitments—fallibilism, pragmatism, and the rejection of a priori firewalls—but where Quine described the static architecture of an individual’s web, EPC identifies the missing piece: the **dynamic, evolutionary engine** of pragmatic selection. It fulfills John Dewey’s project of dissolving dualisms, scales up William James’s individualistic concept of “what works,” and provides a naturalistic answer to C.S. Peirce’s “end of inquiry”: the Apex Network is not an ideal limit, but the messy, emergent result of what has *actually survived* our collective experiment. This realism distinguishes EPC from the anti-representationalism of neopragmatists like Richard Rorty. Where Rorty replaces the quest for objectivity with solidarity, EPC argues that lasting solidarity is an **emergent property** of a network that has achieved objective pragmatic success. The sea is real, and it sinks ships built on flawed designs.

This unique synthesis of holism and evolutionary selection also distinguishes EPC from other attempts to move beyond the foundationalist-coherentist divide. Unlike **Foundherentism**, as proposed by Susan Haack, EPC does not rely on an analogy to a crossword puzzle where empirical data and internal coherence mutually support each other. Instead, EPC posits a more ruthless, eliminative filter: pragmatic viability. An incoherent but temporarily functional network may persist, while a highly coherent but pragmatically unviable network will ultimately fail. Furthermore, while EPC shares a structural language with some forms of **Network Epistemology**, its primary focus is not on the static analysis of belief-linkages but on the **diachronic, evolutionary dynamics** that forge and destroy these networks over historical time. The central question for EPC is not "How is this network structured?" but "What are the long-term survival prospects of a system running on this network?"

Finally, while EPC contains a **constructivist element** in that it treats networks as human constructions, it is more accurately described as a form of **procedural realism** that is more robust than both its constructivist and simpler evolutionary rivals. It avoids the pitfalls of some forms of **Evolutionary Ethics** that attempt to derive normative content directly from our evolved psychological dispositions. EPC makes no such direct derivation; the ultimate test of a predicate is not its evolutionary origin, but its long-term pragmatic performance within a complex system.

This is also what distinguishes EPC from a more conventional **Constructivism**. A purely constructivist theory ultimately grounds normativity in the coherence of our own attitudes, whether individual or collective. EPC, by contrast, argues that the coherence of our attitudes is insufficient. The ultimate arbiter of a network's validity is not its internal logical structure but its **external relationship with the selective pressures of reality.**

This stance provides EPC's definitive answer to Sharon Street's "ideally coherent Caligula." Unlike Korsgaard’s constitutivism, which grounds normativity in the self-reflective structure of agency, EPC grounds it in the external pressures of endurance and pragmatic viability. This contrast shows how EPC avoids the charge of normativity being a projection of our attitudes alone. A constructivist might struggle to condemn Caligula if his monstrous attitudes are perfectly coherent. For EPC, Caligula's internal coherence is irrelevant. The network that produced and sustained such a predicate was an **objective, pragmatic, evolutionary failure**, judged not by our disapproval, but by the immense, real-world systemic friction it generated. This stance-independence is what makes the theory a form of realism, and it also allows EPC to suggest that the ingenious project of **quasi-realism** is a brilliant solution to a problem that a more sophisticated, realist-compatible epistemology like EPC dissolves from the outset. By granting moral claims genuine, albeit network-relative, truth-aptness, it resolves issues like the Frege-Geach problem without abandoning the pursuit of objectivity.

## **7. Conclusion: Inquiry as a Pragmatic Project**

Emergent Pragmatic Coherentism ultimately argues that **morality is a project, not a given.** It reframes all inquiry—scientific, political, and ethical—as part of the same fundamental human endeavor: the multi-generational effort to build the most viable rulebook for navigating our shared existence. On this view, an "is" is a predicate about how the world appears to function, and an "ought" is a time-tested predicate about how best to act within it. Both are judged in the same ultimate court of long-term pragmatic success.

This framework allows us to be both **humble and hopeful.** We are humble in knowing our current rulebook is imperfect and that our access to the broader lessons of history is fallible. Yet we can be hopeful, because progress is a real, observable phenomenon. We can state with confidence that abolishing slavery was not a mere change of opinion; it was a profound act of **debugging our societal code.** Progress occurs when we treat suffering, dissent, and instability not as distractions but as primary epistemological signals of systemic failure. They are not mere obstacles, but essential data points in our collective effort to refine our moral maps

The authority of an “ought” is not found in a separate metaphysical realm of values... It is found in the immense, objective, and procedural weight of the lessons we have collectively learned from what has, and has not, survived our species’ long and often brutal encounter with reality.  An "ought," on this view, is simply a predicate that has earned its truth by proving its worth within a pragmatically viable network.

---

### **References**

Blackburn, Simon. *Essays in Quasi-Realism*. Oxford University Press, 1993.

Dewey, John. *The Quest for Certainty: A Study of the Relation of Knowledge and Action*. Minton, Balch & Company, 1929.

Haack, Susan. *Evidence and Inquiry: A Pragmatist Reconstruction of Epistemology*. 2nd ed. Prometheus Books, 2009.

Harris, Sam. *The Moral Landscape: How Science Can Determine Human Values*. Free Press, 2010.

James, William. *Pragmatism: A New Name for Some Old Ways of Thinking*. Longmans, Green, and Co., 1907.

Joyce, Richard. *The Evolution of Morality*. MIT Press, 2006.

Kitcher, Philip. *The Ethical Project*. Harvard University Press, 2011.

Korsgaard, Christine. *The Sources of Normativity*. Cambridge University Press, 1996.

O’Connor, Alex (CosmicSkeptic). “Why Ethics Are Subjective - Destiny” *YouTube*, May 29, 2021. Video, 1:17:34. https://www.youtube.com/watch?v=Izg97iGcTk4.

O'Connor, Cailin. *The Origins of Unfairness: Social Categories and Institutional Inertia*. Oxford University Press, 2019.

Peirce, Charles Sanders. “How to Make Our Ideas Clear.” *Popular Science Monthly* 12 (January 1878): 286–302.

Putnam, Hilary. *The Collapse of the Fact/Value Dichotomy and Other Essays*. Harvard University Press, 2002.

Quine, W.V.O. “Two Dogmas of Empiricism.” *The Philosophical Review* 60, no. 1 (1951): 20–43.

Quine, W.V.O. *Word and Object*. MIT Press, 1960.

Rorty, Richard. *Contingency, Irony, and Solidarity*. Cambridge University Press, 1989.

Sellars, Wilfrid. *Empiricism and the Philosophy of Mind*. Harvard University Press, 1997.

Street, Sharon. “A Darwinian Dilemma for Realist Theories of Value.” *Philosophical Studies* 127, no. 1 (2006): 109–66.