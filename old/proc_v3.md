# **A Procedural and Naturalistic Model of Moral Objectivity**

## **Abstract**

This paper confronts the long-standing is/ought problem, arguing it is an artifact of a static epistemology. We deploy the dynamic framework of the Network of Predicates, established in "The Architecture of Inquiry," to complete its central task: forging a rigorous external test for a network’s claims. We reframe moral inquiry as a form of empirical cartography: the project of mapping a real, mind-independent "landscape of viability"—the Apex Network.

The methodology for this project is the **Pragmatic Test**, a falsifiable research program that assesses a normative system’s **Pragmatic Viability** by measuring its real-world systemic costs and normative brittleness. Its primary tool is the construction of a **Negative Canon**—an evidence-based catalogue of "failed normative designs" that have been historically falsified by their own unsustainable costs, effectively charting the impassable terrain of the moral landscape.

This model provides a non-teleological account of moral progress as the process of debugging our societal maps. It grounds objectivity in observable facts about which designs prove most resilient, thereby naturalizing the referent of moral terms to answer error theory and transforming evolutionary pressures from a debunker into the very engine of objectivity. The result is a form of **procedural realism** that reframes ethics as a diagnostic science—a form of systemic moral risk assessment.

## **1. Introduction: Reframing the Is/ought Problem**

### **1.1 The Metaethical Impasse**

For centuries, a chasm has divided our landscape of knowledge: the gap between the world of facts ("is") and the world of values ("ought"). This apparent division, famously articulated by Hume, is more than a philosopher's puzzle; it is an intellectual crisis. It has pushed metaethics into a long and intractable stalemate. On one side, moral realists defend the objectivity of our values, but often at the cost of invoking mysterious, non-natural properties incompatible with a scientific worldview. On the other, a host of anti-realist positions—from non-cognitivism to error theory—reduce our deepest normative commitments to mere expressions of emotion, subjective preferences, or a collective, systematic delusion. The cost of this impasse is profound: it cripples our ability to ground normative critique and leaves the public square vulnerable to the charge that morality is, at bottom, nothing more than arbitrary taste or the raw exercise of power.

### **1.2 A New Diagnosis: An Unfinished Map**

This paper argues that the is/ought problem is not a feature of a divided reality, but a conceptual artifact of a static epistemology. The solution is not to build another speculative bridge across this artificial chasm, but to deploy the dynamic, evolutionary engine established in "The Architecture of Inquiry." That work modeled all our collective knowledge as a public Network of Predicates—a fallible map for navigating an objective landscape of pragmatic constraints. The is/ought gap, on this view, is a cartographical error that arises when we use the wrong tools to chart the territory.

"The Architecture of Inquiry" detailed the internal logic of the map, showing how networks maintain coherence and learn via mechanisms like the Functional Transformation. However, it left a crucial task unfinished: forging the Pragmatic Anchor, the external test that ensures the map accurately corresponds to the territory. This paper completes that project. By articulating a rigorous, falsifiable methodology for this external test, we will show how both descriptive and normative claims are adjudicated in the same ultimate court of real-world consequences.

### **1.3 Thesis: Procedural Realism and the Pragmatic Test**

This paper’s thesis is that by forging this anchor, we can ground a new form of naturalistic realism: procedural realism. Moral objectivity is grounded not in mysterious properties, but in mind-independent facts about the landscape of viability—a real, emergent territory we call the Apex Network. An "ought," on this view, is not a different kind of fact, but a hard-won discovery about this territory; a design principle that has been empirically confirmed to be a viable route on our collective map.

The argument will proceed in three stages. First, we will forge the methodology for the Pragmatic Test, showing how it functions as a tool for empirically charting the boundaries of the Apex Network. We will do this primarily through a negative methodology: the construction of a Negative Canon of demonstrably failed normative designs. Second, we will apply this framework to metaethics, introducing Emergent Pragmatic Coherentism (EPC) to model moral progress as the real, observable work of revising our societal code to better align with the Apex Network. Finally, we will situate EPC as a novel form of procedural realism, one that preserves the objectivity of moral claims while providing a powerful, naturalistic answer to the challenges of error theory, quasi-realism, and evolutionary debunking arguments.

## **2. Deploying the Architecture: Forging the Pragmatic Anchor**

Our model of moral objectivity is the direct application of a general, dynamic epistemology. It begins by extending Quinean holism from an individual's "web of belief" to a social and evolutionary framework. Every agent navigates reality using their own web, but because all agents face the shared constraints of a common world, their individual webs are forced to overlap wherever they must coordinate their actions. This is not a top-down agreement but a bottom-up emergence: shared pragmatic challenges generate pragmatic pushback, forcing a convergence on solutions that work. The result is the emergence of a public, structural Network of Predicates—the primary unit of analysis for our model of objectivity.

As established in "The Architecture of Inquiry," these networks are dynamic learning systems that upgrade their own processing rules via the Functional Transformation. That work provided a full account of the *internal* test for justification: a proposition must be coherent with a network's existing structure. However, a complete theory of objectivity requires a two-part, procedural test:

1.  **The Internal Test (Coherence):** The proposition must fit within the network's logical and explanatory structure.
2.  **The External Test (Viability):** The network itself must be externally validated by its long-term success against the constraints of the real world.

The previous paper solved for the internal test, detailing the architecture of coherence. But it left the external test—the **Pragmatic Anchor**—as a necessary but unanalyzed requirement. This leaves us with an incomplete picture. A network that only satisfies the internal test risks being a self-validating fantasy—a well-drawn map of a fictional world, vulnerable to the classic charge of relativism. The primary task of this paper, therefore, is to complete the project. We will now forge that anchor. By articulating a rigorous, falsifiable methodology for the external test of pragmatic viability, we will ground our map in the unforgiving territory of reality.

## **3. The Pragmatic Test: Charting the Landscape of Viability**

The two-part test for objectivity requires that an internally coherent network also be externally validated. This section forges the methodology of that external test—the Pragmatic Test. This is our primary instrument for empirically charting the objective landscape of constraints that forms the Apex Network. It is not a single experiment but a programmatic approach to a posteriori inquiry, drawing on the methods of complex systems science and comparative history (Turchin 2003; Tainter 1988). It is designed to measure the friction generated when a network's design collides with this landscape, providing a rigorous standard for assessing its viability.

### **3.1 Grounding the Filter: The Drive to Endure**

Before defining our metric, we must justify the authority of the filter itself. The answer is that a system's capacity to endure is not a value to be chosen, but the constitutive precondition for having values at all. This filter’s authority has a dual status that protects it from charges of circularity. Descriptively, it is an observable evolutionary fact that systems which fail to preserve their informational structure vanish. Transcendentally, it is the inescapable precondition for any inquiry whatsoever. To evaluate any claim is to participate in a practice that unfolds over time and thus to presuppose the continuity of the system that makes evaluation possible.

It is therefore crucial to distinguish this systems-level analysis from a psychological claim about individual motivation. The "drive to endure" operates as a selective filter on the network itself, not as a motivational force within agents. Individuals may sacrifice their lives for glory or salvation, but the informational networks that license such sacrifices can only be evaluated historically if the network itself—through its carriers, institutions, or texts—maintains sufficient continuity. The claim is not that agents must value survival, but that networks which systematically undermine their own substrate face a structural disadvantage in the long-term transmission of information.

### **3.2 From Endurance to Viability: A Measure of Efficiency**

This inescapable filter provides the non-normative backdrop for our metric. The measure of the Pragmatic Test is not the "survival of the fittest" in a crude, Social Darwinist sense; it is Pragmatic Viability. We define this as a measure of a system's homeostatic efficiency: its ability to maintain and propagate its core informational structure with minimal coercive and energetic cost. This distinction between pragmatic viability and mere endurance is critical. An oppressive empire that persists for a millennium through brutal force is enduring, but it is not viable. It is a high-cost, inefficient, and normatively brittle system whose stability masks a profound internal fragility. Viability is a measure of a network's systemic health and adaptive efficiency, not just its longevity.

### **3.3 The Texture of Normative Pushback**

While the Pragmatic Test is a unified standard, the texture of pragmatic pushback differs by domain. For a normative predicate, pushback is not a simple experimental failure but a complex social signal. It manifests as social friction: eroding trust, breakdowns in cooperation, widespread dissent, riots, and civil conflict. The aggregation of this social friction generates the measurable costs that the Pragmatic Test analyzes.

### **3.4 The Diagnostic Toolkit: A Hierarchy of Systemic Costs**

A network's lack of viability manifests as measurable Systemic Costs. The table below outlines our core diagnostic tools for identifying these empirical signatures of pragmatic failure.

| Conceptual Tool | Definition | Potential Empirical Proxies |
| :--- | :--- | :--- |
| **First-Order Costs** | Direct, material consequences of a network's misalignment with reality. | - Excess mortality/morbidity rates<br>- Frequency of internal violent conflict<br>- Bioarchaeological stress markers |
| **Systemic Costs** | Non-productive resources spent to manage First-Order Costs. | - **Energetic:** Ratio of internal security budget to GDP<br>- **Informational:** State media expenditure; censorship laws |
| **Normative Brittleness** | A network's vulnerability to collapse under novel shocks. | - High and rising Systemic Costs<br>- Low rates of innovation and adaptation<br>- High dependency on a single resource |

This causal link is the core of the diagnostic method: high First-Order Costs (e.g., widespread suffering) are the disease; the resulting high Systemic Costs (e.g., a large secret police force) are the fever. One reliably predicts the other, providing falsifiable grounds for diagnosing a network's low pragmatic viability.

### **3.5 The Primary Method: Charting the Negative Canon**

Following Karl Popper (1959), our most reliable knowledge is not of what is definitively true, but of what is demonstrably false. Therefore, the primary empirical project of this methodology is a negative one: the construction of a Negative Canon. This is a robust, evidence-based catalogue of failed normative designs—the known hazards and impassable terrain on our map of the Apex Network.

The predicate `slavery is an acceptable organizing principle` belongs in this canon, as the historical record provides overwhelming evidence that networks built on it consistently generate immense costs (Patterson 1982). Consider a less obvious example: the predicate `political succession should be determined by fratricide or elite combat`. Networks that adopted this principle—from the Mongol Empire after Genghis Khan to the Ottoman Empire before institutionalized primogeniture—consistently generated catastrophic First-Order Costs in the form of recurring civil wars and systemic instability, placing the predicate firmly in the Negative Canon.

Crucially, the data signaling these failures is generated most intensely at the points of greatest systemic friction. This provides a pragmatic justification for the central insight of standpoint epistemology (Harding 2004). The testimony of the marginalized is treated as epistemically privileged, not as a concession to sentiment, but as a diagnostic necessity. Those experiencing the highest First-Order Costs have the most direct access to the data signaling a network’s impending failure.

### **3.6 Methodological Rigor: Scope, Contingency, and Falsification**

The Pragmatic Test is a powerful tool, and its rigor depends on candor about its methods and limitations. First, EPC is a macro-historical theory of social ethics, most powerful for diagnosing the failure modes of large-scale, complex societies, which form its primary evidentiary base.

Second, we acknowledge that historical events are multi-causal. The Pragmatic Test does not claim that normative predicates are the sole determinant of a network's fate. Our claims are explicitly probabilistic, not deterministic. The methodology relies on the tools of comparative historical science: analyzing large datasets to identify statistically significant patterns and using controlled comparisons between societies that faced similar shocks but had different normative structures. The goal is not to prove that a predicate alone caused a specific collapse, but to demonstrate with high confidence that it reliably contributes to the normative brittleness that increases the probability of collapse under stress.

Finally, the framework's central causal claim is falsifiable. The theory would be decisively broken if broad, cross-cultural historical analysis revealed no statistically significant correlation between a network's internal costs and its long-term viability. If high-friction, coercive systems were consistently found to be no less brittle than low-friction, cooperative ones, the framework would be falsified. Its claims about objectivity remain, in principle, accountable to the empirical court of history.

## **4. Emergent Pragmatic Coherentism (EPC): A Procedural Realism**

With the methodology of the Pragmatic Test in place, we can now deploy this full framework to the specific, difficult challenge of moral cartography. The result is a model we term Emergent Pragmatic Coherentism (EPC). EPC reframes moral inquiry not as a search for mysterious, non-natural properties, but as the fallible, empirical project of mapping the contours of the Apex Network. It defends a procedural realism where moral truths are not invented but are objective, mind-independent facts about which principles of social organization prove maximally viable. A "moral truth," on this view, is a hard-won, a posteriori discovery about this real, emergent landscape.

### **4.1 Moral Claims as Falsifiable Hypotheses about a Real Territory**

The foundational move of EPC is to treat normative claims as high-level, falsifiable hypotheses about the structure of the Apex Network. Moral terms like "...is wrong" or "...is just" are treated as predicates—functional tools used to draw features on our collective map. From this procedural perspective, the is/ought gap dissolves at the level of justification. Both a descriptive predicate (`...is an atom`) and a normative predicate (`...is wrong`) are operators within a network whose objective truth is adjudicated by the same unified test: a proposition is objectively true if it coheres with the real, mind-independent Apex Network. Our epistemic justification for holding it as true, however, is our fallible, two-part procedure: the proposition must cohere within a Shared Network that has itself demonstrated long-term pragmatic viability.

This unified test does not imply an identical process of testing. The feedback loop for "water boils at 100°C" is rapid and direct. The feedback loop for "autocracy is an unstable form of government"—a high-level hypothesis about a complex adaptive system—is slow, diffuse, and plays out over generations. This observed asymmetry is a direct prediction of the model. The complexity of the system under investigation determines the timescale and texture of the Pragmatic Pushback. The authority of an "ought" is therefore harder-won, emerging not from a single experiment, but from the immense, procedural weight of aggregated historical evidence.

### **4.2 Moral Progress as Aligning the Map with the Territory**

EPC provides a robust, non-teleological account of moral progress as a real, observable phenomenon. Progress is not a march toward a utopian endpoint, but the backward-looking, problem-solving process of debugging our societal map to better align with the territory of the Apex Network. This occurs by identifying and removing predicates from the Negative Canon and locking in the successful discovery through systemic learning.

The historical abolition of chattel slavery serves as the paradigm case. The predicate `slavery is an acceptable organizing principle` was a core feature of many historical maps, but it was always objectively false, meaning it was incoherent with the real landscape of viability. This incoherence manifested as catastrophic Pragmatic Pushback, generating a pathologically high **Systemic Brittleness Index (SBI)**. The network’s **Coercion Ratio**—the proportion of resources spent on internal control versus productive capacity—was extreme, and its **Patch Velocity** was high, constantly generating ad-hoc ideological justifications to insulate its core predicate from the data of its own dysfunction. The system endured not because it was viable, but by accumulating a crippling level of epistemic debt.

The arguments of abolitionists were, in effect, a superior cartographical hypothesis. The replacement predicate—`slavery is wrong`—gained traction because it represented a more accurate model of how to construct a viable, low-cost social system. The eventual triumph of abolition was therefore not a mere change of opinion but a profound act of epistemic correction: a demonstrably failed design principle was erased from the map. We can state with objective confidence that this was progress because the resulting network was better aligned with the Apex Network. This progress was then locked in as the new predicate underwent a **Functional Transformation**, being repurposed from a contested moral claim into a foundational, non-negotiable axiom in modern legal and constitutional networks.

### **4.3 The Objective Topography of the Moral Landscape**

Our procedural realism predicts that the Apex Network itself has an objective topography. Moral inquiry is the ongoing project of mapping its features, which include both narrow constraints and open plains.

1.  **The Convergent Core: "Mountain Passes" of the Apex Network.** The Core consists of universally viable normative predicates that represent singular, or near-singular, stable solutions to universal coordination problems. These are the "mountain passes" of the pragmatic landscape—narrow routes any successful network must discover. Norms of basic reciprocity, for example, are a likely candidate, representing a game-theoretically stable solution to the Prisoner's Dilemma (Axelrod 1984). We identify these features empirically through the Test of Independent Convergence.

2.  **The Pluralist Periphery: "Viable Plains" of the Apex Network.** The Periphery accounts for legitimate cultural disagreements without collapsing into relativism. It corresponds to the "viable plains" of the landscape—broad areas where multiple, culturally-specific yet equally viable routes exist. A well-regulated capitalist welfare state and a robust social democracy, for example, may represent distinct but demonstrably viable strategies for organizing a modern economy. The debate between them is an empirical negotiation over second-order costs and benefits, not a sign that one must be objectively wrong.

This two-tiered structure grounds a robust, non-parochial cultural critique. The judgment that a practice like "honor killings" is objectively wrong is not rooted in cultural superiority. It is a falsifiable empirical claim: the practice reliably generates catastrophic First-Order Costs and belongs firmly in the Negative Canon, representing an attempt to chart a path through impassable terrain.

### **4.4 EPC as a Diagnostic Research Program**

The framework's true test lies in ambiguous cases. Here, its value is as a diagnostic, not a dogmatic, tool. It transforms intractable value-clashes into a shared, evidence-based research program by generating falsifiable hypotheses about the long-term viability of competing social technologies. For instance, the short-term instability following a democratic transition can be modeled as a high-cost "investment" made to pay down the immense epistemic debt of a less viable autocratic system. The EPC hypothesis is that, once stabilized, the new democratic network will demonstrate greater long-term pragmatic viability—lower overall systemic costs and higher resilience to novel shocks—than the autocracy it replaced. By framing complex issues as competing, falsifiable hypotheses about measurable pragmatic consequences, EPC transforms moral debate from a conflict of wills into a shared diagnostic project.

### **4.5 The Unit of Selection: Replicators and Interactors**

To be precise about this evolutionary process, we must clarify the unit of selection. EPC adopts a generalized model, treating a network's informational structure—its core normative predicates and their relations—as the replicator. The social group and its institutions serve as the interactor: the physical vessel through which the normative code is instantiated, expressed, and tested. A normative system "survives" by successfully propagating its core organizational principles through time. This can occur even if the original interactor collapses, as the informational code can persist latently in texts or legal traditions, capable of being re-instantiated later. The rediscovery of Roman legal principles during the Renaissance is a prime example. This distinction allows our systems-level analysis to avoid the pitfalls of naive group selection, focusing instead on the long-term viability of the informational code itself.

## **5. Defending the Model: Answering Core Objections**

With the EPC framework fully articulated, we must now test its resilience against the most pressing critical objections. The model's ability to provide robust, non-circular answers to these challenges strengthens the case for its adoption as a coherent naturalistic framework for moral objectivity. We will address four: the stability of evil, the power of ideology, the asymmetry of testing, and the fundamental grounding problem.

### **5.1 Objection: The Stability of Evil ("Might Makes Right")**

A critic might argue that any society that endures for millennia, no matter how oppressive, must have "won" the pragmatic test, thereby making its predicates objectively true. This objection, however, rests on two crucial errors: it mistakes mere endurance for the richer concept of pragmatic viability, and it misidentifies temporary stability for genuine resilience.

As established, viability is a measure of a system's homeostatic efficiency. An oppressive state that persists through immense coercion is, by definition, not viable; it is a high-cost, inefficient system whose endurance is a measure of the energy it must burn to manage its own self-inflicted instability. Such systems are functionally parasitic, their stability subsidized by external extraction like conquest or internal extraction that offloads costs onto a subjugated populace, masking their internal normative decay.

Furthermore, such systems often persist by becoming trapped in a sub-optimal but stable equilibrium, or a "pragmatic plateau." While not maximally viable, they have developed coercive and ideological mechanisms sufficient to suppress internal pressures for change under normal conditions. The inherent normative brittleness of such a system is therefore only fully revealed when it faces a significant exogenous shock—such as a new technology, a climate crisis, or contact with a more viable external network. These shocks change the fitness landscape, and systems trapped on a low pragmatic plateau are often unable to adapt, leading to catastrophic collapse where a resilient, low-cost network would have survived. The endurance of such systems does not make their predicates true; it merely makes them long-running, fragile experiments whose wreckage we chart to build the Negative Canon.

### **5.2 Objection: The Power of Ideology**

A more sophisticated objection concedes that oppressive systems generate costs but argues that ideology can co-opt the revision process. A network, it is argued, can create "patch" predicates like “your suffering is a noble trial” to convince agents to endure pragmatic failure. This objection correctly identifies a key tactic in network evolution, but it underestimates its non-negotiable price.

Ideological patches are never pragmatically free. They introduce cascading Systemic Costs that make them a powerful diagnostic indicator of dysfunction. To maintain a flawed core predicate, a network must invest heavily in an expensive apparatus of ideological maintenance: propaganda, surveillance, and coercion. These are measurable Energetic and Informational Costs that divert immense resources from productive capacity, raising the network's overall Systemic Brittleness Index (SBI). The constant need to generate ad-hoc justifications increases the network's Patch Velocity, a key sign of a degenerating research program.

The very need for this costly ideological insulation is itself an epistemic red flag. We have a powerful pragmatic reason to be deeply skeptical of any network that requires immense and continuous energy expenditure to suppress dissent and explain away suffering. The presence of these defense mechanisms is a primary signal that the network’s core predicates are misaligned with reality, giving us a reason to heed dissenters now as the canaries in the coal mine of systemic failure. A healthy, viable network does not need to spend a third of its budget convincing its citizens that they are not suffering.

### **5.3 Objection: The Asymmetry of Testing**

A third objection targets the claim of a unified test for all predicates, arguing that the rapid, decisive test for an empirical claim is so different from the slow, diffuse test for a moral claim as to render the unified framework meaningless. This observed asymmetry, however, is not a flaw in the model but a direct and crucial prediction of it. EPC posits a unified filter—pragmatic selection—while acknowledging that the complexity of the system being tested determines the timescale and texture of the feedback.

An empirical predicate about a simple physical system yields rapid and easily replicable feedback loops. A moral predicate, as a high-level hypothesis about structuring a complex adaptive social system, necessarily yields feedback that is slow, distributed, and subject to historical contingency. This difference in velocity does not imply a difference in the ultimate arbiter, which for both is the non-negotiable feedback from reality. This asymmetry is explanatorily powerful: it explains precisely why moral knowledge is so much harder-won than simple empirical knowledge and why it requires the aggregation of vast amounts of historical data. Rather than undermining the framework, this observed difference provides strong evidence for its descriptive adequacy.

### **5.4 The Grounding Problem Revisited**

The final and most fundamental challenge is that the theory appears circular, smuggling in the ultimate value of endurance. This objection misunderstands the model's two-part, non-circular defense, which combines a naturalized transcendental argument about the arena of justification with an instrumental argument about the source of normative force.

First, the arena of justification. Endurance is not a value to be chosen from a list; it is the constitutive precondition for having a list at all. Its primacy is established by a naturalized transcendental argument. It is transcendental in that any form of inquiry unfolds over time and thus presupposes the continuity of its own informational substrate. To question the primacy of endurance is to perform an act that is only possible within a system that has already solved for it. It is naturalized in that this is a physical and structural requirement for any real-world information-bearing system, not a feature of pure reason. This gives the filter of endurance a dual status: descriptively, it is an observable evolutionary fact that non-persistent systems vanish; transcendentally, it is the inescapable condition that makes having such facts possible. This argument does not prove "endurance is good"; it shows that endurance functions as the inescapable, non-normative arena in which the viability of all other values is tested.

Second, with endurance established as the non-normative arena, the "ought" that emerges from EPC is a wide-scope, instrumental, and system-level piece of strategic advice. It does not derive a categorical command from descriptive premises. Instead, it offers a conditional imperative: if a system has a de facto commitment to persisting through time (which any inquiring system already has), then it has a powerful, evidence-based reason to adopt predicates that enhance pragmatic viability and avoid those in the Negative Canon. This "ought" is purely instrumental. Its normative force arises through internal critique, supplying a standard of rationality for the ongoing project of any society that seeks to endure.

## **6. Situating EPC in the Metaethical Landscape**

Emergent Pragmatic Coherentism is not an isolated proposal but a synthesis that carves out a unique third way in metaethics. It offers a form of moral realism that is staunchly naturalistic and anti-metaphysical; a form of pragmatism that grounds a robust, externalist objectivity; and an evolutionary theory that avoids relativism and provides a powerful response to debunking arguments. This section will situate the EPC model by demonstrating its distinct advantages over major rival accounts.

### **6.1 A Procedural, Pragmatic Realism**

EPC is a form of procedural, pragmatic realism. It is realist in positing objective, mind-independent truths about the viability of normative systems. It is procedural in grounding these truths not in mysterious, *sui generis* properties, but in the observable, empirical outcomes of the Pragmatic Test. The truth-makers for moral claims are the objective, historical facts about which network designs generate lower systemic costs and greater resilience. The validity of a moral predicate is thus an emergent, relational property, much as the ‘fitness’ of an organism is a real property of its relationship with an environment.

This externalist, systems-level focus distinguishes EPC from other influential naturalist realisms. Cornell Realists, for instance, ground moral facts in agent-centric properties, such as an individual's "objective interests" (Railton 1986). EPC’s framework is more robustly externalist because it formally shifts the unit of evaluation to the multi-generational viability of the network's informational code itself. This allows EPC to make an objective judgment on the failure of a tyrant’s network—its code is a poor long-term replicator due to the systemic costs it generates—a fact entirely independent of the tyrant's own "objective interests." EPC can therefore objectively condemn a successful tyrant where agent-centered theories may struggle.

### **6.2 The Quinean and Pragmatist Lineage**

The EPC framework is the systematic completion of the Quinean project, itself a direct heir to American Pragmatism. Quine’s (1951) demolition of the analytic/synthetic distinction unified all descriptive claims within a single pragmatic web. EPC extends this holism one decisive step further, showing that normative claims are subject to the same filtering process, thereby dissolving the final dogma: the fact/value divide. Where Quine mapped the static architecture of an individual’s web, EPC supplies the missing piece: the dynamic, evolutionary engine of pragmatic selection that operates on shared, public networks.

In doing so, EPC fulfills John Dewey’s (1929) project of a naturalized, experimental ethics. This robust realism also distinguishes EPC from the anti-representationalism of neopragmatists like Richard Rorty (1989). Where Rorty famously replaces objectivity with solidarity, EPC argues that lasting solidarity is not an alternative to objectivity, but an emergent property of a network that has achieved objective pragmatic success. The only path to genuine, enduring solidarity is through the hard, empirical work of building a more viable map.

### **6.3 Explanatory Power Against Anti-Realism**

EPC's procedural realism provides not just answers but deeper, naturalistic diagnoses of the core anti-realist challenges, revealing them to be brilliant solutions to problems generated by a flawed ontology. We agree with J. L. Mackie’s (1977) "argument from queerness": there are no strange, non-natural, intrinsically prescriptive properties woven into the fabric of the world. Mackie’s error was not his ontology but his semantics. He rightly rejected the folk-metaphysical gloss on moral terms but wrongly concluded this entailed a failure of reference. EPC offers a more powerful diagnosis: our moral discourse has always been engaged in successful but mis-glossed reference. Moral terms have been successfully, if imperfectly, tracking real, procedural facts about the pragmatic viability of social arrangements all along. The "objective wrongness" of slavery is not a queer property; it is a real, relational, and empirically discoverable property of a predicate that reliably generates catastrophic systemic costs. EPC thus completes error theory by providing a naturalistic account of the referent of our moral terms.

This same move demonstrates why the ingenious project of quasi-realism (Blackburn 1993), which seeks to explain how non-realists can "earn the right" to realist-sounding grammar, gets the causal story backward. The realist-sounding grammar of our moral claims is not something our attitudes needed to earn; it is a feature our language evolved to have because it has always been tracking an objective, procedural reality. This explains the high stakes of moral disagreement: it is not just a clash of attitudes, but a high-stakes empirical dispute about the viability of our shared social code.

Finally, this framework transforms Sharon Street’s (2006) "Darwinian Dilemma" from a challenge into a confirmation. Street poses a formidable challenge to any realism that must treat the correlation between adaptive beliefs and moral truth as an untenable coincidence. EPC resolves this dilemma by collapsing one of its horns so completely that it becomes the foundation of the other. For EPC, there is no coincidence to explain. Pragmatic viability—a specified, systems-level form of adaptiveness—is not a coincidental correlate of moral truth; it is the truth-maker itself. Evolution is not a distorting influence the realist must explain away; it is the very filtering process that grounds objectivity. Street's debunking argument becomes a causal explanation for our realism.

### **6.4 An Externalist Alternative to Other Naturalisms**

Finally, EPC's systems-level externalism distinguishes it from other influential naturalist rivals. The Neo-Aristotelian project (Foot 2001) grounds normativity in a thick, teleological concept of species-specific "flourishing." EPC shifts the unit of selection to the informational network itself, and its metric is the thin, procedural standard of viability, not a thick concept of "human goodness." This allows EPC to robustly account for the Pluralist Periphery, where multiple forms of life may prove viable so long as they do not generate catastrophic First-Order Costs. Similarly, where many accounts of moral progress (Buchanan & Powell 2018) struggle to provide a non-teleological mechanism, EPC provides one. Progress is a backward-looking process of debugging and charting failures, not a forward-looking process aimed at a final goal.

### **Table 1: A Comparative Metaethical Landscape**

| View | Truth-makers | Unit of Evaluation | Method | Objectivity |
| :--- | :--- | :--- | :--- | :--- |
| **EPC** | External viability facts (low cost, resilience) | Informational network | Comparative, failure-driven empirics | Procedural, fallibilist, externalist |
| **Quasi-realism** | Attitude-dependent projection | Attitudes/practices | Semantic explanation | Deflated, grammar-vindicating |
| **Cornell Realism** | Natural properties of human good | Agent interests | Reflective equilibrium + science | Robust, agent-centered |
| **Neo-Aristotelianism** | Flourishing of organism | Life-form | Teleological evaluation | Robust, teleological |
| **Constructivism** | Idealized procedures | Rational agents | Hypothetical agreement | Procedural, internalist |

## **7. Conclusion: Moral Inquiry as Pragmatic Navigation**

This paper began with one of philosophy's oldest chasms: the gap between "is" and "ought." We have argued that this chasm is not a feature of reality, but an artifact of a static epistemology that fails to see inquiry as what it has always been: a single, multi-generational, and fundamentally pragmatic project. The goal of this project, whether in science, politics, or ethics, is the construction of ever more viable maps for navigating a shared reality.

The core argument of Emergent Pragmatic Coherentism is that the is/ought problem dissolves under a unified theory of justification. It reframes all claims as the application of predicates within a public network, where both descriptive and normative predicates are ultimately adjudicated in the same court of long-term pragmatic selection. This offers a naturalistic model for a robust procedural objectivity, allowing us to be humble in knowing that our current maps are imperfect, yet hopeful in the knowledge that moral progress is a real, observable phenomenon. We can state with an objectivity grounded in empirical evidence that abolishing slavery was not a mere change of opinion; it was a profound act of debugging our societal code—the identification and removal of a demonstrably failed organizing principle from our Negative Canon.

Progress occurs when we treat suffering, dissent, and instability not as mere political problems to be managed, but as primary epistemological data. They are the "check engine" lights for society, signaling a misalignment between our normative network and the unforgiving constraints of reality. This gives us a powerful, pragmatic reason to listen to the marginalized, as they possess the most crucial information about where our collective map is wrong.

The authority of an "ought," therefore, is not found in a mysterious metaphysical foundation, a non-natural realm of values, or the structure of rational agency alone. It lies instead in the immense, procedural weight of historical evidence. An "ought," on this view, is a time-tested design principle coherent with our most pragmatically resilient networks—a hard-won empirical signal that it represents a viable strategy for the shared project of human cooperation.

Ultimately, EPC is more than a solution to a philosophical puzzle; it is an invitation to re-found moral inquiry as a form of **Systemic Moral Risk Assessment**. It provides a framework for diagnosing the hidden costs and latent fragilities within our most cherished institutions and for making evidence-based wagers about the long-term viability of proposed reforms. It reframes moral philosophy from a search for ultimate foundations to the ongoing, fallible craft of pragmatic navigation: the art of steering by the light of humanity's most enduring successes and the hard-won lessons from the wreckage of its failures.

## **Glossary**

**Apex Network:** The real, mind-independent, and emergent object of moral inquiry. It is not a transcendent Platonic Form but the objective, structured "landscape of viability" containing the complete, trans-historical set of maximally viable design principles for social organization. Its features are discovered empirically, primarily by charting its boundaries via the **Negative Canon**.

**Convergent Core:** An objective, topological feature of the **Apex Network**. It consists of a set of universally viable normative predicates representing singular, or near-singular, stable solutions to universal coordination problems (e.g., norms of reciprocity). These are the non-negotiable "mountain passes" of the pragmatic landscape.

**Drive to Endure:** The ultimate, non-normative filter grounding the EPC framework, established by a naturalized transcendental argument. It is not a chosen value but the constitutive precondition for any system of inquiry to exist over time—an inescapable structural constraint analogous to gravity in architecture.

**Emergent Pragmatic Coherentism (EPC):** The full metaethical framework of this paper. It grounds a **Procedural Realism** by synthesizing a dynamic, coherentist epistemology (the Network of Predicates) with an evolutionary, externalist standard of justification (the Pragmatic Test).

**Epistemic Debt:** The accumulating future costs in fragility and incoherence incurred when a network adopts a flawed "patch" (e.g., ideology) to protect a core predicate from **Pragmatic Pushback**, rather than undertaking a more viable core revision.

**First-Order Costs:** The direct, material, and measurable consequences of a network's misalignment with the landscape of viability (e.g., excess mortality, systemic violence, resource depletion). They are the primary, objective data for the **Pragmatic Test**.

**Functional Transformation:** The core learning mechanism in a **Network of Predicates**. It is the process by which a well-tested, pragmatically successful proposition is repurposed from mere data *within* the network to become part of the network's *core processing architecture* (e.g., a foundational legal principle).

**Mere Endurance:** The simple persistence of a system over time, strictly distinguished from **Pragmatic Viability**. A system can endure through high-cost, coercive means, making it **normatively brittle**. Endurance alone is often a lagging indicator of eventual collapse.

**Negative Canon:** The primary epistemological tool of the **Pragmatic Test**. It is a robust, evidence-based catalogue of "failed normative designs"—predicates empirically demonstrated to reliably generate catastrophic **First-Order Costs**. It functions as our most reliable map of the impassable terrain of the **Apex Network**.

**Network of Predicates (or Shared Network):** The public, structural system of shared knowledge that is the primary unit of selection. It emerges from the forced convergence of individual "webs of belief" under the pressure of shared pragmatic tasks and **Pragmatic Pushback**.

**Normative Brittleness:** A network's inherent vulnerability to external shocks. It is the direct consequence of high **Systemic Costs** and **Epistemic Debt**, as resources are diverted from adaptation to internal control. It is the functional inverse of resilience.

**Pluralist Periphery:** An objective, topological feature of the **Apex Network**. It represents the "viable plains" of the pragmatic landscape where multiple, culturally-specific yet equally viable solutions to an organizational problem exist. It accounts for legitimate moral disagreement without relativism, as the entire periphery is bounded by the **Negative Canon**.

**Pragmatic Pushback:** The non-negotiable, often non-propositional, feedback from reality that exerts selective pressure on a network. It is the sum of functional successes and failures that generates the **First-Order Costs** measured by the **Pragmatic Test**.

**Pragmatic Test:** The overall methodology for the external validation of a **Network of Predicates**. It is a programmatic, empirical research program designed to assess a network's **Pragmatic Viability** by analyzing its total systemic costs over time.

**Pragmatic Viability:** The objective metric of a network's success, distinct from **Mere Endurance**. It is a measure of a system's homeostatic efficiency: its ability to maintain its informational structure while minimizing its total **Systemic Costs**. High viability indicates a network is well-aligned with the **Apex Network**.

**Predicate:** The "gene" of cultural evolution; the basic functional unit of a claim within a network. It is a reusable informational tool (e.g., `...is wrong`, `...is an atom`) whose deployment has testable, real-world consequences.

**Procedural Realism:** The metaethical stance of EPC. It is *realist* in positing objective, mind-independent moral truths, but *procedural* in that these truth-makers are not mysterious properties but are objective, empirical facts about which organizational principles cohere with the real, emergent structure of the **Apex Network**.

**Systemic Costs:** The secondary, non-productive energetic and informational costs a network must pay to manage its **First-Order Costs** (e.g., resources spent on coercion, surveillance, and propaganda). The total systemic cost of a network is the primary inverse indicator of its **Pragmatic Viability**.