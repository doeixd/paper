# **A Procedural and Naturalistic Model of Moral Objectivity**

## **Abstract**

This paper extends **Emergent Pragmatic Coherentism (EPC)**, the framework from *The Architecture of Inquiry*, to the problem of moral objectivity. We develop **Procedural Realism**, a naturalistic account arguing that the same diagnostic tools used to measure *epistemic brittleness* in scientific paradigms can be adapted to measure the *normative brittleness* of social systems. By applying EPC's **Systemic Brittleness Index (SBI)**, we show that both descriptive and normative claims are filtered by the same external standard: the real-world costs generated by their misalignment with pragmatic constraints. This offers a powerful way of reframing the is/ought gap at the level of justification, by showing that both domains are filtered through the same pragmatic constraints.

The argument proceeds by operationalizing this diagnostic test for the historical domain. We analyze a network’s brittleness by tracking a hierarchy of systemic costs—from bio-demographic crises to coercive overheads—using this data to construct a **Negative Canon** of empirically falsified, high-cost normative principles. This reveals moral progress to be a real, observable process of *systemic debugging*: the identification and replacement of brittle predicates drawn from the Negative Canon. On this account, moral objectivity is not a metaphysical fiat but an emergent, procedural fact about which normative architectures prove resilient under pragmatic selection. The result is a robust, fallibilist realism that naturalizes the reference of moral terms and offers a decisive reply to error theory and quasi-realism.

## **1. Introduction: From Epistemic Engineering to Moral Objectivity**

Our previous paper, *The Architecture of Inquiry*, introduced **Emergent Pragmatic Coherentism (EPC)** as a general theory of justification. It argued that inquiry is a project of **epistemic engineering**: the ongoing craft of building more resilient, less brittle public knowledge structures. The viability of these structures, from scientific paradigms to legal systems, can be diagnosed by tracking their **Systemic Brittleness Index (SBI)**—a measure of the real-world costs generated by a network’s misalignment with pragmatic constraints. That paper focused on diagnosing *epistemic brittleness*, where high costs manifest as failed predictions, ad-hoc "patching," and mounting epistemic debt.

This paper extends that diagnostic framework from the descriptive to the normative domain. We argue that the is/ought gap is not a metaphysical chasm but an artifact of a static epistemology that fails to recognize a unified, cost-based mechanism of justification. In a dynamic framework, both "is" and "ought" claims are ultimately subject to the same external filter of pragmatic selection. The same diagnostic toolkit used to track the failure modes of scientific theories can be adapted to track the failure modes of social and ethical systems. We will show how this unified approach dissolves the is/ought problem and grounds a robust, naturalistic form of moral objectivity we call **Procedural Realism**.

Our central thesis is that moral progress is a real, observable, and non-teleological process of **systemic debugging**. By applying the SBI framework to the historical record, we can identify and catalogue demonstrably brittle normative predicates—those that reliably generate catastrophic systemic costs—into a **Negative Canon** of falsified moral ideas. This reveals moral objectivity to be an emergent, procedural fact: moral truths are not discovered in a non-natural realm but are reverse-engineered from the hard-won, empirical data of systemic failure.

The argument will proceed in four stages. First, we will articulate the methodology for this project, operationalizing the SBI for socio-historical analysis by defining the measurable proxies for **normative brittleness**. Second, we will apply this diagnostic toolkit to model moral progress as a process of identifying and replacing high-cost predicates. Third, we will situate Procedural Realism in the metaethical landscape, showing how it provides a powerful naturalistic alternative to both traditional realism and anti-realism. Finally, we will defend the model against core objections, demonstrating its conceptual resilience. The result is a unified theory of inquiry where the pragmatic project of building more viable systems becomes the engine for discovering objective truth in both science and ethics.

### 1.1: The Status of the Project: A Conditional and Descriptive Turn

Before detailing this framework, it is essential to be precise about its scope. This paper does not claim to solve the ultimate grounding problem of normativity or to provide a non-circular answer to the question, 'Why should we value survival?' Instead, it takes a conditional and descriptive turn. Its central claim is this: if one begins from a minimal naturalism where endurance is a de facto constraint on any system, then EPC provides a robust model of procedural objectivity and moral progress. This project does not defend the initial 'if' but demonstrates the explanatory power of the 'then'. Its ambition is not to prove that we ought to play this game, but to provide a systematic description of the rules of the game we are already playing, shifting the focus from a search for metaphysical foundations to a testable model of the evolutionary process by which values are filtered, retained, and come to have authority.


## **2. From Epistemic to Normative Brittleness: A Unified Diagnostic Method**

The EPC framework posits a unified test for the justification of any public knowledge system. A network's claims are justified not only by their internal coherence but by the demonstrated external viability of the network itself. This section operationalizes that external test for the normative domain, adapting the diagnostic toolkit developed in *The Architecture of Inquiry* to measure the structural health of social and ethical systems.

### **2.1 Defining Pragmatic Viability and Normative Brittleness**

The central metric of our framework is the **Systemic Brittleness Index (SBI)**, a measure of a network's vulnerability to future shocks based on the systemic costs it generates. In our previous work, we distinguished two primary modalities of this fragility:

*   **Epistemic Brittleness:** The fragility of descriptive networks (e.g., scientific paradigms), diagnosed by proxies like a rising "Patch Velocity" (the accelerating need for ad-hoc hypotheses) and increasing model complexity without a corresponding increase in predictive power.
*   **Normative Brittleness:** The fragility of socio-political and ethical networks. While it also generates epistemic debt, it is most acutely diagnosed through proxies measuring social friction and the misallocation of resources toward internal control rather than productive adaptation.

A network's **Pragmatic Viability** is therefore defined as the inverse of its brittleness: it is the demonstrated, historical capacity of a system to maintain a low and stable SBI over time. This distinction is crucial for immunizing our theory against the "might makes right" objection. A brutal empire that *endures* for a millennium through high-cost coercion is a textbook example of a high-brittleness system. Its longevity is a measure of the immense energy it must burn to manage its self-inflicted instability, not a sign of its viability. A viable network, by contrast, is efficient, resilient, and maintains its structure with low systemic costs.

To be precise about the unit of selection, this framework adopts a distinction from generalized evolutionary theory. A network's informational structure—its core normative predicates and their relations—functions as the replicator: the abstract code that is transmitted over time. The social group and its institutions serve as the interactor: the physical vessel through which the code is expressed and tested. A network 'survives' by successfully propagating its core informational principles, which can occur even if the original interactor collapses; the rediscovery of Roman legal principles during the Renaissance is a prime example. This distinction allows our systems-level analysis to avoid the pitfalls of naive group selection and focus on the long-term viability of the normative code itself.

### **2.2 A Causal Hierarchy of Costs: The Diagnostic Method**

While the general categories of First-Order and Systemic Costs were defined in *The Architecture of Inquiry*, their application to the normative domain requires a crucial methodological principle to avoid ideological circularity: the principle of **causal priority**. This principle establishes a hierarchy for diagnosing normative brittleness, moving from objective bio-social consequences to more abstract ideological claims. This is not a normative claim about which suffering matters more, but a descriptive, systems-dynamic claim about what makes a network unstable and drives its evolution.

1.  **First-Order Costs (Causally Primary):** These are the direct, material signatures of a network's conflict with the constitutive **Drive to Endure**. They are the most fundamental indicators, measurable through objective proxies *without reference to a network's internal values*. Key proxies include:
    *   **Bio-demographic Data:** Excess mortality, morbidity, malnutrition, and other bio-indicators of systemic stress, measurable via demographic and bioarchaeological records.
    *   **Coercive Overheads:** Resources expended on non-productive internal control. The primary proxy is the **Coercion Ratio**: the proportion of a society's total resources (e.g., GDP or labor) allocated to internal security and suppression versus productive capacity (e.g., infrastructure, public health).

2.  **Second-Order Costs (Causally Subordinate):** These are more abstract, ideologically-framed costs contingent on a particular sub-network's goals, such as threats to a cultural identity, religious orthodoxy, or an economic model. A network that must consistently pay immense **First-Order Costs** (e.g., through mass coercion and systemic violence) to shield itself from potential **Second-Order Costs** is demonstrating a critical, high-brittleness design flaw.

3.  **Systemic Costs (The Management Overhead):** As in the general model, these are the informational costs a network must pay to manage the friction generated by its First-Order Costs. This is where ideology becomes a diagnostic indicator. Proxies include **Information Suppression Costs**: resources dedicated to censorship, propaganda, and the persecution of dissenters, often measurable by innovation lags in critical sectors.

This cost hierarchy is not static; it operates within a dynamic feedback loop that bridges the micro and macro levels. Persistent individual friction—the direct, personal experience of **First-Order Costs**—generates withdrawal of support, defection, and resistance at the micro-level. This aggregation of local responses starves the network's institutional carriers (the macro-level) of the legitimacy and resources they need to function. A network ultimately fails when the systemic costs of maintaining its core institutions exceed the society’s capacity to pay them, leading to collapse or radical transformation. This causal mechanism is key: networks predicated on norms that generate high First-Order Costs must pay compounding Systemic Costs to manage the resulting dissent, making their high SBI a clear, diagnostic signal of their non-viability.

### **2.3 The Primary Tool: Constructing the Negative Canon**

Following Karl Popper, our most reliable objective knowledge is of what is demonstrably false or unworkable. The primary empirical project of this methodology is therefore a negative one: the construction of a **Negative Canon**. This is a robust, cross-cultural, and evidence-based catalogue of normative predicates that have been empirically falsified by the catastrophic costs they reliably generate across multiple historical contexts.

The predicate `slavery is an acceptable organizing principle` is a core entry in this canon. This claim is not based on modern moral sentiment but on the overwhelming historical evidence that networks built on this predicate consistently exhibit a pathologically high **Coercion Ratio**, suffer from endemic **First-Order Costs** of violence, and experience long-term economic and innovative stagnation (Patterson 1982; Acemoglu & Robinson 2012). By meticulously mapping these failures, we empirically chart the boundaries of viable social design.

This diagnostic framework provides a purely instrumental, non-moralistic justification for the central insight of **standpoint epistemology**. The testimony of the marginalized is not treated as privileged out of a prior commitment to social justice, but because it is a **privileged stream of diagnostic data**. Those agents experiencing the highest First-Order Costs function as the most sensitive detectors of a system's impending failure. Their dissent is not mere noise to be suppressed; it is the primary "check engine" light signaling that a network’s core predicates are dangerously misaligned with reality.

### **2.4 Falsification Conditions**

This framework is an empirical hypothesis and must be falsifiable. Its central causal claim is that a predictable, statistically significant relationship exists between a network's internal systemic costs and its long-term fragility. The framework would be falsified if broad, cross-cultural historical analysis revealed any of the following:

1.  **No Correlation:** No statistically significant correlation exists between high First-Order Costs (e.g., internal violence) and high Systemic Costs (e.g., a high Coercion Ratio).
2.  **The Superiority of High-Cost Systems:** High-cost, coercive networks are shown to be *more* innovative, adaptable, and resilient to external shocks over the long term than low-cost, cooperative networks when controlling for confounding variables.
3.  **The Failure of the Negative Canon:** Predicates in the proposed Negative Canon (e.g., `slavery is acceptable`) are found in multiple, controlled historical comparisons to *enhance* a network's long-term resilience and adaptive efficiency.

If the historical record showed high-friction, coercive systems to be just as resilient as low-friction ones, the model's central causal claim would be broken, and the theory itself would be falsified.

## **3. Moral Progress as Systemic Debugging**

With the diagnostic method for normative brittleness established, we can now apply it to model moral objectivity. Emergent Pragmatic Coherentism reframes moral inquiry not as a search for non-natural properties, but as a fallible, empirical project of engineering more viable systems of social cooperation. This section will show how this engineering perspective provides a robust, non-teleological account of moral progress.

### **3.1 A Non-Teleological Model of Progress**

EPC models moral progress as a process of **systemic debugging**: the identification and removal of high-cost, brittle predicates from a society’s operative normative network. This process is not a march toward a pre-ordained utopian endpoint (teleology), but a backward-looking, problem-solving endeavor of learning from and correcting catastrophic failures. Progress is the empirically observable reduction of a network’s **Systemic Brittleness Index (SBI)** over time. A moral change constitutes *progress* if the successor network demonstrates a measurably lower SBI—generating fewer **First-Order Costs** and requiring lower **Systemic Costs** for its maintenance—than the network it replaced.

### **3.2 Paradigm Case: The Abolition of Slavery**

The abolition of chattel slavery is a paradigm case of systemic debugging. The claim that this was objective moral progress is not based on an appeal to modern sentiment, but on a pragmatic diagnosis of the predicate `slavery is an acceptable organizing principle` as a catastrophic and unsustainable design flaw.

*   **The Bug:** The predicate was a core component of the normative architecture of many historical societies.
*   **The Pragmatic Costs:** As predicted by our methodology, this predicate generated immense and unsustainable costs. It required a pathologically high **Coercion Ratio**, diverting vast societal resources to surveillance, patrols, and the violent suppression of dissent. It also generated catastrophic **First-Order Costs**, from the endemic violence needed to maintain the system to the constant, systemic risk of mass revolt. Furthermore, by suppressing the human capital and innovative potential of a huge portion of the population, it incurred profound long-term economic and informational costs, rendering the entire system fragile.
*   **The Debugging Process:** The moral arguments of abolitionists were not just appeals to a novel emotion. They were, in effect, arguments that the incumbent normative network was demonstrably inefficient, brittle, and generating unsustainable pragmatic costs. The replacement predicate—`slavery is wrong`—succeeded not because it was metaphysically "truer," but because it proposed a solution that would dramatically lower the network's long-term SBI.
*   **The Result:** The eventual triumph of abolition was an act of engineering a more viable social architecture. A demonstrably failed organizing principle, a predicate firmly in the **Negative Canon**, was identified and removed. We can state with empirically grounded confidence that this was not just a change, but progress, because the resulting network, while still imperfect, was significantly less brittle and more pragmatically viable.

### **3.3 Analyzing a Complex Case: The Status of Women**

The EPC framework's power is not limited to historically settled cases. It provides a diagnostic lens for analyzing complex and ongoing moral debates. Consider the historical shift away from patriarchal norms, which can be modeled as the debugging of the predicate `women's roles are confined to the private and subordinate sphere`.

The long-term diagnosis reveals this predicate to be profoundly inefficient. Its costs include the massive economic deadweight loss of excluding half the population from the formal economy and public life; the severe **informational cost** of silencing female perspectives in collective problem-solving; and the high **coercive costs** (both formal and informal) required to enforce these rigid social roles.

The transition to a more egalitarian network is a complex debugging process. It incurs significant short-term friction costs, such as social and political conflict over traditional norms. However, the EPC framework analyzes this not as a failure, but as a high-cost "investment" made to pay down the immense systemic debt of the old architecture. The empirical wager of feminist critique is that a network that fully utilizes the cognitive and economic resources of its entire population will, in the long run, be vastly more innovative, resilient, and pragmatically viable—that is, it will have a much lower SBI. This reframes the debate from a clash of incommensurable values to a tractable, empirical question about the relative engineering soundness of different social designs.

### **3.4 The Structure of Moral Knowledge: Core and Periphery**

This debugging model does not predict a single, dogmatically absolute moral code. Instead, it predicts an emergent moral landscape with two distinct zones, whose boundaries are an ongoing subject of empirical inquiry.

1.  **The Convergent Core:** This consists of normative predicates that have been independently discovered and retained across diverse cultures. We identify these core principles not only by elimination via the Negative Canon, but also through a positive methodology: the Test of Independent Convergence. When we observe a specific norm (e.g., reciprocity) emerging repeatedly in maximally different historical and environmental contexts, it provides strong evidence that it is not a cultural accident but the discovery of a non-negotiable, low-brittleness 'engineering principle' for any viable human society.
2.  **The Pluralist Periphery:** This accounts for legitimate and persistent cultural diversity without collapsing into relativism. It describes domains where multiple, distinct, yet *equally viable* normative solutions may exist. For example, different models of economic organization (e.g., a regulated welfare-state capitalism vs. a robust social democracy) might represent two different but comparably low-brittleness strategies for managing a complex modern society. The Negative Canon defines the hard boundary of this pluralism: a cultural practice is not a viable option if it relies on predicates (like those supporting honor killings or chattel slavery) that have been empirically falsified by their catastrophic costs.

### **3.5 Methodological Humility: Scope and Challenges**

The application of this diagnostic framework is not a simple algorithm but a complex, probabilistic, and ongoing research program. A candid acknowledgment of its challenges is essential.

*   **Confounding Variables:** A network’s failure can result from many factors beyond its normative code, such as climate shocks or foreign invasion. The framework's power lies not in single-case causal proofs, but in **comparative historical inference**. By analyzing multiple, independent cases (as in the work of Tainter 1988 or Turchin 2003), we can identify robust patterns where specific normative predicates consistently correlate with high brittleness across different contexts.
*   **Scope Conditions:** The historical record is biased toward large, complex societies. The **Negative Canon** is therefore most reliably built from the failure modes of such systems. This defines a crucial scope condition: the EPC framework is most powerful for diagnosing the viability of normative architectures for large-scale societies. Its claims must be more circumspect regarding the full spectrum of small-scale, non-state societies. This is a feature, not a bug, that keeps the theory from over-reaching and respects the limits of its evidentiary base.
*   **Mitigating Confounds:** To isolate normative effects from exogenous shocks, future applications of the Pragmatic Test should employ process-tracing techniques (as in Bennett and Checkel 2014) alongside Bayesian historical modeling (e.g., Heidler et al. 2019). For instance, in analyzing patriarchal brittleness, one could trace causal chains from gender norms to First-Order Costs while holding constant variables like technological access via matched-pair comparisons across contemporaneous societies (e.g., pre-industrial Europe vs. East Asia). This elevates comparative inference from pattern-spotting to probabilistic causal attribution, enhancing the framework's falsifiability.

## **4. Procedural Realism: A Naturalistic Alternative**

The framework of Emergent Pragmatic Coherentism, when applied to the normative domain, yields a novel metaethical position we call **Procedural Realism**. This section situates this view in the philosophical landscape. We argue that it preserves the core commitments of moral realism through a unique synthesis of pragmatism, systems theory, and evolutionary thinking, providing a powerful naturalistic response to the most significant anti-realist and non-cognitivist challenges.

### **4.1 A Form of Pragmatic, Externalist Realism**

Procedural Realism is a form of moral realism, but its claim to objectivity is not grounded in mysterious non-natural properties or a thick teleological account of human flourishing. It is:

*   **Realist** in positing that there are objective, mind-independent truths about the viability of normative systems. The claim that `slavery is wrong` refers to a real, structural fact about that predicate's profound incoherence with the **Apex Network**, the emergent, mind-independent structure of viable predicates.
*   **Procedural** in that these moral truths are not static properties but emergent, relational facts discovered through a historical, empirical process. The "truth-makers" for moral claims are the objective facts about which networks prove resilient (maintain a low SBI) against the constraints of pragmatic selection.
*   **Externalist** in that the justification for a moral claim rests not on an agent's internal coherence or a culture's consensus, but on the demonstrated, historical track record of the entire public system.

### **4.2 The Apex Network: A Real Object of Inquiry**

The entire architecture of EPC’s procedural objectivity rests on the concept of the **Apex Network**. To defend this concept against the charge that it is merely a functional equivalent to an unknowable Platonic Form, we must be rigorously precise about its status. The core of the account lies in a crucial distinction: the difference between **the Apex Network as a real, objective, and mind-independent standard** and our **epistemic access to it, which is necessarily indirect, fallible, and scientific.** The Apex Network is not fallible; our models of it are.

Its existence is a structural necessity of the EPC model. Given the constant, system-wide process of pragmatic convergence—where countless individual webs are filtered by a shared reality—the existence of a **maximal, coherent, and shared set of pragmatically successful predicates is a structural necessity.** This emergent historical object—the cumulative, time-tested informational structure forged in the crucible of humanity’s collective, filtered experience—is what EPC terms the Apex Network. Its ontological status is that of an emergent, structural fact about our world—akin not to a Platonic Form but to the quantum vacuum in physics: a mind-independent substrate of possibilities, inferred from its observable effects (e.g., particle interactions) rather than directly perceived. The Apex Network constrains viable design not as a top-down blueprint but as a bottom-up convergence of low-SBI predicates, discoverable through the empirical debris of historical selection pressures. Epistemically, our access is never direct. We construct a fallible scientific model of it, primarily by studying the wreckage of failures catalogued in our **Negative Canon**.

### **4.3 Answering the Anti-Realist Challenge**

This architecture provides a powerful, unified response to the canonical anti-realist arguments.

*   **vs. Error Theory (Mackie 1977; Joyce 2001):** We agree with the error theorist's "argument from queerness" that there are no strange, non-natural properties. However, we deny the conclusion that all positive moral claims are false. EPC diagnoses this as a case of **successful but mis-glossed reference**. Our moral discourse has been successfully, if imperfectly, tracking real, procedural facts about the viability of social arrangements all along. The "wrongness" of slavery is not a queer property but a relational, empirical property of a predicate that reliably generates catastrophic **First-Order Costs**. Our framework naturalizes the reference of our moral terms, it does not eliminate them.

*   **vs. Non-Cognitivism and "Quasi-Quasi-Realism" (Blackburn 1993; Streumer 2025):** This procedural realism can be brought into sharp relief by contrasting it with contemporary projects that defend realism at the semantic level. Bart Streumer, for instance, argues that the truth of a normative judgment is a descriptive fact about the attitudes of the person *assessing* the judgment. This move elegantly solves disagreement for an assessor, grounding objectivity in their stable context. EPC shares this multi-level structure but operates on an entirely different scale. While a predicate like "slavery is acceptable" can have *contextual truth* relative to the local network of a dominant group, EPC argues that when we make objective moral claims, we appeal to a higher standard: that predicate's coherence with our best model of the **Apex Network**. The truth-maker for "slavery is objectively wrong" is therefore not a psychological fact about an assessor's present disapproval, but a robust, empirical fact about the catastrophic costs and systemic fragility that such a predicate imposes on any network over time. Streumer's project brilliantly vindicates the realist-sounding *grammar* of our moral talk; EPC identifies the objective, evolutionary *filter* that makes some moral systems robustly viable and others demonstrable failures.

*   **vs. Evolutionary Debunking Arguments (Street 2006):** Sharon Street's "Darwinian Dilemma" argues that since evolution shaped our moral beliefs for adaptiveness, their alignment with any independent moral truth would be a wild coincidence. Procedural Realism resolves this dilemma by collapsing one of its horns. For us, **pragmatic viability is not a coincidental correlate of moral truth; it is the truth-maker itself.** The predicates that enhance a network's long-term resilience are procedurally "better" precisely *because* they are better adapted to the constraints of the **Apex Network**. Evolution is not a distorting influence that the realist must explain away; it is the very filtering process that grounds objectivity.

### **4.4 An Externalist Alternative to Other Naturalisms**

EPC’s systems-level externalism distinguishes it from other influential naturalist rivals.

*   **vs. Cornell Realism (Railton 1986):** Unlike agent-centric realisms that ground moral facts in an individual's "objective interests" or a synchronic "homeostatic property cluster" of human goods, EPC's unit of evaluation is the **diachronic, multi-generational viability of the informational network itself.** The objective interests of a tyrant are irrelevant to the assessment; the socio-political network that licensed his predicates was an objective, evolutionary failure because of the systemic friction it generated.

*   **vs. Neo-Aristotelianism (Foot 2001):** The Neo-Aristotelian project grounds normativity in a "thick," teleological concept of species-specific flourishing. EPC, by contrast, uses the "thin," procedural standard of viability. This allows it to robustly account for the **Pluralist Periphery**, where multiple, distinct forms of life may prove equally viable without having to conform to a single, contentious model of "human goodness."

*   **vs. Constitutivist Constructivism (Korsgaard 1996):** Where a constructivist grounds normativity in the internal coherence of our own attitudes or the structure of rational agency, EPC insists on an external check. The ultimate arbiter is not internal consistency but the network's external relationship with the selective pressures of reality. This provides EPC's definitive answer to the "ideally coherent Caligula": Caligula's internal coherence is irrelevant. The network that produced and sustained such a predicate was an **objective, pragmatic, evolutionary failure**, judged not by our disapproval, but by the immense, real-world systemic costs it generated.

### **4.5 A Comparative Summary**

The following table summarizes Procedural Realism's unique position:

| View | Truth-makers | Unit of Evaluation | Method | Objectivity |
| :--- | :--- | :--- | :--- | :--- |
| **Procedural Realism (EPC)** | External viability facts (low SBI), grounded in the Apex Network | Informational network (Replicator) | Comparative, failure-driven empirics | Procedural, fallibilist, externalist |
| **Quasi-realism** | Attitude-dependent projection | Attitudes/practices | Semantic explanation | Deflated, grammar-vindicating |
| **Cornell Realism** | Natural properties of human good | Agent interests | Reflective equilibrium + science | Robust, agent-centered |
| **Neo-Aristotelianism** | Flourishing of organism | Life-form | Teleological evaluation | Robust, teleological |
| **Constructivism** | Idealized procedures / structure of agency | Rational agents | Hypothetical agreement / self-constitution via idealized rational procedures | Procedural, internalist |


## **5. Defending Procedural Realism: Objections and Replies**

With the framework for Procedural Realism fully articulated, we must now test its resilience against the most pressing critical objections. The model's ability to provide robust, non-circular answers to these challenges strengthens its claim to be a coherent, naturalistic framework for moral objectivity.

### **5.1 Objection: The Stability of Evil ("Might Makes Right")**

The most common objection to any pragmatic ethical theory is that it collapses into "might makes right," justifying the practices of any oppressive society that manages to endure. Hasn't a millennium-old empire "won" the pragmatic test, thereby making its oppressive predicates objectively viable by our own standards?

This objection rests on a crucial error the EPC framework is designed to correct: it mistakes **mere endurance** for the richer, more demanding concept of **pragmatic viability**. As defined in Section 2, viability is a measure of a system's ability to maintain its structure with a low **Systemic Brittleness Index (SBI)**. An oppressive state that persists through immense coercion is not viable; it is a high-cost, high-brittleness system. Its longevity is not a sign of strength but a measure of the immense energy (a high **Coercion Ratio**) it must burn to manage its self-inflicted instability.

Such systems are often functionally parasitic, their endurance subsidized by external extraction that masks internal normative decay. This allows us to formulate a set of present-tense **Diagnostic Heuristics**. A network's apparent stability is presumptively parasitic rather than viable when we observe that: (a) its budget for internal control (the **Coercion Ratio**) persistently exceeds investment in productive public goods; (b) its innovation and learning rates lag significantly relative to peers; and (c) its suppression of dissent intensifies without any corresponding reduction in First-Order Costs. These are the empirical signatures of a high-brittleness system on a path toward failure. Their endurance does not vindicate their predicates; it merely makes them long-running, inefficient experiments whose wreckage provides the most unambiguous data for our **Negative Canon** and our fallible map of the **Apex Network**.

### **5.2 Objection: The Power of Ideology**

A more sophisticated objection concedes that oppressive systems generate pragmatic costs but argues that **ideology** can co-opt the revision process. Can't a network create powerful "patch" predicates (e.g., "your suffering is a divine trial") that convince agents to endure failure rather than revise the network's core?

This objection correctly identifies a key tactic in network evolution, but it mistakes a symptom of brittleness for a solution to it. Ideological patches are a form of **normative patching**, functionally identical to the ad-hoc hypotheses that create **Epistemic Debt** in a failing scientific paradigm. They are never pragmatically free. A predicate like "the state is infallible" is a low-eROI (Epistemic Return on Investment) patch—a high-cost addition that makes no novel predictions but merely insulates a failing predicate—designed to suppress data about First-Order Costs. To maintain it, the network must pay compounding **Systemic Costs**: a vast apparatus of propaganda, surveillance, and coercion. The very *need* for this ever-growing layer of ideological insulation is a primary diagnostic indicator of a rising SBI. It provides a powerful, present-tense epistemic reason to be deeply skeptical of any network that requires immense energy expenditure to explain away suffering. A viable network does not need to spend a third of its budget convincing its citizens that they are not suffering.

Historical cases illustrate this brittleness in action. The Soviet Union's ideological apparatus—framing gulag labor as "re-education" and famines as "temporary setbacks"—served as a massive normative patch to sustain predicates like "state ownership is infallible." Yet, it demanded exponential Systemic Costs: a sprawling KGB network, pervasive censorship, and purges that consumed up to 20% of GDP equivalents in coercive overhead ( Conquest 1990). The patch delayed but did not avert collapse, as the underlying First-Order Costs (e.g., demographic crashes from the Holodomor) eroded legitimacy. This exemplifies how ideological insulation, far from resolving friction, amplifies it, providing a diagnostic heuristic for present-day networks reliant on similar "explanatory" infrastructures.

### **5.3 Objection: The Asymmetry of Testing**

A third objection targets the claim of a unified test for all predicates. The test for an empirical claim ("water boils at 100°C") is rapid and decisive, while the test for a moral claim ("slavery is unacceptable") is slow, diffuse, and unfolds over generations. Is this asymmetry so great as to render the claim of a unified test meaningless?

This observed asymmetry is not a flaw in the model but a **direct and crucial prediction of it**. EPC posits a unified pragmatic *filter*, while fully acknowledging that the *complexity of the system being tested* determines the timescale and texture of the feedback. An empirical predicate about a simple physical system produces rapid, clear feedback loops. A moral predicate is a hypothesis about structuring a complex adaptive social system, which has countless interacting variables and feedback loops that are distributed, delayed, and holistic. The difference in the velocity and clarity of the feedback does not imply a difference in the kind of the ultimate arbiter. It simply explains why moral knowledge is so much harder-won—requiring the aggregation of vast amounts of historical data—and underscores that our moral claims are, at their best, fallible attempts to map the real territory of the **Apex Network**.

### **5.4 Objection: The Grounding Problem Revisited**

The final and most fundamental challenge is that the theory appears circular. By making viability the ultimate standard, does it not smuggle in a normative commitment to endurance? Why *ought* we to care about what survives the pragmatic filter?

This objection misunderstands the model's descriptive and conditional nature. The reply is a two-part defense that separates the grounding of the justificatory *arena* from the source of *normative force* within it.

First, the **Constitutive Defense:** The model is anchored not by a chosen value but by a system's constitutive **Drive to Endure**—the minimal, biologically-grounded precondition for the persistence of its structure and core information over time. The status of this drive has a **dual aspect**: descriptively, it is an evolutionary fact that systems that fail to preserve their informational structure vanish, leaving no historical trace; constitutively, it is the inescapable precondition for any inquiry whatsoever. Like gravity for an architect, the Drive to Endure is the non-negotiable filter through which all informational blueprints, including moral ones, must pass to become part of the historical record. It grounds our inquiry into the structure of the **Apex Network**.

Second, with this non-normative arena established, the **Instrumental Defense** provides the conditional normative force. The "ought" that emerges from EPC is a wide-scope, system-level, and strategic one:
> *If* a community has a de facto goal of persisting and solving problems (which any ongoing society does), *then* it has a powerful, evidence-based reason to adopt normative predicates that align with the **Apex Network** and to avoid those catalogued in the **Negative Canon**, as this is the most effective strategy for lowering its SBI and satisfying its constitutive Drive to Endure.

This "ought" is purely instrumental. It does not command commitment from an external, metaphysical source. It is a piece of strategic advice, mapping the predictable consequences of different design choices for any system operating within the inescapable constraints of reality. This two-part defense provides a non-circular and robust grounding for the entire framework.

To address potential counterexamples, consider subcultures driven by non-endurant goals, such as ascetic traditions that prioritize transcendence over persistence or apocalyptic ideologies that embrace collapse. EPC does not deny the psychological or cultural reality of such drives but observes that they leave no durable informational trace in the historical record—precisely because they conflict with the constitutive mechanics of replicator propagation. The "Drive to Endure" is thus not a substantive value but a structural filter: only networks that incidentally align with endurance mechanisms (e.g., biological imperatives for survival and reproduction) persist long enough to generate the cross-cultural data from which we infer the Apex Network. This sidesteps circularity by grounding the arena in observable evolutionary dynamics rather than prescriptive ethics.

## **6. Conclusion: Inquiry as a Pragmatic Project**

This paper began with one of philosophy's oldest chasms: the gap between "is" and "ought." We have argued that this chasm is not a feature of reality but an artifact of a static epistemology. It is dissolved by a unified, dynamic theory of inquiry—**Emergent Pragmatic Coherentism (EPC)**—and its application to ethics, **Procedural Realism**. The goal of this unified project, whether in science or ethics, is the construction of ever more viable maps for navigating a shared reality.

Procedural Realism reframes moral claims as testable hypotheses about viable social design. Their justification is not metaphysical but diagnostic. We assess the **normative brittleness** of a social system by tracking its **Systemic Brittleness Index (SBI)**—a measure of the real-world costs generated by its core principles. This empirical approach allows us to construct a **Negative Canon** of normative predicates that have been decisively falsified by the historical record of systemic failure.

This framework offers a naturalistic model for a robust, procedural objectivity. We can be humble in knowing that our current maps are imperfect, yet we can be confident that moral progress is a real, observable phenomenon. We can state with an objectivity grounded in empirical evidence that abolishing slavery was not a mere change of opinion; it was a profound act of **systemic debugging**—the identification and removal of a demonstrably high-SBI predicate from our societal code.

Progress occurs when we treat suffering, dissent, and instability not as mere political problems to be managed, but as primary **epistemological data**. They are the "check engine" light for society, the clearest signals of a rising SBI and a misalignment between our normative network and the constraints of reality. This gives us a powerful, pragmatic reason to listen to the marginalized, as they possess the most crucial information about where our collective map is wrong.

The authority of an "ought," therefore, is not found in a mysterious metaphysical foundation or a non-natural realm of values. It lies instead in the immense, procedural weight of historical evidence. An "ought," on this view, is a time-tested, low-brittleness predicate coherent with our most pragmatically resilient networks—a hard-won empirical signal that it represents a viable strategy for the shared project of human endurance. Procedural Realism reframes moral philosophy from a search for ultimate foundations to the ongoing, fallible craft of pragmatic navigation: the art of steering by the light of humanity's most enduring successes and the hard-won lessons from the wreckage of its failures.


## **Glossary**

**Procedural Realism:**
The metaethical theory developed in this paper, grounded in EPC. It holds that moral objectivity is not based on metaphysical foundations or cultural consensus but on emergent, procedural facts about the long-term pragmatic viability of normative systems. Its core claim is that the "truth-makers" for moral claims are the objective, empirical facts about which social architectures maintain a low **Systemic Brittleness Index (SBI)** under the selective pressure of real-world constraints.

**Normative Brittleness:**
A specific modality of the **Systemic Brittleness Index (SBI)** that applies to social, political, and ethical networks. It is a system's vulnerability to collapse, diagnosed by tracking proxies for high systemic costs, such as a high **Coercion Ratio** (resources spent on internal suppression) and the accumulation of **First-Order Costs** (e.g., internal violence, systemic instability). It is the normative counterpart to the *epistemic brittleness* found in failing scientific paradigms.

**Pragmatic Viability:**
The objective, external metric of a network's success, defined as the inverse of **Normative Brittleness**. A system possesses high pragmatic viability if it demonstrates a historical capacity to maintain a low and stable **Systemic Brittleness Index (SBI)**. This distinguishes it from **mere endurance**, which can be achieved through high-cost, high-brittleness means (e.g., brutal coercion).

**The Pragmatic Test:**
The overall methodology for applying the EPC framework to the socio-historical domain. It is a programmatic, empirical research agenda that operationalizes the diagnosis of **Normative Brittleness** by assessing a network's **Pragmatic Viability** through a multi-proxy analysis of its systemic costs over time.

**Negative Canon:**
The primary empirical output of the **Pragmatic Test**. It is a robust, cross-cultural, and evidence-based catalogue of *normative predicates* (e.g., "slavery is an acceptable organizing principle") that have been empirically falsified by their demonstrated tendency to generate catastrophic costs and a chronically high **Systemic Brittleness Index (SBI)**.

**Convergent Core:**
The set of universally viable normative predicates that represent stable, low-cost solutions to universal human coordination problems (e.g., norms of reciprocity). The model predicts the existence of this core as an emergent consequence of pragmatic filtering across diverse societies.

**Pluralist Periphery:**
The set of culturally-specific but demonstrably viable normative systems. This concept accounts for legitimate moral disagreements by identifying domains where multiple, distinct social architectures may prove to be *equally viable* (i.e., possess comparably low and stable SBIs). Its boundaries are strictly defined by the **Negative Canon**, thus preventing a collapse into relativism.

### **References**

Acemoglu, Daron, and James A. Robinson. 2012. *Why Nations Fail: The Origins of Power, Prosperity, and Poverty*. New York: Crown Business.

Axelrod, Robert. 1984. *The Evolution of Cooperation*. New York: Basic Books.

Bennett, Andrew, and Jeffrey T. Checkel, eds. 2014. Process Tracing: From Metaphor to Analytic Tool. Cambridge University Press. Heidler, Raphaela, et al. 2019. "Bayesian Analysis for Historians." Historical Methods 52(3): 143–162.

Blackburn, Simon. 1993. *Essays in Quasi-Realism*. New York: Oxford University Press.

Boyd, Richard N. 1988. “How to Be a Moral Realist." In Essays on Moral Realism, edited by Geoffrey Sayre-McCord, 181–228. Ithaca, NY: Cornell University Press.

Buchanan, Allen, and Russell Powell. 2018. *The Evolution of Moral Progress: A Biocultural Theory*. New York: Oxford University Press.

Conquest, Robert. 1990. The Great Terror: A Reassessment. Oxford University Press.

Dewey, John. (1929) 1960. *The Quest for Certainty: A Study of the Relation of Knowledge and Action*. New York: Capricorn Books.

Foot, Philippa. 2001. *Natural Goodness*. Oxford: Clarendon Press.

Glenn, Patrick. n.d. *The Architecture of Inquiry: A Pragmatic and Naturalistic Account of Objectivity*. PhilPapers. Accessed September 11, 2025. https://philpapers.org/rec/GLETAO.

Harding, Sandra G. 2004. *The Feminist Standpoint Theory Reader*. New York: Routledge.

Henrich, Joseph. 2015. *The Secret of Our Success: How Culture Is Driving Human Evolution, Domesticating Our Species, and Making Us Smarter*. Princeton, NJ: Princeton University Press.

Holling, C. S. 1973. “Resilience and Stability of Ecological Systems.” *Annual Review of Ecology and Systematics* 4: 1–23.

Joyce, Richard. 2001. The Myth of Morality. Cambridge: Cambridge University Press.

Korsgaard, Christine M. 1996. The Sources of Normativity. Cambridge: Cambridge University Press.

Mackie, J. L. 1977. *Ethics: Inventing Right and Wrong*. London: Penguin Books.

Patterson, Orlando. 1982. *Slavery and Social Death: A Comparative Study*. Cambridge, MA: Harvard University Press.

Popper, Karl. (1934) 1959. *The Logic of Scientific Discovery*. London: Hutchinson.

Quine, W. V. O. 1951. “Two Dogmas of Empiricism.” *The Philosophical Review* 60 (1): 20–43.

Railton, Peter. 1986. “Moral Realism.” *The Philosophical Review* 95 (2): 163–207.

Rorty, Richard. 1979. *Philosophy and the Mirror of Nature*. Princeton, NJ: Princeton University Press.

Street, Sharon. 2006. “A Darwinian Dilemma for Realist Theories of Value.” *Philosophical Studies* 127 (1): 109–66.

Streumer, Bart. 2025. "Quasi-Realism for Realists." Philosophers' Imprint 25 (10): 1–17.

Tainter, Joseph A. 1988. *The Collapse of Complex Societies*. Cambridge: Cambridge University Press.

Turchin, Peter. 2003. *Historical Dynamics: Why States Rise and Fall*. Princeton, NJ: Princeton University Press.
